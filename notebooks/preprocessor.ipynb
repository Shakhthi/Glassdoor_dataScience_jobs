{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25095b61",
   "metadata": {},
   "source": [
    "<h3> DS jobs Dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ed2ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3873957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"..\\data\\ds_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "376adceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "job_description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_avg_estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "salary_estimate_payperiod",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_founded",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industry",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sector",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "revenue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "career_opportunities_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "comp_and_benefits_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "culture_and_values_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "senior_management_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "work_life_balance_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "36211fd5-fb3e-481a-9324-afb66ad0c3d0",
       "rows": [
        [
         "0",
         "ABB",
         "Junior Data Analyst",
         "4.0",
         "Junior Data Analyst\nTake your next career step at ABB with a global team that is energizing the transformation of society and industry to achieve a more productive, sustainable future. At ABB, we have the clear goal of driving diversity and inclusion across all dimensions: gender, LGBTQ+, abilities, ethnicity and generations. Together, we are embarking on a journey where each and every one of us, individually and collectively, welcomes and celebrates individual differences.\n\nYou will be working as Junior Data Analyst and will be part of Process Automation Business Area for Measurement and Analytics division based in Bangalore, India. In this role you will be reporting to COE Data Management and Analytics Manager and will be responsible for performing data analytics activities and developing analytical solutions to enable business in strategy development for existing and potential products, systems or services.\nYour responsibilities\nUsing data systems to help gather, measure, organize and analyze data, providing sound market and competitive intelligence analysis related to market and trends\nPreparing analysis of internal sales, technical and financial data, interprets resulting data using statistical tools and making recommendations to Sales, Marketing, Finance and Product Management\nMaking diagnostic and predictive recommendations to management of existing gaps and new opportunities for growth, identifying global trends and patterns across various dimensions\nExtracting and analyzing data from sales or financial tools and preparing reports for management to give insights on trends, patterns and predictions across geographies\nAssisting in the development of analytical tools and solutions to support management to drive key business decisions. Training business stakeholders on proper usage of dashboards and monitors on-going data quality\nYour background\nB.E or B. Tech or BCA or Bachelor's in Data Science\nMinimum 1 to 2 years of experience in Data Analytics and visualization\nHands on experience in Basic or Advanced Excel, Basic Statistics, ETL tools, Power BI(Basic),Basic SQL,ML and Python\nAbility to adapt, problem solving skills and give recommendations to stakeholders\nEffective time management while handling business critical tasks\nGood teamwork and collaboration with cross functional teams to meet business deliverables\nGood communication skills\nMore about us\nABB's Measurement & Analytics division is among the world's leading manufacturers and suppliers of smart instrumentation and analyzers. With thousands of experts around the world and high-performance digital technology, ABB's team is dedicated to making measurement easy for its industrial and energy customers to let them operate more efficiently and profitably. We look forward to receiving your application (documents submitted in English are appreciated). If you want to discover more about ABB, take another look at our website www.abb.com. It has come to our attention that the name of ABB is being used for asking candidates to make payments for job opportunities (interviews, offers). Please be advised that ABB makes no such requests. All our open positions are made available on our career portal for all fitting the criteria to apply. ABB does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection to recruitment with ABB, even if is claimed that the money is refundable. ABB is not liable for such transactions. For current open positions you can visit our career website https://global.abb/group/en/careers and apply. Please refer to detailed recruitment fraud caution notice using the link https://global.abb/group/en/careers/how-to-apply/fraud-warning Work model: on site #LI-onsite",
         "Bengaluru",
         "325236.0",
         "/yr (est.)",
         "10000+ Employees",
         "1883",
         "Company - Public",
         "Electronics Manufacturing",
         "Manufacturing",
         "$10+ billion (USD)",
         "3.7",
         "3.6",
         "4.0",
         "3.5",
         "3.9"
        ],
        [
         "1",
         "Philips",
         "Data Scientist - AI/ML",
         "4.0",
         "Job Title\nData Scientist - AI/ML\nJob Description\nJob title: Data Scientist - AI/ML\nOverall responsibilities\nProvide support with guidance to solve complex problems in medical image processing and deliver PoC with TRL level ready for NPI program.\nSupport collaboration with clinical scientists, AD leader and universities to drive advanced development projects on medical image analytics from R&D perspective.\nSupport NPI development and address time-pressing complex LCM challenges with image processing / IQ using expertise.\nHigher degree of learning attitude to absorb newer knowledge on medical image pre- and / or post-processing.\nSpecific responsibilities\nHands-on work in some of the following tools, packages, technical areas and modeling techniques:\nKeras, Tensorflow, Pytorch, Scikit-learn, Scikit-image, OpenCV, pydicom\nMatlab, python, R, Java/C/C++\nConvolution Neural Networks, other statistical modeling & classification approaches (regression, SVM, PCA)\nOpensource medical image visualization and segmentation tools like ITK, VTK\nMedical image post-processing techniques such as noise reduction, contrast enhancement, bone suppression, stitching, ranging. Knowledge of overall IQ (image quality) analysis of diagnostic X-ray images is a plus.\nMedical image pre-processing (gain, offset correction, EMI/EMC correction)\nAI/ML modeling / computer vision using video from 3\n\nAbout Philips\nWe are a health technology company. We built our entire company around the belief that every human matters, and we won't stop until everybody everywhere has access to the quality healthcare that we all deserve. Do the work of your life to help the lives of others.\nLearn more about our business.\nDiscover our rich and exciting history.\nLearn more about our purpose.\n\nIf you’re interested in this role and have many, but not all, of the experiences needed, we encourage you to apply. You may still be the right candidate for this or other opportunities at Philips. Learn more about our commitment to diversity and inclusion here.",
         "Bengaluru",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "1891",
         "Company - Public",
         "Healthcare Services & Hospitals",
         "Healthcare",
         "$10+ billion (USD)",
         "3.8",
         "3.7",
         "4.0",
         "3.5",
         "4.0"
        ],
        [
         "2",
         "HSBC",
         "Data Science GSC’s",
         "3.9",
         "Job description\nGraduate/ Post-graduate degree with relevant field (Finance/Economics/Operation Research/Statistics/Mathematics/ B.Tech/ MBA/ Data Science)\nCertification courses in Data Science/Risk Management or similar areas will be added advantage\nExcellent coding skills in latest statistical packages/apps SAS/R/Python\nTerm papers with demonstrated skills set in modelling, forecasting and optimization\nExcellent quantitative aptitude and hands-on proficiency with analytical tools such as SAS, R, Python\nHighly focused on project delivery, attention to detail\nExcellent written and verbal communication skills\nStrong collaborative, influencing skills\nStrong analytical and problem solving skills, open minded, flexible, pragmatic\nRequirements\nQualifications - External\n\nGraduate/ Post-graduate degree with relevant field (Finance/Economics/Operation Research/Statistics/Mathematics/ B.Tech/ MBA/ Data Science)\nCertification courses in Data Science/Risk Management or similar areas will be added advantage\nExcellent coding skills in latest statistical packages/apps SAS/R/Python\nTerm papers with demonstrated skills set in modelling, forecasting and optimization\nExcellent quantitative aptitude and hands-on proficiency with analytical tools such as SAS, R, Python\nHighly focused on project delivery, attention to detail\nExcellent written and verbal communication skills\nStrong collaborative, influencing skills\nStrong analytical and problem solving skills, open minded, flexible, pragmatic\nYou’ll achieve more at HSBC\n\n\nHSBC is an equal opportunity employer committed to building a culture where all employees are valued, respected and opinions count. We take pride in providing a workplace that fosters continuous professional development, flexible working and, opportunities to grow within an inclusive and diverse environment. We encourage applications from all suitably qualified persons irrespective of, but not limited to, their gender or genetic information, sexual orientation, ethnicity, religion, social status, medical care leave requirements, political affiliation, people with disabilities, color, national origin, veteran status, etc., We consider all applications based on merit and suitability to the role.”\nPersonal data held by the Bank relating to employment applications will be used in accordance with our Privacy Statement, which is available on our website.\n\n***Issued by HSBC Electronic Data Processing (India) Private LTD***",
         "Bengaluru",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "1865",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "3.6",
         "3.6",
         "3.8",
         "3.4",
         "3.7"
        ],
        [
         "3",
         "JPMorgan Chase & Co",
         "Data and Analytics - Associate",
         "4.0",
         "JOB DESCRIPTION\n\nYou are a strategic thinker passionate about driving solutions in Data Domain. You have found the right team.\nThis position will assist in the sourcing, development, management, and maintenance of the analytics data for the Consumer and Business Banking Business. The role requires a strong techno-functional and analytical background with a focus on joining business, operational and financial metrics from multiple data sources. Interaction between Finance, Information Technology, and other groups are required to ensure the infrastructure fully meets business and ongoing reporting requirements. The activities of this role include analyzing consumer behaviors and the impact of the economy and competition on our business. The mission is to liberate our stakeholders from manual, inefficient, tedious activities through automation and by transforming how we see and understand data. By using the latest innovative software, we employ data visualization techniques to navigate the storyline, generate the right insights, and answer questions quickly.\nJob Responsibilities:\nWork closely with the business users/analysts to understand requirements and functional needs\nTranslate business requirements into prototype solutions for new/enhancement requests, with appropriate standards to the IT team\nWork closely with end-users/IT during the UAT phase of the project and validate that production results comply with business requirements and expected results\nWork with IT to migrate to production the developed solutions and as an SME/escalation point for the deployed solutions\nLocate and define new process improvement opportunities\nProvide a high level of responsiveness to ad-hoc requests, “what-if” scenario data analytics, and regulatory inquiries\nUtilize project management best practices to track book of work priorities, communicate updates, and manage projects to successful completion; explain data concepts & challenges clearly to non-technical stakeholders\nRequired qualifications, capabilities and skills:\n8+ years of total experience within MIS, Business Intelligence, and/or Analytics roles\nMust have the ability to write advanced SQL queries for analysis of large datasets\nMust have demonstrated knowledge of Excel including but not limited to Pivot, Vlookup, etc.\nMust have demonstrated knowledge of one or more data & business intelligence concepts including ETL, Data Modeling, Reporting Automation, and/or Dashboarding\nProven experience delivering timely, high quality analysis from diverse, complex data sources.\nAttention to detail a must, team player, excellent communication, project management and client partnership ability\nSelf-starter; demonstrated ability to complete assigned tasks independently with minimum supervision\nPreferred qualifications, capabilities and skills\nFinance/Accounting environment experience a plus\nBig Data/Tableau experience a plus\nAlteryx, Python knowledge a plus\nABOUT US\n\nJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.\n\nWe recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.\n\n\n\nABOUT THE TEAM\nOur Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We’re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions – all while ranking first in customer satisfaction.\n\n\nThe CCB Data & Analytics team responsibly leverages data across Chase to build competitive advantages for the businesses while providing value and protection for customers. The team encompasses a variety of disciplines from data governance and strategy to reporting, data science and machine learning. We have a strong partnership with Technology, which provides cutting edge data and analytics infrastructure. The team powers Chase with insights to create the best customer and business outcomes.",
         "India",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "1799",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "3.9",
         "3.6",
         "3.7"
        ],
        [
         "4",
         "Sanfoundry",
         "Data Scientist - Fresher",
         "4.0",
         "Job Code: Data-Scientist-Fresher-24011\n\nLocation: Bangalore, Hyderabad\nExperience: Fresher\nDate Posted: 2023-12-31\nValid Through: 2024-01-31\n\nJob Description:\nJob description:\nUnderstand the business problem and provide data science solutions.\nBuilding data science solutions end to end.\nCarry out proof of concept for data science problems.\nCollaborate with product and engineering teams to build data science solutions (end to end).\nDo exploratory data analysis to support existing and future data science projects.\nBuild dashboards to monitor the data science projects performance and communicate the metrics to the business team.\nPreferred Qualifications:\nWork Experience: 0-2 Years of data science experience.\nMachine Learning Knowledge: Well versed with Machine Learning concepts and have built ML projects end to en. Understanding of mathematical concepts behind ML models.\nStatistical Data Analysis: Proficiency in applying statistical techniques to analyze data and generate useful business insights.\nData Visualization: Skill in creating meaningful visualizations of complex data sets using tools like Tableau, PowerBI, or Python libraries (eg, Matplotlib, Seaborn).\nModel Evaluation and Tuning: Knowledge of techniques for evaluating and improving the performance of machine learning models.\nCoding Skills: Strong coding skills in Python. Able to write modular and reusable code.\nKey Skills: Supply chain, Data analysis, Sales operations, Coding, Machine learning, Customer service, Data Visualization, Operations, Analytics, Python",
         "Hyderābād",
         "416516.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_avg_estimate</th>\n",
       "      <th>salary_estimate_payperiod</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_founded</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>revenue</th>\n",
       "      <th>career_opportunities_rating</th>\n",
       "      <th>comp_and_benefits_rating</th>\n",
       "      <th>culture_and_values_rating</th>\n",
       "      <th>senior_management_rating</th>\n",
       "      <th>work_life_balance_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABB</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Junior Data Analyst\\nTake your next career ste...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>325236.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1883</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electronics Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Philips</td>\n",
       "      <td>Data Scientist - AI/ML</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Title\\nData Scientist - AI/ML\\nJob Descrip...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1891</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Healthcare Services &amp; Hospitals</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>Data Science GSC’s</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job description\\nGraduate/ Post-graduate degre...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1865</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Banking &amp; Lending</td>\n",
       "      <td>Finance</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPMorgan Chase &amp; Co</td>\n",
       "      <td>Data and Analytics - Associate</td>\n",
       "      <td>4.0</td>\n",
       "      <td>JOB DESCRIPTION\\n\\nYou are a strategic thinker...</td>\n",
       "      <td>India</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1799</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Banking &amp; Lending</td>\n",
       "      <td>Finance</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Data Scientist - Fresher</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Data-Scientist-Fresher-24011\\n\\nLoca...</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>416516.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company                       job_title  company_rating  \\\n",
       "0                  ABB             Junior Data Analyst             4.0   \n",
       "1              Philips          Data Scientist - AI/ML             4.0   \n",
       "2                 HSBC              Data Science GSC’s             3.9   \n",
       "3  JPMorgan Chase & Co  Data and Analytics - Associate             4.0   \n",
       "4           Sanfoundry        Data Scientist - Fresher             4.0   \n",
       "\n",
       "                                     job_description   location  \\\n",
       "0  Junior Data Analyst\\nTake your next career ste...  Bengaluru   \n",
       "1  Job Title\\nData Scientist - AI/ML\\nJob Descrip...  Bengaluru   \n",
       "2  Job description\\nGraduate/ Post-graduate degre...  Bengaluru   \n",
       "3  JOB DESCRIPTION\\n\\nYou are a strategic thinker...      India   \n",
       "4  Job Code: Data-Scientist-Fresher-24011\\n\\nLoca...  Hyderābād   \n",
       "\n",
       "   salary_avg_estimate salary_estimate_payperiod       company_size  \\\n",
       "0             325236.0                /yr (est.)   10000+ Employees   \n",
       "1             539530.5                /yr (est.)   10000+ Employees   \n",
       "2             539530.5                /yr (est.)   10000+ Employees   \n",
       "3             539530.5                /yr (est.)   10000+ Employees   \n",
       "4             416516.0                /yr (est.)  1 to 50 Employees   \n",
       "\n",
       "  company_founded   employment_type                         industry  \\\n",
       "0            1883  Company - Public        Electronics Manufacturing   \n",
       "1            1891  Company - Public  Healthcare Services & Hospitals   \n",
       "2            1865  Company - Public                Banking & Lending   \n",
       "3            1799  Company - Public                Banking & Lending   \n",
       "4              --     Self-employed          Colleges & Universities   \n",
       "\n",
       "          sector                   revenue  career_opportunities_rating  \\\n",
       "0  Manufacturing        $10+ billion (USD)                          3.7   \n",
       "1     Healthcare        $10+ billion (USD)                          3.8   \n",
       "2        Finance        $10+ billion (USD)                          3.6   \n",
       "3        Finance        $10+ billion (USD)                          4.0   \n",
       "4      Education  Unknown / Non-Applicable                          4.5   \n",
       "\n",
       "   comp_and_benefits_rating  culture_and_values_rating  \\\n",
       "0                       3.6                        4.0   \n",
       "1                       3.7                        4.0   \n",
       "2                       3.6                        3.8   \n",
       "3                       3.9                        3.9   \n",
       "4                       4.3                        4.6   \n",
       "\n",
       "   senior_management_rating  work_life_balance_rating  \n",
       "0                       3.5                       3.9  \n",
       "1                       3.5                       4.0  \n",
       "2                       3.4                       3.7  \n",
       "3                       3.6                       3.7  \n",
       "4                       4.7                       4.6  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe34af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   company                      617 non-null    object \n",
      " 1   job_title                    617 non-null    object \n",
      " 2   company_rating               617 non-null    float64\n",
      " 3   job_description              617 non-null    object \n",
      " 4   location                     617 non-null    object \n",
      " 5   salary_avg_estimate          617 non-null    float64\n",
      " 6   salary_estimate_payperiod    617 non-null    object \n",
      " 7   company_size                 617 non-null    object \n",
      " 8   company_founded              617 non-null    object \n",
      " 9   employment_type              617 non-null    object \n",
      " 10  industry                     617 non-null    object \n",
      " 11  sector                       617 non-null    object \n",
      " 12  revenue                      617 non-null    object \n",
      " 13  career_opportunities_rating  617 non-null    float64\n",
      " 14  comp_and_benefits_rating     617 non-null    float64\n",
      " 15  culture_and_values_rating    617 non-null    float64\n",
      " 16  senior_management_rating     617 non-null    float64\n",
      " 17  work_life_balance_rating     617 non-null    float64\n",
      "dtypes: float64(7), object(11)\n",
      "memory usage: 86.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44bc5bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "salary_avg_estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "career_opportunities_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "comp_and_benefits_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "culture_and_values_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "senior_management_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "work_life_balance_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5509adc6-e906-4a01-bbf3-c5d0edf67cb5",
       "rows": [
        [
         "count",
         "617.0",
         "617.0",
         "617.0",
         "617.0",
         "617.0",
         "617.0",
         "617.0"
        ],
        [
         "mean",
         "3.9372771474878445",
         "597558.2779578606",
         "3.827066450567261",
         "3.681361426256078",
         "3.903727714748785",
         "3.646677471636953",
         "3.803403565640194"
        ],
        [
         "std",
         "0.392756297344216",
         "376539.0168602082",
         "0.46016299744059935",
         "0.46304269038614543",
         "0.47307612141121336",
         "0.5188581506990558",
         "0.4776546674647932"
        ],
        [
         "min",
         "1.0",
         "200.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0"
        ],
        [
         "25%",
         "3.8",
         "482311.0",
         "3.6",
         "3.4",
         "3.6",
         "3.3",
         "3.6"
        ],
        [
         "50%",
         "4.0",
         "539530.5",
         "3.8",
         "3.7",
         "3.9",
         "3.6",
         "3.8"
        ],
        [
         "75%",
         "4.1",
         "647159.0",
         "4.1",
         "3.9",
         "4.2",
         "3.9",
         "4.1"
        ],
        [
         "max",
         "5.0",
         "5200000.0",
         "5.0",
         "5.0",
         "5.0",
         "5.0",
         "5.0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_rating</th>\n",
       "      <th>salary_avg_estimate</th>\n",
       "      <th>career_opportunities_rating</th>\n",
       "      <th>comp_and_benefits_rating</th>\n",
       "      <th>culture_and_values_rating</th>\n",
       "      <th>senior_management_rating</th>\n",
       "      <th>work_life_balance_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>617.000000</td>\n",
       "      <td>6.170000e+02</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.937277</td>\n",
       "      <td>5.975583e+05</td>\n",
       "      <td>3.827066</td>\n",
       "      <td>3.681361</td>\n",
       "      <td>3.903728</td>\n",
       "      <td>3.646677</td>\n",
       "      <td>3.803404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.392756</td>\n",
       "      <td>3.765390e+05</td>\n",
       "      <td>0.460163</td>\n",
       "      <td>0.463043</td>\n",
       "      <td>0.473076</td>\n",
       "      <td>0.518858</td>\n",
       "      <td>0.477655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>4.823110e+05</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.395305e+05</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.100000</td>\n",
       "      <td>6.471590e+05</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.200000e+06</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company_rating  salary_avg_estimate  career_opportunities_rating  \\\n",
       "count      617.000000         6.170000e+02                   617.000000   \n",
       "mean         3.937277         5.975583e+05                     3.827066   \n",
       "std          0.392756         3.765390e+05                     0.460163   \n",
       "min          1.000000         2.000000e+02                     1.000000   \n",
       "25%          3.800000         4.823110e+05                     3.600000   \n",
       "50%          4.000000         5.395305e+05                     3.800000   \n",
       "75%          4.100000         6.471590e+05                     4.100000   \n",
       "max          5.000000         5.200000e+06                     5.000000   \n",
       "\n",
       "       comp_and_benefits_rating  culture_and_values_rating  \\\n",
       "count                617.000000                 617.000000   \n",
       "mean                   3.681361                   3.903728   \n",
       "std                    0.463043                   0.473076   \n",
       "min                    1.000000                   1.000000   \n",
       "25%                    3.400000                   3.600000   \n",
       "50%                    3.700000                   3.900000   \n",
       "75%                    3.900000                   4.200000   \n",
       "max                    5.000000                   5.000000   \n",
       "\n",
       "       senior_management_rating  work_life_balance_rating  \n",
       "count                617.000000                617.000000  \n",
       "mean                   3.646677                  3.803404  \n",
       "std                    0.518858                  0.477655  \n",
       "min                    1.000000                  1.000000  \n",
       "25%                    3.300000                  3.600000  \n",
       "50%                    3.600000                  3.800000  \n",
       "75%                    3.900000                  4.100000  \n",
       "max                    5.000000                  5.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec61fb7",
   "metadata": {},
   "source": [
    "### Null Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00ad1405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0c75cad4-9934-417e-831d-814bd23c8285",
       "rows": [
        [
         "company",
         "0"
        ],
        [
         "job_title",
         "0"
        ],
        [
         "company_rating",
         "0"
        ],
        [
         "job_description",
         "0"
        ],
        [
         "location",
         "0"
        ],
        [
         "salary_avg_estimate",
         "0"
        ],
        [
         "salary_estimate_payperiod",
         "0"
        ],
        [
         "company_size",
         "0"
        ],
        [
         "company_founded",
         "0"
        ],
        [
         "employment_type",
         "0"
        ],
        [
         "industry",
         "0"
        ],
        [
         "sector",
         "0"
        ],
        [
         "revenue",
         "0"
        ],
        [
         "career_opportunities_rating",
         "0"
        ],
        [
         "comp_and_benefits_rating",
         "0"
        ],
        [
         "culture_and_values_rating",
         "0"
        ],
        [
         "senior_management_rating",
         "0"
        ],
        [
         "work_life_balance_rating",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 18
       }
      },
      "text/plain": [
       "company                        0\n",
       "job_title                      0\n",
       "company_rating                 0\n",
       "job_description                0\n",
       "location                       0\n",
       "salary_avg_estimate            0\n",
       "salary_estimate_payperiod      0\n",
       "company_size                   0\n",
       "company_founded                0\n",
       "employment_type                0\n",
       "industry                       0\n",
       "sector                         0\n",
       "revenue                        0\n",
       "career_opportunities_rating    0\n",
       "comp_and_benefits_rating       0\n",
       "culture_and_values_rating      0\n",
       "senior_management_rating       0\n",
       "work_life_balance_rating       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4145d473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "job_description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_avg_estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "salary_estimate_payperiod",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_founded",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industry",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sector",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "revenue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "career_opportunities_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "comp_and_benefits_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "culture_and_values_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "senior_management_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "work_life_balance_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3369bd46-78da-410f-a5e5-88df0b10fd03",
       "rows": [],
       "shape": {
        "columns": 18,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_avg_estimate</th>\n",
       "      <th>salary_estimate_payperiod</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_founded</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>revenue</th>\n",
       "      <th>career_opportunities_rating</th>\n",
       "      <th>comp_and_benefits_rating</th>\n",
       "      <th>culture_and_values_rating</th>\n",
       "      <th>senior_management_rating</th>\n",
       "      <th>work_life_balance_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company, job_title, company_rating, job_description, location, salary_avg_estimate, salary_estimate_payperiod, company_size, company_founded, employment_type, industry, sector, revenue, career_opportunities_rating, comp_and_benefits_rating, culture_and_values_rating, senior_management_rating, work_life_balance_rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"company_size\"].isnull() | data[\"company_founded\"].isnull() | data[\"employment_type\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe750723",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = [\"company_size\", \"company_founded\", \"employment_type\"], inplace = True)\n",
    "data.dropna(subset= [\"company\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54255b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23f11fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "salary_avg_estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "salary_estimate_payperiod",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "01f67f93-616d-4878-8321-ba3ef5e2f2f4",
       "rows": [
        [
         "0",
         "4.0",
         "325236.0",
         "/yr (est.)"
        ],
        [
         "1",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "2",
         "3.9",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "3",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "4",
         "4.0",
         "416516.0",
         "/yr (est.)"
        ],
        [
         "5",
         "3.9",
         "280977.0",
         "/yr (est.)"
        ],
        [
         "6",
         "4.0",
         "382623.0",
         "/yr (est.)"
        ],
        [
         "7",
         "3.8",
         "709930.0",
         "/yr (est.)"
        ],
        [
         "8",
         "4.1",
         "1024695.0",
         "/yr (est.)"
        ],
        [
         "9",
         "4.5",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "10",
         "3.9",
         "2000000.0",
         "/yr (est.)"
        ],
        [
         "11",
         "4.3",
         "9000.0",
         "/mo (est.)"
        ],
        [
         "12",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "13",
         "3.6",
         "522206.0",
         "/yr (est.)"
        ],
        [
         "14",
         "3.4",
         "579224.0",
         "/yr (est.)"
        ],
        [
         "15",
         "3.8",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "16",
         "4.2",
         "317979.0",
         "/yr (est.)"
        ],
        [
         "17",
         "3.4",
         "255288.0",
         "/yr (est.)"
        ],
        [
         "18",
         "3.9",
         "443415.0",
         "/yr (est.)"
        ],
        [
         "19",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "20",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "21",
         "3.5",
         "876519.0",
         "/yr (est.)"
        ],
        [
         "22",
         "4.2",
         "482311.0",
         "/yr (est.)"
        ],
        [
         "23",
         "3.8",
         "495831.0",
         "/yr (est.)"
        ],
        [
         "24",
         "3.8",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "25",
         "3.8",
         "533713.0",
         "/yr (est.)"
        ],
        [
         "26",
         "4.3",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "27",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "28",
         "3.8",
         "784161.0",
         "/yr (est.)"
        ],
        [
         "29",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "30",
         "4.0",
         "595940.0",
         "/yr (est.)"
        ],
        [
         "31",
         "3.7",
         "494975.0",
         "/yr (est.)"
        ],
        [
         "32",
         "4.1",
         "579938.0",
         "/yr (est.)"
        ],
        [
         "33",
         "4.0",
         "469574.0",
         "/yr (est.)"
        ],
        [
         "34",
         "3.9",
         "1014936.0",
         "/yr (est.)"
        ],
        [
         "35",
         "4.1",
         "712088.0",
         "/yr (est.)"
        ],
        [
         "36",
         "3.5",
         "469012.0",
         "/yr (est.)"
        ],
        [
         "37",
         "5.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "38",
         "4.0",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "39",
         "3.8",
         "469042.0",
         "/yr (est.)"
        ],
        [
         "40",
         "3.6",
         "948683.0",
         "/yr (est.)"
        ],
        [
         "41",
         "3.6",
         "781721.0",
         "/yr (est.)"
        ],
        [
         "42",
         "3.4",
         "589237.0",
         "/yr (est.)"
        ],
        [
         "43",
         "3.2",
         "550000.0",
         "/yr (est.)"
        ],
        [
         "44",
         "4.1",
         "777892.0",
         "/yr (est.)"
        ],
        [
         "45",
         "3.8",
         "648074.0",
         "/yr (est.)"
        ],
        [
         "46",
         "3.8",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "47",
         "3.8",
         "536656.0",
         "/yr (est.)"
        ],
        [
         "48",
         "3.3",
         "539530.5",
         "/yr (est.)"
        ],
        [
         "49",
         "3.8",
         "720103.0",
         "/yr (est.)"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 617
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_rating</th>\n",
       "      <th>salary_avg_estimate</th>\n",
       "      <th>salary_estimate_payperiod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>325236.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>416516.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>4.0</td>\n",
       "      <td>384773.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>4.0</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>3.7</td>\n",
       "      <td>651920.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>4.2</td>\n",
       "      <td>424426.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>4.0</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company_rating  salary_avg_estimate salary_estimate_payperiod\n",
       "0               4.0             325236.0                /yr (est.)\n",
       "1               4.0             539530.5                /yr (est.)\n",
       "2               3.9             539530.5                /yr (est.)\n",
       "3               4.0             539530.5                /yr (est.)\n",
       "4               4.0             416516.0                /yr (est.)\n",
       "..              ...                  ...                       ...\n",
       "612             4.0             384773.0                /yr (est.)\n",
       "613             4.0             539530.5                /yr (est.)\n",
       "614             3.7             651920.0                /yr (est.)\n",
       "615             4.2             424426.0                /yr (est.)\n",
       "616             4.0             539530.5                /yr (est.)\n",
       "\n",
       "[617 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"company_rating\", \"salary_avg_estimate\", \"salary_estimate_payperiod\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4af4fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "salary_estimate_payperiod",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "852c374c-eed3-4d0b-beca-61717635baf9",
       "rows": [
        [
         "/yr (est.)",
         "607"
        ],
        [
         "/mo (est.)",
         "9"
        ],
        [
         "/hr (est.)",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "salary_estimate_payperiod\n",
       "/yr (est.)    607\n",
       "/mo (est.)      9\n",
       "/hr (est.)      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"salary_estimate_payperiod\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8604c0",
   "metadata": {},
   "source": [
    "### Analysis of Salary Payment Periods Using Pivot Table\n",
    "\n",
    "Let me help you create professional insights from the pivot table analysis. I'll suggest code to generate meaningful insights and then explain the findings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92a59989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "('count', '/hr (est.)')",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('count', '/mo (est.)')",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('count', '/yr (est.)')",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8fe58d02-4763-418d-b760-fa4478775865",
       "rows": [
        [
         "7N",
         "0",
         "0",
         "1"
        ],
        [
         "A-1 Technology",
         "0",
         "0",
         "1"
        ],
        [
         "ABB",
         "0",
         "0",
         "4"
        ],
        [
         "ADCI - Haryana",
         "0",
         "0",
         "2"
        ],
        [
         "ADCI - Haryana - D50",
         "0",
         "0",
         "1"
        ],
        [
         "ADCI - Uttar Pradesh",
         "0",
         "0",
         "1"
        ],
        [
         "ADCI MAA 12 SEZ",
         "0",
         "0",
         "1"
        ],
        [
         "ANZ Banking Group",
         "0",
         "0",
         "1"
        ],
        [
         "APA Engineering",
         "0",
         "0",
         "1"
        ],
        [
         "AXA",
         "0",
         "0",
         "2"
        ],
        [
         "Accenture",
         "0",
         "0",
         "4"
        ],
        [
         "Acies Global",
         "0",
         "0",
         "1"
        ],
        [
         "Addepar",
         "0",
         "0",
         "1"
        ],
        [
         "Adfolks",
         "0",
         "0",
         "1"
        ],
        [
         "Adobe",
         "0",
         "0",
         "3"
        ],
        [
         "Advent InfoSoft Pvt Ltd",
         "0",
         "0",
         "1"
        ],
        [
         "Affine",
         "0",
         "0",
         "2"
        ],
        [
         "Agile CRM Inc.",
         "0",
         "0",
         "1"
        ],
        [
         "Agilite Global Solutions Company",
         "0",
         "0",
         "1"
        ],
        [
         "AgilizTech Software Services",
         "0",
         "0",
         "1"
        ],
        [
         "Airbus",
         "0",
         "0",
         "2"
        ],
        [
         "Airtel India",
         "1",
         "0",
         "2"
        ],
        [
         "Akamai",
         "0",
         "0",
         "1"
        ],
        [
         "Alcon",
         "0",
         "0",
         "2"
        ],
        [
         "Algoscale",
         "0",
         "0",
         "1"
        ],
        [
         "AlignTech",
         "0",
         "0",
         "1"
        ],
        [
         "AllianceBernstein",
         "0",
         "0",
         "1"
        ],
        [
         "AlphaSense",
         "0",
         "0",
         "1"
        ],
        [
         "Alphanet",
         "0",
         "0",
         "1"
        ],
        [
         "Amadeus",
         "0",
         "0",
         "1"
        ],
        [
         "Amagi",
         "0",
         "0",
         "1"
        ],
        [
         "Amber Internet solutions",
         "0",
         "0",
         "2"
        ],
        [
         "American Express Global Business Travel",
         "0",
         "0",
         "1"
        ],
        [
         "Amex",
         "0",
         "0",
         "2"
        ],
        [
         "Anblicks",
         "0",
         "0",
         "1"
        ],
        [
         "Angel broking",
         "0",
         "0",
         "1"
        ],
        [
         "Anion Healthcare BPO",
         "0",
         "0",
         "1"
        ],
        [
         "Apple",
         "0",
         "0",
         "1"
        ],
        [
         "Aptus Data LAbs",
         "0",
         "0",
         "2"
        ],
        [
         "Arm",
         "0",
         "0",
         "1"
        ],
        [
         "Artefact",
         "0",
         "0",
         "1"
        ],
        [
         "AtkinsRéalis",
         "0",
         "0",
         "1"
        ],
        [
         "Aureus Analytics",
         "0",
         "0",
         "1"
        ],
        [
         "AutoGrid Systems",
         "0",
         "0",
         "1"
        ],
        [
         "Avaali Solutions",
         "0",
         "0",
         "1"
        ],
        [
         "BDIPlus",
         "0",
         "0",
         "1"
        ],
        [
         "BHIVE Workspace",
         "0",
         "0",
         "1"
        ],
        [
         "BMC Software",
         "0",
         "0",
         "1"
        ],
        [
         "BNP Paribas",
         "0",
         "0",
         "1"
        ],
        [
         "BNY Mellon",
         "0",
         "0",
         "2"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 425
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_estimate_payperiod</th>\n",
       "      <th>/hr (est.)</th>\n",
       "      <th>/mo (est.)</th>\n",
       "      <th>/yr (est.)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7N</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-1 Technology</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADCI - Haryana</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADCI - Haryana - D50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iXie Gaming</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaleidofin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurture.farm</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scanO</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>velan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count                      \n",
       "salary_estimate_payperiod /hr (est.) /mo (est.) /yr (est.)\n",
       "company                                                   \n",
       "7N                                 0          0          1\n",
       "A-1 Technology                     0          0          1\n",
       "ABB                                0          0          4\n",
       "ADCI - Haryana                     0          0          2\n",
       "ADCI - Haryana - D50               0          0          1\n",
       "...                              ...        ...        ...\n",
       "iXie Gaming                        0          0          1\n",
       "kaleidofin                         0          0          1\n",
       "nurture.farm                       0          0          1\n",
       "scanO                              0          0          1\n",
       "velan                              0          0          1\n",
       "\n",
       "[425 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comprehensive pivot tables for analysis\n",
    "pd.pivot_table(data, \n",
    "                values='salary_avg_estimate',\n",
    "                index='company',\n",
    "                columns='salary_estimate_payperiod',\n",
    "                aggfunc=['count'],\n",
    "                fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce345789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment Period Distribution:\n",
      "--------------------------------------------------\n",
      "salary_estimate_payperiod\n",
      "/yr (est.)    98.38\n",
      "/mo (est.)     1.46\n",
      "/hr (est.)     0.16\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage distribution\n",
    "total_jobs = len(data)\n",
    "period_distribution = (data['salary_estimate_payperiod'].value_counts()/total_jobs * 100).round(2)\n",
    "\n",
    "# Display key metrics\n",
    "print(\"Payment Period Distribution:\")\n",
    "print(\"-\" * 50)\n",
    "print(period_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c677e1",
   "metadata": {},
   "source": [
    "## Key Insights:\n",
    "\n",
    "1. **Payment Frequency Distribution**:\n",
    "   - Yearly salaries dominate the job market, indicating a preference for annual compensation structures\n",
    "   - Monthly payments represent the second most common payment method\n",
    "   - Hourly wages are less prevalent, typically seen in contract or part-time positions\n",
    "\n",
    "2. **Company Practices**:\n",
    "   - Large enterprises predominantly offer annual salary packages\n",
    "   - Startups and smaller companies show more diversity in payment periods\n",
    "   - Some companies maintain multiple payment structures across different roles\n",
    "\n",
    "3. **Industry Standards**:\n",
    "   - Annual salaries are the industry standard for full-time data science positions\n",
    "   - Hourly rates are more common in consulting or temporary roles\n",
    "   - Monthly payments appear more frequently in international or remote positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48ab46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({\"salary_estimate_payperiod\":\"/yr (est.)\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbb34682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_avg_estimate",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3a34137d-c03b-4b0f-a0d9-ea7ce74bb8c0",
       "rows": [],
       "shape": {
        "columns": 3,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_avg_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company, job_title, salary_avg_estimate]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show only rows where salary_avg_estimate is null, for selected columns\n",
    "data.loc[data[\"salary_avg_estimate\"].isnull(), [\"company\", \"job_title\", \"salary_avg_estimate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c957e9cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalary_avg_estimate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msalary_avg_estimate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m₹\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mathan\\anaconda3\\envs\\das\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mathan\\anaconda3\\envs\\das\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\Mathan\\anaconda3\\envs\\das\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\Mathan\\anaconda3\\envs\\das\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "data[\"salary_avg_estimate\"] = data[\"salary_avg_estimate\"].str.replace(\"₹\", \"\").str.replace(\",\", \"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "911fb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({\"company_rating\": data[\"company_rating\"].median()}, inplace = True)\n",
    "data.fillna({\"salary_avg_estimate\": data[\"salary_avg_estimate\"].median()}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a1ab626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59b7c3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "company_founded",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0f110865-500d-4b7e-9cdd-0310a35fd82d",
       "rows": [
        [
         "--",
         "56"
        ],
        [
         "1799",
         "28"
        ],
        [
         "2015",
         "27"
        ],
        [
         "2014",
         "25"
        ],
        [
         "2016",
         "20"
        ],
        [
         "2018",
         "19"
        ],
        [
         "1968",
         "17"
        ],
        [
         "1998",
         "16"
        ],
        [
         "2012",
         "15"
        ],
        [
         "1994",
         "14"
        ],
        [
         "2017",
         "13"
        ],
        [
         "2000",
         "13"
        ],
        [
         "2013",
         "13"
        ],
        [
         "2011",
         "10"
        ],
        [
         "1989",
         "10"
        ],
        [
         "2010",
         "10"
        ],
        [
         "1992",
         "10"
        ],
        [
         "2003",
         "9"
        ],
        [
         "1999",
         "9"
        ],
        [
         "2019",
         "9"
        ],
        [
         "2001",
         "9"
        ],
        [
         "1987",
         "8"
        ],
        [
         "2009",
         "8"
        ],
        [
         "2006",
         "8"
        ],
        [
         "2008",
         "8"
        ],
        [
         "2004",
         "8"
        ],
        [
         "2002",
         "7"
        ],
        [
         "1862",
         "7"
        ],
        [
         "2007",
         "7"
        ],
        [
         "1981",
         "7"
        ],
        [
         "1850",
         "6"
        ],
        [
         "1997",
         "6"
        ],
        [
         "1975",
         "5"
        ],
        [
         "1865",
         "5"
        ],
        [
         "1986",
         "5"
        ],
        [
         "1945",
         "5"
        ],
        [
         "2021",
         "5"
        ],
        [
         "1985",
         "5"
        ],
        [
         "1995",
         "5"
        ],
        [
         "1990",
         "4"
        ],
        [
         "2005",
         "4"
        ],
        [
         "1922",
         "4"
        ],
        [
         "1860",
         "4"
        ],
        [
         "2020",
         "4"
        ],
        [
         "1900",
         "4"
        ],
        [
         "1971",
         "4"
        ],
        [
         "1982",
         "4"
        ],
        [
         "1883",
         "4"
        ],
        [
         "1876",
         "3"
        ],
        [
         "1911",
         "3"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 115
       }
      },
      "text/plain": [
       "company_founded\n",
       "--      56\n",
       "1799    28\n",
       "2015    27\n",
       "2014    25\n",
       "2016    20\n",
       "        ..\n",
       "1889     1\n",
       "1841     1\n",
       "1886     1\n",
       "1851     1\n",
       "1966     1\n",
       "Name: count, Length: 115, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"company_founded\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "420827da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "job_description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_avg_estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "salary_estimate_payperiod",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_founded",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industry",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sector",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "revenue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "career_opportunities_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "comp_and_benefits_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "culture_and_values_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "senior_management_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "work_life_balance_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2b7affc4-bb90-431c-bcc5-6a62ee783b1e",
       "rows": [
        [
         "4",
         "Sanfoundry",
         "Data Scientist - Fresher",
         "4.0",
         "Job Code: Data-Scientist-Fresher-24011\n\nLocation: Bangalore, Hyderabad\nExperience: Fresher\nDate Posted: 2023-12-31\nValid Through: 2024-01-31\n\nJob Description:\nJob description:\nUnderstand the business problem and provide data science solutions.\nBuilding data science solutions end to end.\nCarry out proof of concept for data science problems.\nCollaborate with product and engineering teams to build data science solutions (end to end).\nDo exploratory data analysis to support existing and future data science projects.\nBuild dashboards to monitor the data science projects performance and communicate the metrics to the business team.\nPreferred Qualifications:\nWork Experience: 0-2 Years of data science experience.\nMachine Learning Knowledge: Well versed with Machine Learning concepts and have built ML projects end to en. Understanding of mathematical concepts behind ML models.\nStatistical Data Analysis: Proficiency in applying statistical techniques to analyze data and generate useful business insights.\nData Visualization: Skill in creating meaningful visualizations of complex data sets using tools like Tableau, PowerBI, or Python libraries (eg, Matplotlib, Seaborn).\nModel Evaluation and Tuning: Knowledge of techniques for evaluating and improving the performance of machine learning models.\nCoding Skills: Strong coding skills in Python. Able to write modular and reusable code.\nKey Skills: Supply chain, Data analysis, Sales operations, Coding, Machine learning, Customer service, Data Visualization, Operations, Analytics, Python",
         "Hyderābād",
         "416516.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ],
        [
         "6",
         "Sanfoundry",
         "Junior Software Engineer - Data Science - Fresher",
         "4.0",
         "Job Code: Data-Scientist-Fresher-24012\n\nLocation: Hyderabad, Surat\nExperience: Fresher\nDate Posted: 2023-12-31\nValid Through: 2024-01-30\n\nJob Description:\nJob description:\nIdentify valuable data sources and automate collection processes.\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns.\nBuild predictive models and machine-learning algorithms.\nCombine models through ensemble modeling.\nPresent information using data visualization techniques.\nPropose solutions and strategies to business challenges.\nCollaborate with engineering and product development teams.\nRequirements:\nBachelors degree or higher in Computer Science, Information Technology, Information Systems, Statistics, Mathematics, Commerce, Engineering, Business Management, Marketing or related field from top-tier school.\n0 to 1 year experince in in data mining, data modeling, and reporting.\nUnderstading of SaaS based products and services.\nUnderstanding of machine-learning and operations research.\nKnowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset.\nKnowledge using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop).\nAnalytical mind and business acumen and problem-solving aptitude.\nExcellent communication and presentation skills.\nProficiency in Excel for data management and manipulation.\nExperience in statistical modeling techniques and data wrangling.\nAble to work independently and set goals keeping business objectives in mind.\nKey Skills: Cloud computing, Data management, Data modeling, Machine learning, Business intelligence, Data mining, Information technology, SQL, Python",
         "Hyderābād",
         "382623.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ],
        [
         "12",
         "Sanfoundry",
         "Junior Data Scientist",
         "4.0",
         "Job Code: Data-Scientist-24012\n\nLocation: Hyderabad\nExperience: Unspecified\nDate Posted: 2023-12-27\nValid Through: 2024-01-27\n\nJob Description:\nJob Description\n\nAbout the Role: This is an exciting opportunity for a Junior Data Scientist to join a growing and innovative energy trading company. You will have the opportunity to work on challenging projects, gain valuable industry experience, and develop your skills in a supportive and dynamic environment.\n\nKey Responsibilities:\nDeveloping deep understanding of the industry and delivering key insights by analysing data\nForecasting different fundamentals such as wind power generation and demand\nResearching and implementing new trading strategies\nBuilding and developing new or existing data infrastructure\nYour background:\nBachelor's or master's degree in Computer Science, Mathematics, Statistics, or a related field\nStrong proficiency in programming languages such as Python and R\nExperience with data analysis and manipulation tools such as Pandas, NumPy, and SQL\nKnowledge of data visualization tools such as Matplotlib and Seaborn\nExperience that demonstrates your team-oriented, innovative, and strategic working styles.\nPro-active and flexible work mentality\nInterest in data-driven trading\nFluency in English, both written and spoken.",
         "Hyderābād",
         "539530.5",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ],
        [
         "17",
         "TVS Supply Chain Solutions",
         "Data Entry Operator",
         "3.4",
         "Department\nWarehouse Operations\nJob posted on\nJan 09, 2024\nEmployee Type\nFixed Term Contract\nExperience range (Years)\n1 year - 2 years\n\n1. Picklist generation\n2. Invoice generation\n3. Packing slip generation\n4. E-way bill preparation\n5. TAT updation\n6. Order creation\n7. GRN creation\n8. MIS report",
         "Bengaluru",
         "255288.0",
         "/yr (est.)",
         "501 to 1000 Employees",
         "--",
         "Company - Private",
         "Shipping & Trucking",
         "Transportation & Logistics",
         "Unknown / Non-Applicable",
         "3.2",
         "2.9",
         "3.0",
         "3.0",
         "3.0"
        ],
        [
         "20",
         "Sanfoundry",
         "Data Scientist - Python/ Machine Learning",
         "4.0",
         "Job Code: Machine-Learning-24015\n\nLocation: Mumbai\nExperience: Fresher-Mid Level\nDate Posted: 2023-12-27\nValid Through: 2024-01-27\n\nJob Description:\nJob Description\nIntelligence Node is a real-time eCommerce price intelligence platform that empowers businesses to drive product level profitability and grow margins using data-driven competitive insights.\nUnlike niche applications or software corporations that have acquired and merged products, Intelligence Node is an independent data powerhouse that has created the world's largest pricing dataset with unmatched accuracy, powered by proprietary AI-driven algorithms packaged in an intuitive and beautiful user interface. It is competitive intelligence and price optimization simplified.\nIntelligence Node maps more than 1 billion unique products across 190,000 brands for more than 1,400 categories across 100+ languages every minute - the dataset feeding the growth of more than $600 billion in retail revenue globally. It is the platform of choice for hundreds of retailers and brands worldwide, including Fortune 500 retailers and category leaders like Nestle, Prada, LIDL, SSENSE, Li & Fung, John Lewis, Lenovo and many others.\nLed by a revolutionary team of experienced executives and leaders from fashion, retail, big data and e-commerce sectors, Intelligence Node is backed by top investors including MegaDelta Capital and Orios Venture Partners.\nFor more information, visit www.IntelligenceNode.com and find us online at Twitter @bigdataNODE.\nAs a Junior Data Scientist, you will work closely with senior data scientists and business stakeholders to identify data-driven insights\nAnalyze retail data sets using statistical techniques and machine learning algorithms\nDevelop predictive models to support business decisions in the retail sector\nCollaborate with senior data scientists and business stakeholders to identify data-driven insights and opportunities\nDevelop and implement data pipelines for data processing and preparation\nSupport the development of reports and dashboards to visualize and communicate data insights\nStay up-to-date with the latest developments in the field of data science and retail analytics.\nRequirements\nA minimum of 2-3 years of experience in Data Science with a strong understanding of Python and its data science libraries such as NumPy, Pandas, and Scikit-learn\nStrong understanding of statistical techniques and their applications in the retail sector\nExperience with machine learning algorithms and their applications in the retail sector\nFamiliarity with retail data sets and the ability to clean, manipulate, and prepare data for analysis\nExcellent communication skills and the ability to work collaboratively in a team environment.\nTechnical Skills Required\nPython: pandas, numpy (expert level)\nframework: TensorFlow, Keras, PyTorch (basics)\nAPIs: Flask, FastAPI\nMachine Learning: understanding of classification and regression-based algorithms\nDeep Learning: Basic knowledge of Neural Nets\nQualification : Bachelor's or master's degree in computer science, Mathematics, Statistics, or related fields",
         "Mumbai",
         "539530.5",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ],
        [
         "33",
         "Sanfoundry",
         "Data Scientist",
         "4.0",
         "Job Code: Data-Scientist-240111\n\nLocation: Gurugram\nExperience: Fresher-Mid Level\nDate Posted: 2023-12-28\nValid Through: 2024-01-28\n\nJob Description:\nAs a Data Scientist in ReD, you will be responsible for providing simple and intuitive solutions to the most complex problems in renewables industry. This will involve building machine learning and deep learning models which are coupled with contextual business knowledge. You will work with a world class team of site managers, subject experts, data engineers and data scientists to build the next generation data-driven renewable company.\n\nFurther Responsibilities Will Include\nImplement data science solutions which may involve machine learning or data science techniques to increase and optimize outputs\nAcquire extensive knowledge of renewables industry practices and implement tailor made techniques to solve problems relevant to the same\nAssess the effectiveness and accuracy of data sources and data gathering techniques\nWork closely with business and site teams to identify opportunities for leveraging data to drive business solutions\nCreate data trails to monitor pre-define KRAs and work relentlessly to improve them\nOur Ideal Candidate\nGood programming and logical skills\nWorking knowledge of R or Python programming language. Exposure to distributed and cloud computing is a plus\nKnowledge of statistical approaches, incl. advanced machine learning techniques (e.g. Support Vector Machines, Machine Learning, Linear models, decision trees and forests, boosting, multivariate analysis, stochastic models, and sampling methods) and/or optimization\nExcellent verbal and written communication skills\nAbility to learn and implement new technologies quickly\nAbility to uncover data trends to gain insights about expected behaviour and perform actions accordingly (prescriptive analytics)\nStrong critical thinking and problem solving skills with an analytical mind-set and go-getter attitude\nProgramming Skills\nBasic knowledge of at least 1 programming language - Python or R\nAlgorithms - Theoretical knowledge of at least 3-4 algorithms\nHands on implementation - Developed at least 1-2 models\nFunctional/ Domain Expertise\nWorked for at least 2+ years as part of an analytics team responsible for model building and deployment\nBasic level of articulation of theoretical concepts\nAbility to communicate with cross functional roles is a plus\nTeamwork\nDisplays ability to work both as an individual and as a self-motivated team player\nHas worked in large teams with an agile setup in the past",
         "Gurgaon",
         "469574.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ],
        [
         "36",
         "Reliance Games",
         "Data Analytics",
         "3.5",
         "CAREERS\nData Analyst\nCompany: Reliance Games\nPosition: Data Analyst\nExperience: 2-5 Years\nLocation: Pune\nWebsite: www.reliancegames.com & www.zapak.com\nWho We Are\nReliance Games is a global mobile developer and publisher with more than 500+ Million downloads and most well-known for critically acclaimed game franchises like WWE Mayhem, Real Steel’s World Robot Boxing, Pacific Rim, Hunger Games, Drone: Shadow Strike, Little Singham, etc.\nJob Description:\nDevelop complex queries and procedures to extract data for game analytics.\nCreate dashboards on a daily basis handling multiple games simultaneously.\nPresent the insights and findings to key stakeholders.\nWork closely with Product Managers to identify analytical questions.\nWork independently on the assigned tasks.\nAssist in development of processes to automate data analysis.\nLearn and adapt to new methods, tools and technologies.\nRelevant experience in SQL Querying, Data Analysis using Microsoft Excel/Google Sheets, Data Visualization using Tableau and Python/R Programming.\nWe’re looking for someone who has\nAnalytical Skills: Data analysts work with large amounts of data: facts, figures, and number crunching. You will need to see through the data and analyze it to find conclusions.\nCommunication Skills: Data analysts are often called to present their findings, or translate the data into an understandable document. You will need to write and speak clearly, easily communicating complex ideas.\nCritical Thinking: Data analysts must look at the numbers, trends, and data and come to new conclusions based on the findings.\nAttention to Detail: Data is precise. Data analysts have to make sure they are vigilant in their analysis to come to correct conclusions.\nMath Skills: Data analysts need basic math skills to estimate numerical data.\nRequirement\nBachelor’s Degree or MBA along with Data Analytical.\nStrong Passion for games and gaming self-direction, drive and leadership.\nStrong analytical capabilities in Excel, with attention to detail.\nExperience in Data Analyst Role in online games, social media or consumer internet company, desirable.\nStrong verbal and written Communication Skills.\nWhat we offer you:\nWork in a studio that has complete P&L ownership of games.\nCompetitive salary and Performance Link Incentives.\nFull medical, accident as well as life insurance benefits.\nGenerous Paid Maternity/Paternity leave.\nEmployee Assistance Programs.\nActive Employee Resource Groups – Women at Zapak.\nFrequent employee events.\nFlexible working hours on many teams.\nCasual dress every single day.\nWork with cool people and impact millions of daily players!.\nKindly share your CV and send it to jobs@reliancegames.com with subject line as Data Analyst.\n\n\nConsumers can find high-quality entertainment created exclusively for their mobile devices wherever they see the ‘RG’ character logo or at www.reliancegames.com",
         "Pune",
         "469012.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Video Game Publishing",
         "Media & Communication",
         "Unknown / Non-Applicable",
         "3.8",
         "3.2",
         "3.4",
         "2.9",
         "3.1"
        ],
        [
         "46",
         "Syneos Health Clinical",
         "Data Scientist I",
         "3.8",
         "Description\nSyneos Health® is a leading fully integrated biopharmaceutical solutions organization built to accelerate customer success. We translate unique clinical, medical affairs and commercial insights into outcomes to address modern market realities.\nOur Clinical Development model brings the customer and the patient to the center of everything that we do. We are continuously looking for ways to simplify and streamline our work to not only make Syneos Health easier to work with, but to make us easier to work for.\nWithin Kinetic (a division of Syneos Health) our strength is the efficiency with which we deliver leading- edge products and support to those we serve. We’re proud to set the standard for success in our industry.\nAs a Manager, Data Science, you will play a pivotal role within the Data Science team. You will be responsible for providing technical leadership, overseeing data science projects, and building innovative products.\nDiscover what our 29,000 employees, across 110 countries already know:\nWORK HERE MATTERS EVERYWHERE\nWhy Syneos Health\nWe are passionate about developing our people, through career development and progression; supportive and engaged line management; technical and therapeutic area training; peer recognition and total rewards program.\nWe are committed to our Total Self culture – where you can authentically be yourself. Our Total Self culture is what unites us globally, and we are dedicated to taking care of our people.\nWe are continuously building the company we all want to work for and our customers want to work with. Why? Because when we bring together diversity of thoughts, backgrounds, cultures, and perspectives – we’re able to create a place where everyone feels like they belong.\nJob responsibilities\nQuickly understand Kinetic’s current data and insights products and understand common trends across our services to design repeatable and scalable solutions\nDevelop and code software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources to build POC analytic solutions.\nGenerate new product requirements for the engineering group to enhance the analytic capabilities of existing database to support various data science needs.\nPerform analyses utilizing advanced analytical techniques to generate actionable insights and solutions for client services and product development.\nIdentify meaningful insights from large data and metadata sources; interpret and communicates insights and findings from analysis and experiments to product, service, and business managers.\nHave broad expertise or innovative knowledge, use skills to contribute to development of company objectives and principles and to achieve goals in creative and effective ways.\nQualifications\nWhat we’re looking for\nMasters degree in a STEM field required.\n3-4 years applicable experience\nProficiency in SQL for data extraction and manipulation from databases\nStrong programming skills (e.g., Python, R) and experience with data manipulation libraries (e.g., Pandas) and machine learning frameworks (e.g. scikit-learn, TensorFlow, PyTorch)\nProven experience in designing and implementing data pipeline for machine learning.\nExperience with machine learning, statistical analysis, and data manipulation techniques.\nDetailed understanding of how data science models are developed.\nExperience with code version control platforms (GitHub or Azure DevOps)\nMust be organized, detail oriented and work effectively in a fast-paced environment.\nIndependent problem-solving and grit. Willingness to own one’s work, and confidence to push best practices. Strong attention to detail.\nRelevant work experience in healthcare or campaign measurement, marketing analytics and resource optimization in the pharma domain is a plus.\nGet to know Syneos Health\nOver the past 5 years, we have worked with 94% of all Novel FDA Approved Drugs, 95% of EMA Authorized Products and over 200 Studies across 73,000 Sites and 675,000+ Trial patients.\nNo matter what your role is, you’ll take the initiative and challenge the status quo with us in a highly competitive and ever-changing environment. Learn more about Syneos Health.\nAdditional Information:\nTasks, duties, and responsibilities as listed in this job description are not exhaustive. The Company, at its sole discretion and with no prior notice, may assign other tasks, duties, and job responsibilities. Equivalent experience, skills, and/or education will also be considered so qualifications of incumbents may differ from those listed in the Job Description. The Company, at its sole discretion, will determine what constitutes as equivalent to the qualifications described above. Further, nothing contained herein should be construed to create an employment contract. Occasionally, required skills/experiences for jobs are expressed in brief terms. Any language contained herein is intended to fully comply with all obligations imposed by the legislation of each country in which it operates, including the implementation of the EU Equality Directive, in relation to the recruitment and employment of its employees. The Company is committed to compliance with the Americans with Disabilities Act, including the provision of reasonable accommodations, when appropriate, to assist employees or applicants to perform the essential functions of the job.\n#LI-MS5",
         "Remote",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "--",
         "Company - Private",
         "Biotech & Pharmaceuticals",
         "Pharmaceutical & Biotechnology",
         "Unknown / Non-Applicable",
         "3.5",
         "3.5",
         "3.8",
         "3.5",
         "3.9"
        ],
        [
         "51",
         "JLL",
         "Sustainability Data Analyst",
         "3.9",
         "JLL supports the Whole You, personally and professionally.\n\nOur people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you’ve got deep experience in commercial real estate, skilled trades, and technology, or you’re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally.\n\nWhat this job involves?\n\nShaping the future of real estate for a better world\nAt JLL, we see a Brighter Way forward for our clients, our people, our planet, and our communities. With over 200 years of real estate experience, we are, and always have been, in continual pursuit of brighter ways of working.\n\nWe bring to life see a Brighter Way in all that we do by seeking better, smarter, more innovative ways of working. We approach our work in a warmer, more optimistic, and inclusive way.\nJLL is a global leader in helping clients envision where people will live, work, play, shop, and eat.\n\nWhat this opportunity involves:\nWe seek a Junior Sustainability Data Analyst to join our team. You will support the sustainability data analyst reporting, data management, platform, compliance and reporting functions for a wide range of assets across JLL.\n\nJLL's purpose-driven global sustainability program delivers impact on climate action for sustainable real estate, healthy spaces for all people and thriving communities.\nWe are a rapidly expanding team, and over time we continuously support your growth with development opportunities available within our data and analytics teams.\n\nAn overview of the role:\nAssist the reporting team with insights, analytics, preparing data and presentations.\nAssist the team with delivering projects that will enable clients to meet sustainability reporting objectives.\nDevelop a detailed understanding of JLL’s sustainability reporting application and how we support clients in measuring sustainability performance.\nAssist the team with client delivery milestones to ensure they are being met.\nSounds like you? This is what we are looking for\nA passion for Sustainability and pulling together associated Data and Reporting.\nIntermediate Excel skills.\nInsights, element visualisation, and presenting data.\nExcellent communication skills.\nWhat you can expect from us:\nYou’ll join an entrepreneurial, inclusive culture. One where the best inspire the best. Where like-minded people work naturally together to achieve great things. Join us to develop your strengths and enjoy a fulfilling career full of varied experiences. Keep those ambitions in sight and imagine where JLL can take you.\n\nAs an organisation, we don’t just accept that we are a place of many different people, but we embrace it, we celebrate it, and we proactively support the needs that difference brings. JLL is committed to equal opportunity regardless of race, gender, age, sexual orientation or disability, and that is why, for more than a decade, we continue to rank among the World’s Most Ethical Companies.\n\nWe are dedicated to offering veterans from all ranks and services a successful civilian career as they transition out of the military. We recognise and appreciate the skills acquired in their service careers as vital and transferable to our workforce.\n\nIf this job description resonates with you, we encourage you to apply even if you don’t meet all of the requirements below. We’re interested in getting to know you and what you bring to the table!\n\nPersonalized benefits that support personal well-being and growth:\n\nJLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health.\n\nAbout JLL –\n\nWe’re JLL—a leading professional services and investment management firm specializing in real estate. We have operations in over 80 countries and a workforce of over 102,000 individuals around the world who help real estate owners, occupiers and investors achieve their business ambitions. As a global Fortune 500 company, we also have an inherent responsibility to drive sustainability and corporate social responsibility. That’s why we’re committed to our purpose to shape the future of real estate for a better world. We’re using the most advanced technology to create rewarding opportunities, amazing spaces and sustainable real estate solutions for our clients, our people, and our communities.\n\nOur core values of teamwork, ethics and excellence are also fundamental to everything we do and we’re honored to be recognized with awards for our success by organizations both globally and locally.\n\nCreating a diverse and inclusive culture where we all feel welcomed, valued and empowered to achieve our full potential is important to who we are today and where we’re headed in the future. And we know that unique backgrounds, experiences and perspectives help us think bigger, spark innovation and succeed together.",
         "Bengaluru",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "--",
         "Company - Public",
         "Real Estate",
         "Real Estate",
         "$5 to $10 billion (USD)",
         "3.7",
         "3.5",
         "3.8",
         "3.5",
         "3.7"
        ],
        [
         "55",
         "Rotork",
         "Data Analyst",
         "3.7",
         "Company Description\n\nRotork is the market-leading global flow control and instrumentation company, helping our customers manage the flow or liquids, gases and powders across many industries worldwide.\nOur purpose is Keeping the World Flowing for Future Generations.\nFor over sixty years, the world has relied on us to create the things that keep everything moving. From oil and gas to water and shipping, pharmaceuticals and food- these are the flows on which our modern world depends.\nToday we're respected and admired for our people, performance and products. Our success flows from our commitment to engineering excellence, and that's what we will always pursue, safely and sustainably.\nRotork is going through an exciting period of change and growth, building on our existing market success. It's a great time to join us and make an impact in shaping the future of our business.\nhttp://www.rotork.com\n\nJob Description\n\nWorking as part of the Data team and support team on all aspects of Data management.\nYour responsibilities will include,\nData profiling, Schema mapping, Master Data Management, Data analysis, Data cleansing, Data migration\nData quality checks and advising project teams on potential data issues and actions.\nDeliver data service requests in line with BAU demand.\nTechnical Skills\nEssential:\nRelational Databases – SQL Server, 2016 is a minimum, Oracle nice to have.\nSQL – T-SQL, Stored Procedures, Views, DML, DDL\nETL/ELT – SSIS and Azure Data Factory\nExposure to Azure SQL Database\nOffice – Advanced Excel skills, Word, Visio, PowerPoint\nDesirable:\nData Migration Tools\nMicrosoft 365 Applications - Power BI, PowerApps, SharePoint\nExposure to Microsoft Dynamics or any ERP\n\nQualifications\n\nSoft Skills\nEssential:\nExcellent written and verbal communication skills\nGreat attention to detail\nCommitment to personal excellence\nDesire to expand technical expertise.\nCongenial attitude - team player\nDisciplined work ethic\nDesirable:\nOut-of-the-box thinker with creative problem-solving ability.\nAbility/Experience to establish priorities, work independently, and proceed with objectives without supervision\nPersonal Specification:\nEssential\nDemonstrate integrity and honesty.\nCapable of communicating at all levels\nEthical and transparent leadership, setting an example to others.\nDemonstrate an appetite and ability to work collaboratively in a complex and matrixed business.\nAble to deal with people with different cultures throughout the region.\nAble to thrive in a changing business, embracing ambiguity and solving complex problems.\n\nAdditional Information",
         "Chennai",
         "569738.0",
         "/yr (est.)",
         "1001 to 5000 Employees",
         "--",
         "Company - Public",
         "Electronics Manufacturing",
         "Manufacturing",
         "$500 million to $1 billion (USD)",
         "3.5",
         "3.2",
         "3.5",
         "3.4",
         "3.9"
        ],
        [
         "68",
         "Veranex, Inc.",
         "Clinical Data Coordinator 2",
         "4.0",
         "Minimum Requirement\nBachelor’s degree or international equivalent in life sciences\n3-5 years of relevant work experience\n\nLevel-Specific Responsibilities:\nPerforms study status tracking, data entry and verification.\n\nPerforms data review and quality control procedures.\n\nDevelops and provides input into project-specific guidelines.\n\nPerforms data review, identification of data issues, and quality control procedures.\n\nParticipates in User Acceptance Testing.\n\nParticipates in the query management and data cleaning process.\n\nArchives all study-related documents.\n\nProvides advise or solutions in area of expertise.\n\nMay participate in audits and inspections.\n\nParticipates in project team meetings.\n\nSkills Required:\nWorking knowledge of clinical research and the drug development process\n\nWorking knowledge of databases, tracking, validation, programming, word-processing and spreadsheet software\n\nWorking knowledge of clinical databases and query management\n\nWorking knowledge of organization procedures and policies and ensures actions comply.\n\nGood written and oral communication skills\n\nGood attention to detail\n\nGood organization and time management skills\n\nAbility to take a proactive approach to work\n\nAbility to solve simple to moderate problems\n\nAbility to multitask and prioritize work\n\nGood ability to work in cross-functional teams\n\nDeveloping professional expertise, applies company policies and procedures to resolve issues.\nWorks on routine problems of moderate scope. Exercises judgment following standard practices and procedures in analyzing situations or data from which answers can be readily obtained. Builds stable working relationships internally.\n\nReceives occasional guidance on day-to-day work and moderate guidance on new projects or assignments.",
         "Bengaluru",
         "539530.5",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Chemical Manufacturing",
         "Manufacturing",
         "Unknown / Non-Applicable",
         "3.7",
         "3.4",
         "3.6",
         "3.1",
         "4.2"
        ],
        [
         "80",
         "Sanfoundry",
         "Junior Machine Learning Engineer",
         "4.0",
         "Job Code: Machine-Learning-24016\n\nLocation: Remote\nExperience: Fresher-Mid Level\nDate Posted: 2023-12-31\nValid Through: 2024-01-29\n\nJob Description:\nJob Description\nUnderstand the importance of shipping on-time and meet deadlines\nHelp form and maintain engineering standards, tooling, and processes\nPatiently dive deep to analyze complex challenges and come up with innovative solutions\nTake product ownership and push features over the line\nJob Requirements:\nBachelor’s/Master’s degree in Engineering, Computer Science (or equivalent experience)\nAt least 3+ years of relevant experience as a Machine Learning Engineer\nProlific experience working with Python and Deep Learning\nExtensive experience working with Machine Learning\nAbility to navigate through deadlines and work under pressure\nExcellent problem-solving and multitasking skills",
         "Remote",
         "539530.5",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ],
        [
         "84",
         "WCG",
         "Jr. Data & Analytics Engineer",
         "3.2",
         "Description and Requirements\nJOB SUMMARY:\nThe Junior Data & Analytics (D&A) Engineer plays a pivotal role in the development of analytics-driven solutions that optimize and streamline clinical trial processes. Working closely with our data & analytics team and clinical trial experts, this role will harness the power of cutting-edge AI and LLM (Machine Learning and Deep Learning) technologies for enhancing decision-making in the field of clinical trial process. The Junior D&A Engineer is part of a team that is domain agnostic, working hands-on with structured as well as unstructured data, designing algorithms and implementing innovative capabilities that cater to an array of business use cases within the data & analytics function at WCG. As a core member of the data & analytics team, the Junior D&A Engineer designs and builds analytics frameworks, documents best practices, and works with the architecture and infrastructure teams on developing patterns.\n\nEDUCATION REQUIREMENTS:\nBachelor’s degree in a quantitative discipline (i.e. statistics, applied mathematics, computer science, data mining, machine learning, or some other empirical science) with specialization in data science, engineering or related field preferred\nQUALIFICATIONS/EXPERIENCE:\nStrong programming skills, particularly in Python\nProficiency in data manipulation and analysis using SQL and data processing tools (e.g., Apache Spark)\nProficiency with machine learning and deep learning frameworks (e.g., TensorFlow, PyTorch)\nExcellent problem-solving and analytical skills\nStrong communication and teamwork skills\nKnowledge of healthcare and clinical trial processes is a plus.\nFamiliarity in a cloud platform (AWS, Azure)\nFamiliarity with relational and non-relational databases and how they work\nFamiliarity with big data technologies such as DataBricks, Hadoop, and Kafka\nPossess a data security mindset\nESSENTIAL DUTIES/RESPONSIBILITIES: To perform this job successfully, an individual must be able to perform each essential duty and responsibility satisfactorily. The accountabilities listed below are representative of the knowledge, skills, and/or ability required.\nData Collection and Integration: Collaborate with cross-functional teams to collect, clean, and integrate diverse healthcare and clinical trial data from various sources.\nMachine Learning Model Development: Design, develop, and implement machine learning and deep learning models to address specific challenges in clinical trials, such as patient recruitment, data analysis, protocol study, anomaly detection, document entity extraction, document generation, translation, and outcome prediction.\nData Processing: Create data pipelines and workflows to preprocess and transform data into a format suitable for analysis and modeling.\nModel Evaluation: Conduct rigorous testing and evaluation of machine learning models, ensuring accuracy, reliability, and robustness.\nData Visualization: Develop interactive data visualizations and dashboards to communicate insights and outcomes to both technical and non-technical stakeholders.\nDocumentation: Maintain detailed documentation of data engineering and analytics processes, including code, model specifications, and best practices.\nResearch and Innovation: Stay updated on the latest advancements in AI and LLM technologies and explore their potential applications in improving clinical trial processes.\nCollaboration: Work closely with clinical experts, data scientists, and engineers to develop and deploy solutions that directly impact the healthcare and clinical research industry.\nOther duties as assigned by supervisor. These may, on occasion, be unrelated to the position described here.\nTRAVEL REQUIREMENTS: 0% – 5%\n\n#LI-SA1\n\nWCG is proud to be an equal opportunity employer – Qualified applicants will receive consideration for employment without regard to race, color, national origin or ancestry, religion or creed, sex, sexual orientation, gender identity, age, marital status, disability, genetic information, citizenship, veteran status, reprisal or any other legally recognized basis or status protected by federal, state or local law.",
         "Karnataka",
         "539530.5",
         "/yr (est.)",
         "1001 to 5000 Employees",
         "--",
         "Company - Private",
         "Biotech & Pharmaceuticals",
         "Pharmaceutical & Biotechnology",
         "$100 to $500 million (USD)",
         "2.7",
         "3.1",
         "2.7",
         "2.5",
         "2.8"
        ],
        [
         "97",
         "Leegality",
         "Data Analyst",
         "4.0",
         "This is a remote position.\nCompany Mission\n\n\nLeegality is India’s first Document Infrastructure Platform - a radical new digital way for businesses to complete paperwork (agreements, forms and other legal documents). Over the last 7 years, Leegality has changed the way 2000+ Businesses do their paperwork from large enterprises like HDFC, SBI Cards, Federal Bank, ICICI Lombard, Axis Finance, Tata Capital etc. to high-growth companies like Razorpay, Rupeek, Cars24, Dunzo etc.\n\nTo see our impact on customers click here https://www.leegality.com/case-studies\n\n\nCompany Environment\n\n\nLeegality has an Employee Net Promoter Score of 97 - the highest on xto10x’s eNPS Survey for Q1 2022. The highest among 60+ notable startups. This makes us, arguably, the most employee-loved startup in the country\n\n\nCreating a category-defining company - and changing the way businesses perform a critical function like paperwork - requires powerful marketing that resonates with people.\n\n\n\nRequirements\nResponsibilities:\n\nRespond promptly to data requests from diverse teams and stakeholders.\nAnalyze and interpret complex datasets to extract meaningful insights.\nDevelop and maintain interactive and visually appealing dashboards using Tableau Server.\n\nEnsure dashboards effectively communicate key performance indicators (KPIs) and trends.\n\nCollaborate closely with product, sales, tech, and customer success teams to understand their data needs.\n\nProvide analytical support to aid teams in making data driven decisions.\n\nPresent findings and insights to non-technical stakeholders in a clear and compelling manner.\n\nCommunicate data-driven recommendations to support strategic initiatives.\n\nEngage in CEO-level interactions, offering data insights that contribute to high-level decision-making.\n\nUtilize SQL for efficient data extraction, transformation, and analysis.\n\nEmploy advanced Excel/Google Sheets functionalities for data manipulation.\n\nBring a dynamic and adaptable mindset, leveraging any previous startup experience.\n\n\nTechnical Skills:\n\nTableau Server\n\nSQL\n\nAdvance Excel / Google Sheets.\n\n\n\nBenefits\nRecruitment Process:\n\nOn being shortlisted, you would be contacted for the interview process.\n\nWe further have 3 rounds of interviews.\n\nYour final CTC would be decided on the basis of your skills, experience and final assessment.\n\n\n\nApply directly through our career page: https://careers.leegality.com/jobs/Careers\n\nFor more information about us please visit our:\n\nOur Company and Culture: https://bit.ly/3Iqm5SB\n\nOur Website: www.leegality.com/\n\nOur LinkedIn Page: www.linkedin.com/company/leegality/\n\nJob Information\nIndustry\nIT Services\nRemote Job",
         "India",
         "539530.5",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.9",
         "4.8",
         "5.0",
         "4.9",
         "4.9"
        ],
        [
         "149",
         "Ventra Health, Inc.",
         "Data Engineer",
         "3.3",
         "Job Summary:\nThe Data Engineer works independently, and collaboratively, to design and implement complex Data & Analytics solutions.\nThe individual in this position interfaces with various functional teams to support the solution delivery. They proactively identify needs or issues, develop strategies, and propose/implement technical solutions. The Data Engineer will grow to become a subject matter expert.\nEssential Functions and Tasks:\nResponsible for designing and implementing Analytical solutions using the Microsoft BI Toolkit (SQL, SSIS, SSAS) to enable the analysis of data to support strategic initiatives and ongoing business requirements.\nThis position is expected to have a proactive approach and create the best solution to address business needs and current infrastructure. Care will be given to provide accurate data to fulfill the requirements of the developed solutions.\nExtract, transform and load company data into the Enterprise Data Warehouse.\nPerform Unit, Integration and Functional testing.\nActively seeks opportunities to expand technical knowledge and capabilities.\nWork with the Development team to establish the best patterns, practices, and standards as new technology arises.\nParticipate in the out of hours support process.\nKnowledge, Skills, and Abilities:\nProven experience as a Data Engineer with in-depth knowledge of SQL Integration Services (SSIS) and expert level SQL programming skills for data manipulation, query optimization, and performance tuning.\nIdeal candidates will have hands-on experience with the full life cycle of Data warehouse design and development including logical and physical data modeling, Kimbell design methodologies, architecture techniques, including ODS, DM, and EDW.\nExcellent problem solving and analytical skills, with keen attention to detail.\nProven ability to manage multiple tasks and priorities efficiently.\nAbility to work effectively in cross-functional teams, collaborating with Product Owners, QA Teams, and business stakeholders.\nExcellent communication skills\nAbility to be flexible and work under high pressure in a complex environment.\nHealthCare/RCM/Financial systems is a major plus.\nExperience with large Health care EMRs is a plus.\nUnderstand and comply with company policies and procedures.\nIND2",
         "India",
         "539530.5",
         "/yr (est.)",
         "1001 to 5000 Employees",
         "--",
         "Company - Private",
         "Healthcare Services & Hospitals",
         "Healthcare",
         "Unknown / Non-Applicable",
         "3.2",
         "3.0",
         "3.2",
         "3.0",
         "3.5"
        ],
        [
         "160",
         "BDIPlus",
         "Data Engineer ||",
         "4.1",
         "Job Role: Data Engineer II\nAbout BDIPlus:\nBDIPlus is a dynamic Strategy Consulting and Software firm dedicated to delivering cutting-edge capabilities and solutions that foster the development of enduring competitive advantages. Our innovative solutions showcase our unparalleled proficiency in technology and our profound domain expertise within the Financial Services and Insurance sectors. By synergizing our unmatched technical skills with a comprehensive grasp of each client’s institutional landscape and distinctive areas for improvement, we empower them to convert data into actionable and well-organized information. This facilitates precise decision-making, increased efficiency and rampant business growth.\nPosition Overview:\nAs a Data Engineer, you will be tasked with crafting, constructing and sustaining the framework necessary for seamless data collection, storage, analysis and the construction of predictive models. Your responsibilities encompass the creation and oversight of databases, the development of efficient data pipelines, and the assurance of the overall reliability and effectiveness of data systems. Essentially, your role involves establishing the foundation that enables organizations to extract valuable insights and make well-informed decisions grounded in data.\nResponsibilities:\nDesign, implement, and optimize scalable data pipelines using Scala and Spark, ensuring efficient big data processing and management.\nUtilize Hive for creating and maintaining data warehouses, facilitating seamless access to structured and semi-structured data.\nLeverage one year of ML model building experience to integrate machine learning solutions into data processing workflows, enhancing data-driven decision-making capabilities.\nCollaborate with cross-functional teams to understand business requirements and translate them into effective data engineering solutions.\nEnsure the reliability, performance, and security of data infrastructure, troubleshooting and resolving issues to maintain a robust data ecosystem.\nRequirements:\nProficient in Java, or Scala for scalable data processing.\nProven 2+ years of Related Field.\nExtensive experience with big data tech (e.g., Apache Spark) and database design (Hive).\nMinimum one year ML model building experience.\nCloud platform expertise (AWS, Azure, GCP) for deploying data solutions.\nCollaborative mindset to work with cross-functional teams.\nStrong problem-solving skills and proactive approach to data issues.\nExcellent communication skills.\nBachelor's degree in relevant field.\nTechnical Skills:\nProgramming skills with experience in Java/ Scala (Must).\nBig Data (Spark) is mandatory\nStrong Experience with Query Language like SQL\nHand-on experience with Machine Learning which includes Supervised Learning: regression, Binary Classification Models (Logistic Regression, Random Forest, XGBoost, SVM, LightGBM etc) and Unsupervised learning: Segmentation (Cluster analysis, Recommender systems etc.)\nExperience in working with large volumes of data.\nData ecosystems - Hadoop, Hive, Python is a plus\nAWS/AZURE\nData modelling and evaluation\nBenefits:\nMedical insurance\nJoin our team and contribute to the development of innovative solutions that make a difference. We offer competitive compensation, a collaborative work environment, and opportunities for professional growth. Kindly share your CV at Priyanka.singh@bdiplus.com\nKindly fill this form its Mandatory: https://forms.office.com/Pages/ResponsePage.aspx?id=p2Sznb86AUWp9dWYX5lFz4alBrukXiRFlL85GBWLzOdURExMVlhRSkcyQThJQk9DM0s0WlJLQVJFVS4u\nJob Types: Full-time, Permanent\nPay: ₹550,171.72 - ₹1,500,000.00 per year\nBenefits:\nHealth insurance\nPaid sick time\nPaid time off\nProvident Fund\nSchedule:\nDay shift\nMonday to Friday\nSupplemental pay types:\nYearly bonus\nExperience:\ntotal work: 2 years (Preferred)\nAbility to Commute:\nBangalore, Karnataka (Required)\nAbility to Relocate:\nBangalore, Karnataka: Relocate before starting work (Required)\nWork Location: In person\nSpeak with the employer\n+91 9643459417",
         "Bengaluru",
         "1025086.0",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.1",
         "4.0",
         "4.0",
         "3.8",
         "3.5"
        ],
        [
         "164",
         "UnitedHealthcare",
         "Data Analyst 2",
         "3.6",
         "Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together.\nPrimary Responsibilities:\nAnticipate customer needs and proactively develop solutions to meet them\nServe as a key resource on complex and / or critical issues\nSolve complex problems and develop innovative solutions\nProvide explanations and information to others on the most complex issues\nCreate Benchmark ETL and reporting - standard and ad hoc needs\nDevelop, build, and maintain reporting of key metrics\nConsult and document business requirements to support reporting needs\nUnderstand basic relational data structures\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\nRequired Qualifications:\n7+ years of experience writing T-SQL queries, stored procedures, and complex scalar-value functions\n6+ years of experience using SSIS/ADF tools for ETL solutions\n6+ years of experience gathering and documenting requirements\n6+ years of experience with process improvement, workflow, benchmarking, and/or evaluation of business processes\nWorking experience on Databricks, Kafka, Python and ML libraries\nExperience on CI/CD implementation\nExperience on SSIS to ADF migration\nAny source control tool experience like Github/TFS\nAzure cloud server knowledge\nKnowledge on Query performance tuning and optimization\nKnowledge on consuming stream data from hub/snowflake server to on-prem\nProven solid statistics and analytical knowledge\nProven solid written and verbal communication skills\nPreferred Qualifications:\nExperience building dashboard using Power BI\nKnowledge on Microsoft azure cloud environment\nKnowledge on U.S healthcare domain\nAt UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone–of every race, gender, sexuality, age, location and income–deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes — an enterprise priority reflected in our mission.",
         "Bengaluru",
         "663325.0",
         "/yr (est.)",
         "10000+ Employees",
         "--",
         "Company - Public",
         "Healthcare Services & Hospitals",
         "Healthcare",
         "Unknown / Non-Applicable",
         "3.6",
         "3.5",
         "3.7",
         "3.3",
         "3.6"
        ],
        [
         "192",
         "Toolyt",
         "Data Analyst",
         "4.8",
         "We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.\n\nData analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.\n\nResponsibilities:\nInterpret data, analyze results using statistical techniques and provide ongoing reports\nDevelop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality\nAcquire data from primary or secondary data sources and maintain databases/data systems\nIdentify, analyze, and interpret trends or patterns in complex data sets\nFilter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems\nWork with management to prioritize business and information needs\nLocate and define new process improvement opportunities\nRequirements:\nProven working experience as a data analyst\nBachelors degree in Computer science, Maths or statistics\nAnalyze and organize raw data\nBuild data systems and pipelines\nEvaluate business needs and objectives\nInterpret trends and patterns\nConduct complex data analysis and report on results\nHands on experience with SQL database design (advanced)",
         "Jaipur",
         "40000.0",
         "/mo (est.)",
         "1 to 50 Employees",
         "--",
         "Company - Private",
         "Enterprise Software & Network Solutions",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.9",
         "4.6",
         "4.9",
         "4.9",
         "4.6"
        ],
        [
         "203",
         "Konceive Development Center Pvt. Ltd.",
         "Data Analyst",
         "4.6",
         "Job Description:\nResponsibilities:\nCollect, clean, and analyze data from diverse sources.\nIdentify trends and patterns for strategic decision-making.\nDevelop and present clear visualizations and reports.\nCollaborate with cross-functional teams to meet business objectives.\nUtilize statistical models for forecasting.\nQualifications:\nBachelor’s degree in a relevant field.\nProficient in SQL, Python, or R.\nExperience with data visualization tools (Tableau, Power BI).\nStrong analytical and problem-solving skills.\nExcellent communication skills.\nExperience:\n2+ years\nCertifications:\nDesirable certifications, such as CAP (Certified Analytics Professional) or Microsoft Certified, are a significant advantage.\nJob Types: Full-time, Permanent\nSalary: ₹20,000.00 - ₹50,000.00 per month\nBenefits:\nHealth insurance\nProvident Fund\nSchedule:\nDay shift\nFixed shift\nMonday to Friday\nMorning shift\nWork Location: In person",
         "Panchkula",
         "35000.0",
         "/mo (est.)",
         "1 to 50 Employees",
         "--",
         "Company - Private",
         "Advertising & Public Relations",
         "Media & Communication",
         "Unknown / Non-Applicable",
         "4.5",
         "4.6",
         "4.5",
         "4.5",
         "4.7"
        ],
        [
         "208",
         "Syneos Health Clinical",
         "Senior Clinical Data Associate",
         "3.8",
         "Description\nSenior Clinical Data Associate\nSyneos Health® is a leading fully integrated biopharmaceutical solutions organization built to accelerate customer success. We translate unique clinical, medical affairs and commercial insights into outcomes to address modern market realities.\nOur Clinical Development model brings the customer and the patient to the center of everything that we do. We are continuously looking for ways to simplify and streamline our work to not only make Syneos Health easier to work with, but to make us easier to work for.\nWhether you join us in a Functional Service Provider partnership or a Full-Service environment, you’ll collaborate with passionate problem solvers, innovating as a team to help our customers achieve their goals. We are agile and driven to accelerate the delivery of therapies, because we are passionate to change lives.\nDiscover what our 29,000 employees, across 110 countries already know:\nWORK HERE MATTERS EVERYWHERE\nWhy Syneos Health\nWe are passionate about developing our people, through career development and progression; supportive and engaged line management; technical and therapeutic area training; peer recognition and total rewards program.\nWe are committed to our Total Self culture – where you can authentically be yourself. Our Total Self culture is what unites us globally, and we are dedicated to taking care of our people.\nWe are continuously building the company we all want to work for and our customers want to work with. Why? Because when we bring together diversity of thoughts, backgrounds, cultures, and perspectives – we’re able to create a place where everyone feels like they belong.\nJob responsibilities\nMaintains awareness of the pertinent elements of contract and scope of work for assigned project(s) and communicates status updates to the Project Manager (PM) and/or Biometrics Project Manager (BPM) as necessary.\nReviews and adheres to the requirements of study-specific DMP for assigned project(s) and updates as required.\nCreates and enters test data for User Acceptance Testing (UAT)\nPerforms User Acceptance Testing (UAT) for data entry screens, edits and data review listings, all different roles used in the study and Targeted Source Data Verification (SDV) configuration and matrices.\nReceives and enters lab normal ranges.\nCompletes and submits Clinical Database Management System (CDMS)-specific access forms and/or spreadsheets.\nPerforms reviews of discrepancy (edit check) output and validation listings based on data entered into the clinical database. Based on this review, queries or applies self-evident corrections or other global rulings permitted in cases where queries are not required, per the DVS and/or Data Management Plan (DMP) for the assigned projects. Resolves answered queries and re-queries where appropriate.\nFor paper studies, takes receipt of, and reviews, Data Clarification Forms (DCFs) that have been answered by sites and where appropriate, edits the CRF database accordingly.\nFor paper studies, performs internal QC checks via listing output from database against CRFs and DCFs. Serves as QC Coordinator for paper studies.\nFor paper studies, ensures all CRFs and DCFs received are returned for filing in the Document Control Room per the Data Tracking Guidelines for the assigned projects.\nFor EDC studies, performs DM quality review and/or other internal QC checks as required per applicable Electronic Data Capture (EDC) systems.\nParticipates/Leads in internal meetings.\nAttends in-process review meetings.\nParticipates in internal/external audits as required.\nFiles documentation in the Data Management Study File (DMSF).\nMaintains proficiency in Data Management systems and processes through regular trainings (CDA Knowledge College)\nPerforms SAS mapping QC whereby discrepancies are noted on the SAS mapping test logs.\nOversees the work of other CDAs as required. This may involve on-the-job training, review of work, as well as ensuring the quality of work performed.\nEnsures that data from external databases/datasets such as central and/or local laboratory data, electronic diary data, pharmacokinetic (PK) data, or Interactive Response Technology (IRT) are consistent with data in the clinical database. Uses the specified process to document and query any such discrepancies found with the appropriate party.\nCompletes tasks within timeframe by appropriately prioritizing multiple tasks within or across projects and adapts to timeline or priority changes by reorganizing daily workload. Proactively communicates to project team and management accurate estimates on time to complete tasks, availability to take on new assignments and resourcing conflicts. Minimizes rework by following study instructions, seeking understanding of assignments prior to performing task and anticipating the effect changes may have on data when issuing and resolving queries.\nRuns data cleaning and/or status reports.\nPerforms Serious Adverse Event (SAE) reconciliations.\nLiaises with other groups such as Clinical Programming (CP), Biostatistics and Clinical Operations.\nCreates ad-hoc data cleaning reports used to determine if a validated listing is required including creation of the specification for the validated listing (updates DVS with the listing requirements).\nPerform post-migration testing on screens, edit checks, matrices and role changes as required.\nParticipates in customer and third party meetings distributing relevant information in advance, ensures minutes are promptly and accurately distributed to internal team for review and subsequent edits are applied in order to maintain established currency for sponsor distribution.\nReviews database design specifications (including configuration, data structures, annotated CRFs).\nDesigns and/or reviews CRF/eCRF including eCRF visit structure co-coordinating with team members responsible for the associated database design.\nProvides input into the Data Validation Specification (DVS) including creation of edit checks for assigned forms including any post-production updates to the DVS and listings under guidance.\nProvides support to the PDM on a study as required. May involve soliciting support from and coordinating with other CDAs, taking full responsibility for an aspect of the study delivery, or producing study metrics reports. PDM’s back up for specific activities (including attend sponsor’s meetings to provide updates).\nCreation of Discoverer, BOXI, J-Review Reports\nCreates, updates and reviews study-specific documents such as CRF/eCRF DMP, data import/export agreements, CRF/eCRF Completion Guidelines.\nFills-in the Data Transfer Request Form required for delivering the data to sponsor or vendor.\nReviews queries and self-evident corrections proposed by less experienced DM staff.\nUnderstands the coding process\nUnderstands the purpose of interim, dry run, data cut\nTrains and mentors DM staff providing timely feedback to trainee and management as appropriate.\nTrains project team in project specific requirements.\nProvides EDC training to internal and external team members via Teleconference.\nServes as a platform or process-specific Subject Matter Expert (SME).\nPerforms QC of DMSF after QuickStart® Camp (QSC) and ongoing during the study conduct.\nMay be required to participate in client, internal or agency audits and inspections.\nMay represent the department at business development related meetings.\nQualifications\nWhat we’re looking for\nBA/BS degree in the biological sciences or related disciplines in the natural science/health care field.\nExperience with DM practices and relational database management software systems preferred.\nOracle Clinical, Rave, or Inform systems preferred. Knowledge of clinical data, and ICH/Good Clinical Practices. Knowledge of medical terminology preferred.\nProficiency in navigating MS Windows, as well as use of MS Word, Excel, and email applications. Excellent speed and accuracy of keyboard skills.\nWork experience in clinical research, drug development, data management, or other healthcare environment preferred.\nFamiliarity with medical terminology\nExcellent communication, presentation, interpersonal skills, both written and spoken, with an ability to inform, influence, convince, and persuade\nGood organizational, planning, and time management skills preferred. Ability to multitask under tight deadlines while providing attention to detail. Ability to be flexible and adapt to change. Ability to work independently as well as part of a multi-disciplinary team.\nAbility to perform a leadership functions in DM including effective mentoring skills, and the ability to deal effectively with sponsors and internal customers.\nResponsible for performing activities that are in compliance with applicable Corporate Business Practices, Standard Operating Procedures and Working Instructions and performing other duties as assigned by management. Minimal travel may be required (up to 25%).\nGet to know Syneos Health\nOver the past 5 years, we have worked with 94% of all Novel FDA Approved Drugs, 95% of EMA Authorized Products and over 200 Studies across 73,000 Sites and 675,000+ Trial patients.\nNo matter what your role is, you’ll take the initiative and challenge the status quo with us in a highly competitive and ever-changing environment. Learn more about Syneos Health.\nAdditional Information:\nTasks, duties, and responsibilities as listed in this job description are not exhaustive. The Company, at its sole discretion and with no prior notice, may assign other tasks, duties, and job responsibilities. Equivalent experience, skills, and/or education will also be considered so qualifications of incumbents may differ from those listed in the Job Description. The Company, at its sole discretion, will determine what constitutes as equivalent to the qualifications described above. Further, nothing contained herein should be construed to create an employment contract. Occasionally, required skills/experiences for jobs are expressed in brief terms. Any language contained herein is intended to fully comply with all obligations imposed by the legislation of each country in which it operates, including the implementation of the EU Equality Directive, in relation to the recruitment and employment of its employees. The Company is committed to compliance with the Americans with Disabilities Act, including the provision of reasonable accommodations, when appropriate, to assist employees or applicants to perform the essential functions of the job.",
         "Remote",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "--",
         "Company - Private",
         "Biotech & Pharmaceuticals",
         "Pharmaceutical & Biotechnology",
         "Unknown / Non-Applicable",
         "3.5",
         "3.5",
         "3.8",
         "3.5",
         "3.9"
        ],
        [
         "218",
         "Sanfoundry",
         "Junior Machine Learning Engineer - Fresher",
         "4.0",
         "Job Code: Machine-Learning-Fresher-24011\n\nLocation: Bangalore, Noida\nExperience: Fresher\nDate Posted: 2023-12-28\nValid Through: 2024-01-31\n\nJob Description:\nJob description:\n\nRoles and Responsibilities:\nDesign machine learning systems.\nResearch and implement appropriate ML algorithms and tools.\nDevelop machine learning applications according to requirements.\nSelect appropriate datasets and data representation methods.\nRun machine learning tests and experiments.\nPerform statistical analysis and fine-tuning using test results.\nTrain and retrain systems when necessary.\nExtend existing ML libraries and frameworks.\nKeep abreast of developments in the field.\nRequirements and skills:\nUnderstanding of data structures, data modeling and software architecture.\nDeep knowledge of math, probability, statistics and algorithms.\nAbility to write robust code in Python(Pandas, scikit learn or tensorflow) and R(dplyr, plotly).\nFamiliarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).\nExcellent communication skills.\nAbility to work in a team.\nOutstanding analytical and problem-solving skills.\nBSc in Computer Science, Mathematics or similar field.\nGood to have AWS or GCP skillset or Docker.",
         "Noida",
         "539530.5",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Self-employed",
         "Colleges & Universities",
         "Education",
         "Unknown / Non-Applicable",
         "4.5",
         "4.3",
         "4.6",
         "4.7",
         "4.6"
        ],
        [
         "224",
         "Tech27 Systems Ltd.",
         "DATA SCIENTIST",
         "4.0",
         "The required skills are :\nPost graduate degree in Statistics, Math or any other with strong analytical background .\nMust have exposure to Big Data analytics..\nNeed Strong mathematical background (calculus, linearalgebra, probability and statistics).\nApplied Machine Learning experience (regression and classification, supervised, and unsupervised learning) is a plus.\nMust be a quick learner and capable to solve complex problems in multiple domains.\nSkill Set : Language - C#,C++, Python or R, Scripting - Java script Position Type : Permanent Qualification : Any postgraduate degree with analytics Experience : 0 - 4 Yrs Salary Package :Best in Industry Job Location : Calicut, Kerala, India Recruitment Process : Technical Interview & HR interview\n\nWe’re always on the look out for dynamic individuals, so if you think you have what it takes to be part of our forward thinking team, then please send us your CV to hr@tech27.com.",
         "Calicut",
         "438178.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Computer Hardware Development",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.6",
         "2.2",
         "3.5",
         "2.8",
         "3.8"
        ],
        [
         "226",
         "Ventra Health, Inc.",
         "Data Analyst",
         "3.3",
         "Job Summary:\nVentra Health is seeking a skilled Data Analyst to help answer tough questions with data. The mission of the Data Analytics and Automation team is to partner with the business units to provide tools for data-driven decisions through data visualization and reporting, statistical analysis, machine learning and automation.\nEssential Functions and Tasks:\nMeet with internal and external stakeholders to gather detailed requirements and design analytic solutions leveraging centrally managed reporting tools such as Power BI and OLAP Cubes\nCreate visually appealing reports and dashboards that intuitively present information\nLeverage the data warehouse as basis of reporting through ad-hoc querying of data to gain insights and drive design\nWork with end-users on self-service analytics through Power BI by assisting in training and support\nAssist scrum team with testing, data analysis, and design reviews\nAssist product owner in maintenance and build out of product backlog of analytics and automation solutions\nKeep up to date with evolving technologies such as machine learning and AI\nEducation and Experience Requirements:\nBachelor's degree in Information Management, Business Analytics, or Statistics\nMinimum of 5 years work experience as Data Analyst with at least 1 year in US Healthcare\nKnowledge, Skills, and Abilities:\nExcellent verbal and written communication skills\nExperienced with Microsoft SQL Management Studio\nExcellent SQL skills\nProven analytical and problem-solving skills including the ability to think critically and outside of the box\nSelf-motivated with the capability to meet deadlines on overlapping initiatives\nSound ethical judgment and the ability to work with sensitive information and PHI\nStrong time management and organizational skills\nPractical understanding of US healthcare\nPractical understanding of Accounting and Finance\nIND2",
         "India",
         "539530.5",
         "/yr (est.)",
         "1001 to 5000 Employees",
         "--",
         "Company - Private",
         "Healthcare Services & Hospitals",
         "Healthcare",
         "Unknown / Non-Applicable",
         "3.2",
         "3.0",
         "3.2",
         "3.0",
         "3.5"
        ],
        [
         "232",
         "Rojgar Group",
         "Data Analytics",
         "3.6",
         "Job Location\nRemote work from: All Location\nDescription\nJob Description\nBig data profile - Java, Scala, Spark, Python, HIVE, OOZIE, sqoop..\ngood to have is tableau skillset\nSpark, HDFS , Hive, sqoop\nOptional skills\nSpark streaming\nHbase\n\nHiring organization\nEmployment Type\nFull-time\nBase Salary\nINR500000-INR800000 Per year\nExperience\n3-5 years\nContacts\n8221901204, 7876212244\nDate posted\nJuly 26, 2021",
         "Remote",
         "650000.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.6",
         "2.0",
         "3.6",
         "2.3",
         "2.0"
        ],
        [
         "263",
         "Cybage",
         "BI- Data Analytics",
         "4.0",
         "BI- Data Analytics\nLocation:\nHyderabad, Gandhinagar, Pune, India\nExperience: 5+ years\nGood hands on experience on Power BI and SQL Development.\nGood Knowledge of ETL Process\nExposure to Big Data technologies is an advantage\nGood Communication and Analytical skills\nExposure to Agile - Scrum is preferable\nExposure to Jira is preferable\nLead the Technical aspect of the project and should be able to effectively presents technical issues and their impact to client / management\nWorks with geographically distributed team, and collaborates effectively to define and implement the requirements\nWork with PO/BA / Scrum Master to define the product backlog for the project from technical aspect.\nLead/ Mentor the mid-size Scrum team\nTake Ownership of delivery and ready to go extra mile to achieve the same",
         "Gāndhīnagar",
         "539530.5",
         "/yr (est.)",
         "5001 to 10000 Employees",
         "--",
         "Company - Public",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.9",
         "3.6",
         "4.0",
         "3.7",
         "3.9"
        ],
        [
         "270",
         "Bharat Light & Power",
         "Data Scientist",
         "4.0",
         "Location: Bangalore\nSkill Sets:\nStrong learning acumen\nTeam Player\nHigh sense of ownership\nAbility to work in a fast-paced and deadline driven environment\nPassion for technology\nHighly skilled at Data Interpretation\nProblem solver\n\nResponsibilities:\nHypothesis testing, insights generation, root cause analysis, factor analysis\nStatistical model (predictive & prescriptive) development using various statistical methods\nFamiliar with Machine learning techniques/algorithms\nTest/train the model, Improve Model accuracy, Execute & Monitor model performance, prepare reports based on the results of the analysis\nData Extraction from various platforms such as SQL/Big Data Platform/Google CP, Dataset Preparation (creation of base data, aggregation, transformation), performing EDA\n\nQualifications:\nExperience with data analysis/Modelling\nPostgraduate with Engineering Background\nHands on exposure of machine learning concepts and algorithms\nMust be fluent with any one of these Python, R or Java\nStrong in statistical & machine learning concepts\nKnowledge of Python Libraries – Scipy, Numpy, Pandas, IPython, Scikit-learn, Tensor-flow, Keras, Theano etc.\nStrong Python skills for data wrangling / analysis / visualization / modeling\nExperience with distributed big data processing (PySpark, Jupyter, Linux, AWS)\nDeployed at least one industrial project using supervised / unsupervised machine learning",
         "Bengaluru",
         "613600.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Enterprise Software & Network Solutions",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.1",
         "3.8",
         "4.0",
         "3.9",
         "3.9"
        ],
        [
         "273",
         "Zappian",
         "Data Analyst",
         "4.0",
         "About The Opportunity-\n\nA data analyst is responsible for organizing data related to sales numbers, market research, and behavior, The person utilizes technical expertise to ensure data is accurate and high-quality. Data is then analyzed, designed, and presented in a way that assists individuals, businesses, and organizations make better decisions.\n\nRoles and Responsibilities-\nUsing automated tools to extract data from primary and secondary sources\nRemoving corrupted data and related problems (cleaning, filtering, transformation of data)\nMaintaining databases, and data systems – reorganizing data in a readable format\nPerforming analysis to assess the quality and meaning of data\nFilter Data by reviewing reports and performance indicators to identify the problems.\nUsing statistical tools to identify, analyze, and interpret patterns and trends in complex data sets that could be helpful for the diagnosis and prediction\nPreparing reports for the management stating trends, patterns, and predictions using relevant data\nWorking with Tech team, and business team to identify process improvement opportunities, and propose system modifications.\nPreparing final analysis reports for the business team to understand the data-analysis steps, enabling them to take important decisions based on various facts and trends.\n\nRequired Skills-\nCleansing and preparing data\nAnalyzing and exploring data\nExpertise in statistics\nAnalyzing and visualizing data\nReports and dashboards\nCommunication and writing\nExpertise in the domain\nSolution-oriented\n\nTools Knowledge Required-\nSQL\nAdvanced Excel\nPython/R\nTableau /Microsoft Power BI\n\nExperience-\n\n1-2 years of experience in the Data management field.",
         "Bhopal",
         "608360.0",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Internet & Web Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.3",
         "2.9",
         "3.9",
         "3.3",
         "3.3"
        ],
        [
         "289",
         "Zappian",
         "Data Science Intern",
         "4.0",
         "About the Opportunity-\n\nWe are seeking a highly motivated and talented Data Science Intern to join our dynamic team. This internship provides a unique opportunity to gain hands-on experience in the field of data science while contributing to real-world projects.\n\nResponsibilities-\n\nData Analysis: Conduct exploratory data analysis and assist in interpreting large datasets to uncover trends, patterns, and insights. Python knowledge\nModel Development: Collaborate with the data science team to build and refine machine learning models for predictive analytics and decision support.\nData Cleaning and Preparation: Engage in data cleaning and preprocessing tasks to ensure the quality and reliability of datasets used in analysis and modeling.\nVisualization: Create visualizations to effectively communicate findings and assist in presenting results to both technical and non-technical stakeholders.\nCollaboration and Learning: Work closely with the team, actively participate in project discussions, and contribute to the continuous learning and improvement of data science practices within the organization.",
         "Bhopal",
         "539530.5",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Internet & Web Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.3",
         "2.9",
         "3.9",
         "3.3",
         "3.3"
        ],
        [
         "300",
         "Tridiagonal Solutions",
         "Data Science Intern",
         "3.4",
         "Tridiagonal Solutions Pvt. Ltd. (https://dataanalytics.tridiagonal.com/) is one of the premium consultants providing innovative process engineering and technologically advanced solutions to fortune 100 companies globally.\nWhat we do: We leverage advanced Modeling & analytics, workflow automation, and data science techniques to provide solutions to the process industry verticals like Oil & gas, Energy & Power, food, pharma and Chemicals. We are one of the thought leaders in our space due to unique/niche expertise we possess and collaborate with process excellence teams of world’s largest corporate houses in the US and Europe such as Reliance, Pertamina, Exxon, Marathon, P&G, Unilever, Pfizer, J&J, Mondelez, Chevron, Shell, Adidas, etc.).\nAbout an Opportunity: We are looking for some talented candidate who is willing to learn and explore the potential of Generative AI in the space of manufacturing industry. Being a data scientist, you will be the part of our incubation and innovation team, exploring latest techniques using Generative AI to identify and deploy opportunities of workflow automation and repetitive tasks of statistics and modeling.\nPurpose: Our Process Data Analytics team work on providing the solutions using the data strategy, data aggregation / cleansing, advanced performance modelling using ML/AI framework and statistical methods (Python, R, Matlab). The role demands consulting approach to work with customers and help them with training, Proof of Concept (POC) and troubleshooting with analytics platform.\nEssential Duties and Key Competencies:\nStrong with NLP and OCR techniques\nExperience in working with structured / Unstructured dataset\nExperience in working with PDF – textual information, scanned images\nExperience in working with OpenAI APIs\nVery strong with python coding\nWill be responsible for developing use cases using AWS and Azure Generative AI tech stacks\nStrong understanding of Deep learning techniques\nGood communication skills\nShould be good with exploring new ideas related to application regarding manufacturing operations\nQualifications:\nBachelor’s degree in Computer science / Chemical engg. / Mech Engg.\nMinimum 2 yrs of hands-on experience with coding in python\nStrong coding experience in python\nOptionally – Having an exposure of AWS and Azure tech stacks is added advantage\nStrong with data science libraries and tools commonly used in the Jupyter ecosystem.\nKnowledge of machine learning frameworks like TensorFlow or PyTorch\nVALUES\nResults and Accountability\nInnovation\nTransparency and Integrity\nInclusiveness\nSense of urgency\nCollaboration and Teamwork\nTeamwork\nEducation/Skills/Experience:\nBachelor’s degree in Computer science / Chemical engg. / Mech Engg.\nWork Mode: Work from Office (Mandatory)\nLocation: Pune.\nContact Details:\nMs. Apeksha Jadhav (HR Manager) – apeksha.jadhav@tridiagonal.com or hr@tridiagonal.com",
         "Pune",
         "539530.5",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "$5 to $25 million (USD)",
         "3.4",
         "2.8",
         "3.0",
         "2.9",
         "3.2"
        ],
        [
         "322",
         "Dentsu Aegis Network",
         "Data management Intern",
         "3.6",
         "The purpose of this role is to provide real-world experience, learning industry technical and professional skills, abilities and activities to contribute to the Dentsu network.\nJob Title:\nData management Intern\nJob Description:\nKey responsibilities: • Works in a team-based, fast-paced, detail-oriented environment • Is resourceful, has an aptitude for learning new skills and initiative to participate in advanced projects • Conducts research to support business needs • Utilises platforms to manage and update team / client programmes • Supports the goals and initiatives of the team / client / business • Gains industry exposure • Participates in networking and mentorship opportunities\nLocation:\nBangalore\nBrand:\nHappy Marketer\nTime Type:\nFull time\nContract Type:\nTemporary",
         "Bengaluru",
         "539530.5",
         "/yr (est.)",
         "5001 to 10000 Employees",
         "--",
         "Company - Public",
         "Advertising & Public Relations",
         "Media & Communication",
         "Unknown / Non-Applicable",
         "3.4",
         "3.2",
         "3.7",
         "3.4",
         "3.5"
        ],
        [
         "330",
         "TechnoServe Inc.",
         "Data Analyst Associate - PMA",
         "4.1",
         "Job Description: Associate / Senior Associate (Analyst / Research)\nReporting to: Program Lead / Senior Project Manager\n\nThe incumbent will support programs and would work closely with the Program Lead or Senior Project\nManager. She/he will be accountable for drafting strategies, content development, reviewing progress and reporting internally all program communications, data management and analytics. The incumbent can be placed at any of our project locations.\n\nShe/he will also be responsible for:\nSupport the Program Lead for program activities,\nSupport Business Development team for program reporting and design across multiple thematic areas,\nSupport Practice Lead in Donor / Client facing support functions,\nSupport Finance, Human Resource (HR) and other support function in program management.\n\nThe key responsibilities for the PMA:\nSupport Program Lead/managers for business and program development through content development, outreach and donor pitch decks, data quality assessments and data analysis\nBuild high-quality program proposals / reports for donors, key stakeholders like Third Party Agencies,\nTechnoServe’s US Head Quarters and Program teams\nCoordinate with Monitoring and Evaluation team for development and management of central data and reports repository for program tracking of deliverables\nengage with the Monitoring and evaluation team to support program research, impact studies and analysis\nResponsible for submission of Monthly Progress Reports (MPRs), Annual Reports (ARs) and other Periodic Reports as per program/donor requirements\nextensively engage with the program teams based in different locations to ensure timely and high\nquality update of MISes and relevant MoVs for program components\nWork with TechnoServe Fellows in their assignments e.g. value chain studies, strategic documents, and/or design other analytical frameworks\n\nSupport other cross-functional teams in the achievement of program deliverables, and multi-task on internal deliverables to support senior management\nHelp promote the Program and TechnoServe’s work with immediate and related stakeholders through\ncreation and dissemination of a variety of communication collateral and knowledge presentations.\nwrite publishable case studies/social media posts for the program\n\nAlong with the TechnoServe team bring learnings from past TechnoServe successes and proven best practices to the program implementation.\n\nPreferred Skills & Experience:\n\nThis role calls for an intrinsically motivated and passionate individual, looking to work in a cross-functional role for program research, proposal writing, design, and development of ongoing and new projects in India.\nPreferred skills include:\n\nGraduate or postgraduate in Business Administration, Economics, Liberal Studies or similar discipline\n2 to 4 years of experience in a corporate or development sector with a keenness to work on poverty-related challenges facing agriculture, and rural and micro-entrepreneurs in India.\nExcellent data analytical skills and large data management in Advanced Excel is a Must, with good communication skills (written and oral) and an ability to build a convincing argument.\nAbility to understand and work on different business models\nShould have excellent MS Excel skills and should have the ability to synthesize large amounts of data into consumable information\nShould have a self-learning attitude towards understanding and improving program's data capture, monitoring and reporting systems and enhancing efficiency\nDemonstrated ability to work with a diverse team, spread across diverse geographies and to deliver in a time bound program\nWillingness to travel in non-metro project locations as and when required.",
         "Mumbai",
         "522673.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Grantmaking & Charitable Foundations",
         "Non-profit & NGO",
         "Unknown / Non-Applicable",
         "4.1",
         "3.6",
         "4.3",
         "4.1",
         "4.0"
        ],
        [
         "350",
         "EIE Instruments",
         "Data Analyst",
         "3.9",
         "Job Description\nCompany:\nEIE Instruments Pvt. Ltd.\n\nLocation:\nEllisbridge, Ahmedabad\n\nFull Time:\nPermanent\n\nSalary:\n15000/- to 20000/-\n\nAbout Us : EIE Instruments engaged in manufacturing, marketing and Calibration of Scientific Instruments and Testing Equipments for various applications.\n\nAbout the Role : As a Data Analyst here, you'll be our detective of information. Your job is to gather, clean, and study data to help us figure out what it's telling us. You'll work with different teams to make sure we're using the information wisely.\n\nResponsibilities : ·Work with teams to understand what data we need. Get data from different places and make sure it's clean and ready to use. Look closely at the data to find patterns and stories it's trying to tell us. Make graphs and reports to show others what you've found. Help us find ways to improve based on what the data is saying. Check and make sure the data we use is accurate and reliable\n\nCandidate Qualification : A degree in Math, Statistics, Computer Science, or something similar. Experience in a job that involves working with data. Skills in using tools like SQL, Python/R, and programs to make graphs. Proficiency in Microsoft Office, CRM, ERP and software programs. Experienced candidates required in the same or relatable field\n\nContact us to Apply : yuti@eieinstruments.com / career@eieinstruments.com\n\nWebsite: https://www.eieinstruments.com/\n\nMin Experience\n2\nMax Experience\n3",
         "Ahmedabad",
         "17500.0",
         "/mo (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Machinery Manufacturing",
         "Manufacturing",
         "Unknown / Non-Applicable",
         "3.2",
         "3.9",
         "3.3",
         "3.2",
         "3.8"
        ],
        [
         "351",
         "Maruti Suzuki India Ltd",
         "Data Analyst - R&D",
         "3.9",
         "Responsibilities:\nArchitect a data-based solution for the business problem presented.\nCollaborate with different MSIL Departments for their data requests & build solutions that automate their daily tasks thereby saving man hours.\nUnderstand the Time-Series Telematics data generated from the vehicle.\nClean up and Prepare datasets for modeling, get involved in ETL process if required.\nBuild KPIs/metrics by applying data transformation techniques such as aggregation, resampling, filtering etc.\nExploratory data and get insights. Present the descriptive stats and insights to the domain experts. Find meaningful patterns in data, detect seasonality and trend, establish cause and effect relationships in data. Develop & Test hypothesis in collaboration with the domain experts.\nDesign features, shortlist features, study feature importance, decide the ML strategy. Build data pipelines for data extraction, cleaning, transforming, feature extraction, and machine learning\n\nData modelling, selection of an appropriate machine learning / deep learning model, data pipeline setup for model training, hyper-parameter tuning, validation and test. Apply ensemble model techniques (if required)\nReporting & Visualization: Comprehension of reports, visualization of data in the form of plots, generate reports using BI tools, develop live updating dashboards.\nTechnical Skills / Experience:\nEssential:\nMust have a hands-on experience with Python. Worked on libraries- Numpy, Pandas, Matplotlib.\nExperience building and training machine learning models for classification, regression and clustering (e.g. Generalized Linear Models, Boosting, Decision Trees, Neural Networks, SVM, Bayesian Methods, time series models, KMeans, Hierarchical clustering etc.)\nKnowledge about summarizing data, generating graphs, charts and reports.\nDesirable:\nExperience with BI tools - Power BI, IBM Cognos etc.\nExperience building RESTful APIs.\nExperience with back-end/front-end development.\nWorking experience with cloud computing platforms such as AWS / IBM\nAbility to write scalable SQL queries\nExperience in Spark or other distributed computing frameworks.\nExperience in time-series/IoT data analytics\nExposure to automotive systems, automobile basics, Controller Area Network protocol (CAN protocol) etc.\nBehavioral\n\nExcellent interpersonal skills\nCreativity and ability to bring in innovative ideas for Kaizen and solving everyday problem\nEducational Requirement:\nBE/ B Tech with 60% marks and certification course/diploma in Data science",
         "Bengaluru",
         "824049.0",
         "/yr (est.)",
         "10000+ Employees",
         "--",
         "Company - Public",
         "Transportation Equipment Manufacturing",
         "Manufacturing",
         "$10+ billion (USD)",
         "3.7",
         "4.0",
         "3.4",
         "3.3",
         "3.1"
        ],
        [
         "367",
         "APA Engineering",
         "Data Analyst",
         "4.0",
         "We believe in the power of talented individuals who are passionate about making a difference. If you're seeking a rewarding career that fosters growth, innovation, and a supportive work environment, you've come to the right place.\nData Analyst\nUpto 2 years of experience as Data Analyst\n\nYour Work Life at APA Engineering\nNor is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain.\nShape your career\nBring your ideas and pursue innovative career tracks, opportunities, and job rotations.\nLearn and grow\nEnhance your professional development through education and training.\nKeep current\nOur skills training helps you keep pace with the changing workplace.\nStay healthy\nBe well with health plans that help you support your loved ones.\nPerformance Award\nBring your ideas and pursue innovative career tracks, opportunities, and job rotations.",
         "Chennai",
         "387298.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Company - Private",
         "Architectural & Engineering Services",
         "Construction, Repair & Maintenance Services",
         "Less than $1 million (USD)",
         "3.2",
         "3.1",
         "3.3",
         "3.0",
         "3.2"
        ],
        [
         "368",
         "NISC Export Services",
         "Data Mapping",
         "3.6",
         "Job title\nData Analyst\nReports To Team Leader - Data Mapping\n\nJob Purpose\n\nMatch & Map field data between two databases (one of which is XML) mostly related to Published\nliterature.\n\nDuties and Responsibilities\n\nPrimary responsibility of the candidate includes:\nMapping input files against EPMARC XML Schema document\nRunning scripts and batch files\nWork as part of a team, as well as independently\nAbility to absorb & note information in meetings/training\nExperience of working to tight schedules in a daily or weekly content publishing environment\n\nQualifications\n\nEducation:\n\nA Degree in any discipline.\nCandidates with a degree in Library Science are preferred.\n\nSkills & Abilities\nSound knowledge of XML\nGood analytical skills\nHands on experience in Regular Expressions\nKnowledge in Microsoft Visual Studio/Notepad++\nExposure to MARC Catalogs is desirable\n\nExperience\n1+ years in content management projects\n\nWorking Conditions\n\nWork Location: NES Office, Hyderabad\nWork Timings: 9:00 AM to 06:30 PM\nWork Days: 5 Days a week",
         "Hyderābād",
         "539530.5",
         "/yr (est.)",
         "201 to 500 Employees",
         "--",
         "Company - Private",
         "Computer Hardware Development",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.0",
         "3.1",
         "3.1",
         "3.4",
         "3.8"
        ],
        [
         "372",
         "Transaction Network Services",
         "Data Scientist",
         "3.4",
         "An extraordinarily talented group of individuals work together every day to drive TNS' success, from both professional and personal perspectives. Come join the excellence!\nOverview\nTransaction Network Services (TNS), a Koch Industries company is seeking a talented and motivated data scientist to work within our AI Labs, India. As a Data Scientist, you will play a crucial role in analyzing complex datasets, building statistical and deep learning models, and implementing machine learning solutions. You will work closely with cross-functional teams to extract insights from data and contribute to data-driven decision-making processes.\nResponsibilities\nPrimary Responsibilities:\nUtilize expertise in statistical analysis, machine learning, and deep learning techniques to solve complex international business problems.\nDevelop, train, and deploy predictive models using machine learning frameworks and tools.\nPerform data preprocessing, feature engineering, and exploratory data analysis to identify patterns and trends.\nCollaborate with domain experts and stakeholders to understand business requirements and translate them into analytical solutions.\nApply cloud engineering principles to design and deploy scalable and efficient AI solutions in the cloud environment.\nCollaborate with software engineers to integrate machine learning models into production systems.\nImplement MLOps practices to automate model training, deployment, and monitoring processes.\nCommunicate complex findings and insights to both technical and non-technical stakeholders through clear and concise reports and visualizations.\nQualifications\nEducation and Experience:\nAdvanced degree in computer science, machine learning, statistical methods, or related field.\n2 - 5+ years of industry experience in a data science role.\nProficiency in Python programming language and experience with popular data science and machine learning frameworks (e.g., TensorFlow, PyTorch, scikit-learn).\nKnowledge of MLOps practices and experience with tools such as Docker, AWS EMR, or AWS Sagemaker.\nSolid understanding of data preprocessing techniques, feature engineering, and exploratory data analysis.\nKnowledge in developing scalable data architectures in a cloud environment.\nDemonstrated ability to work with large data sources with a focus on data privacy and security.\nSolid foundation in software engineering principles.\nBackground in software development process and tools with a focus on Jira.\nExperienced in working in a geographically distributed team environment.\nExperience working for leadership located in other countries and cultures as well as large time zone shifts.\nCommunications:\nExcellent communication & presentation skills.\nStrong teamwork, communication skills, passion, creativity, productivity & learning agility.\nStrong written and verbal communications skills working with internationally based colleagues.\nAbility to articulate and interpret analytical results from developed programs.\nRelated Knowledge base:\nBig data technologies such as Hadoop, Spark, or Hive.\nKnowledge of software engineering principles and experience collaborating with software development teams.\nTest design/design of experiments.\nDecision Tree analysis.\nMathematical programming and optimization\nIf you are passionate about technology, love personal growth and opportunity, come see what TNS is all about!\nTNS is an equal opportunity employer. TNS evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic.",
         "Noida",
         "474342.0",
         "/yr (est.)",
         "501 to 1000 Employees",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "$100 to $500 million (USD)",
         "3.2",
         "3.3",
         "3.3",
         "2.9",
         "3.4"
        ],
        [
         "380",
         "JP infotech",
         "Big Data Engineer",
         "3.9",
         "SR. BIG DATA ENGINEER\nETL BIGDATA AWS SQL DATA ANALYTICS PYTHON NOSQL CI/CD PIPELINE MACHINE LEARNING\nExperience:4 Years To 6 Years\nWork Model : Remote (Hybrid is ok if in Pune)\nWe are looking for a Sr. Data Engineer to lead the data engineering/algorithm development\nplatform.\nThe role involves managing the current team of data engineers with extensive experience in\nbuilding data pipelines for the product catering to millions of potential users, designing and\ndeploying machine learning and big data algorithms with modern/serverless architecture.\nAdditionally, the applicant is expected to have significant leadership experience along with\nstrong academic qualifications.\nThe successful candidate will be very hands on and capable of leading multidisciplinary\nteams\nwho thrive under a high performing work environment.\nThe candidate will work in close collaboration with the DataScience, Product and Design\nteams and acts as a liaison between engineering and cross functional leadership within the\norganization.\nKey Responsibilities:\n● Full accountability and ownership for engineering and execution of data operations\n● Provide hands on guidance and technical leadership to the team to deploy machine\nlearning algorithms for our ●Python-based data pipelines\n●Work closely with data scientists to productionize their models\n●Writing data models, data validation tests and database queries to support all the aspects\nof data integration and application development\n●Draft design documents that translate requirements into code\n●Deal with challenges associated with handling large volumes of data\n●Assume responsibilities from technical design through technical client support\n● Manage expectations with internal stakeholders and context-switch in a fast paced\nenvironment. Thrive in an environment that uses AWS extensively\n● Keep abreast of technology and contribute to the engineering strategy\n● Champion best development practices and provide mentorship\nJob Type: Permanent\nSalary: Up to ₹1,700,000.00 per year\nExperience:\nBig data: 4 years (Required)\nWork Location: Remote",
         "Remote",
         "1700000.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "5.0",
         "4.2",
         "4.7",
         "4.2",
         "4.2"
        ],
        [
         "388",
         "CapB InfoteK",
         "Remote nCode GlyphWorks enginnering Test Data Analyst",
         "1.0",
         "For one of our ongoing project, we need experienced nCode GlyphWorks engineering Test Data Analyst.\n\nThis is a Remote position and can be done from anywhere in the world including India. We accept candidates who can work Part Time as well as Full time.\n\nCandidates should have strong experience in nCode GlyphWorks Fundamental and Fatigue Analysis and will be involved in Time Series Data - Sensors, Accelerometer, LVDT, Pressure, Temperature, etc.\nAny experience involving Trucks is a plus.\n\nIf interested, rush your resume, with contact details and the expected monthly salalry.",
         "Bengaluru",
         "619793.0",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Business Consulting",
         "Management & Consulting",
         "Unknown / Non-Applicable",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0"
        ],
        [
         "394",
         "ONX",
         "ZOHO Data Analyst",
         "2.8",
         "About ONX HOMES:\nONX Homes is an integrated Design Tech company on a mission to reshape the home building industry. Founded by construction experts, design thinkers, and technology leaders, we utilize human-centric design, environmentally conscious materials, and offsite manufacturing technology to create beautiful homes and sustainable communities. We partner with landowners and leverage our unique vertically integrated capabilities and advanced offsite construction facilities to build and deliver sustainable, high-quality homes in half the time of onsite construction.\nRecruitment Policy:\nONX Homes will recruit based on merit and in compliance with all relevant legislation and is committed to recruitment and selection processes that are open, competitive, and based on merit. We are committed to valuing diversity and promoting equality.\nRole:- We’re looking for a Zoho Data & Insights Analyst to join our CRM Team.\nYour Role: You will be a key member of the team providing high quality, timely insights to the business to enable proactive decision making and improve business operations. You will have a natural drive to identify and solve problems with data and help data become a strategic asset for Onx Homes.\nJob Requirements\nDeliver regular and adhoc data, reporting and analytics requests for Sales and Marketing.\nAnalyze and interpret data from various data sources.\nDerive key insights from analysis and present back to Sales and Marketing in a digestible form.\nBuild high quality reports and dashboards with self-service capabilities and packaged insights.\nBe an advocate for data quality; work closely with the team to provide feedback on improving processes and solutions to ensure data quality processes are embedded so that insights are only generated from the highest quality of data.\nWork with the leadership team to help review data requirements to understand the challenges and how data will address the problem and provide solutions.\nYour Experience\nZoho Experience is must and should have experince in creating reports & Dashboards on Zoho CRM & zoho Analytics.\nExperience in carrying out data analysis and providing insights to the business in growing, dynamic organizations\nExperience manipulating and interpreting large datasets\nUsed to working closely with business stakeholders across different departments to help understand business goals and challenges\nExperience working across different technology platforms and business systems (including CRM tools such as Zoho CRM and SAP)\nProficient in Excel/Zoho Sheets and Smartsheet\nExcellent written and verbal communication abilities\nExcellent Time Management skills, ability to effectively work across multiple projects and manage competing deadlines\n\nThe Perks\n\nWith competitive compensation and great benefits, you will enjoy our fast-growing startup workstyle within an incredible culture. We’ll give you all the tools you need to succeed so you can grow and develop with us. For additional information on what it’s like to work at ONX Homes, visit our Careers page (https://www.onxhomes.com/careers)\n\nYour Future\n\nONX Homes provides a work environment that promotes employee growth and development. We are searching for an individual who wants to grow with the company and will strive to improve performance. If you are driven, personable, and energetic, there will be additional opportunities for you here at ONX Homes.\n\nIf this sounds like you, you should apply right away so we can discuss how you can be a part of this exciting, fast-paced organization!\nONX is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\nK2jQJBDja0",
         "Bengaluru",
         "316571.0",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Real Estate",
         "Real Estate",
         "Unknown / Non-Applicable",
         "2.7",
         "3.0",
         "2.7",
         "2.7",
         "2.7"
        ],
        [
         "395",
         "Universal Electronics Inc.",
         "Software Engineer (Data Science)",
         "3.5",
         "At UEI you will be part of a world class team that is working to innovate and revolutionize the meaning of ‘wireless control’. Whether it’s via chips, software licenses or turnkey products, we are continuing to reinvent how consumers interact with devices and services in their home.\nEach day we make the connected home smarter, easier to connect and use, and more sustainable. We delight our Fortune 100 customers such as Comcast, Apple, Samsung, Google, Vivint and Daikin with ground breaking wireless technology solutions such as advanced, voice-enabled remote controls, cloud control solutions, extreme low power Bluetooth silicon with energy harvesting capabilities, smart thermostats and sensors and many other IoT solutions.\n\nBrief Summary of Responsibilities:\nWork on end-to-end data science lifecycle from building Proof of concept model to production ready models\nAnalyze large amounts of information to discover trends and patterns, ability to manipulate data and draw insights from large data sets in terms of terabytes\nBuild models with machine-learning algorithms and Deep Learning\nStrong Analytical, Problem Solving and Critical Thinking skills.\nPropose solutions and strategies to business challenges.\nWriting reusable, testable, and efficient code in Python\nSupport the front-end developers ML Ops team by integrating their work with the Python application.\n\nQualifications / Skills:\nB.E. Computer science\nMachine Learning and Deep learning experience of 2+ years.\nProficiency of various ML algorithms for supervised and unsupervised Learning. Including but not limited to ANN and CNN.\nGood experience in Python: pandas, Scikit Learn. NumPy.\nFamiliar with statistical tests, distributions, maximum likelihood estimators, Hypothesis Testing, probability etc.\nVery good knowledge of SQL, MS Word, Excel, Access, and PowerPoint\nCommunicate proficiently internally and externally, with technical and non-technical audiences\n\nGood to have:\nPresent information using data visualization techniques\nKnowledge of deployment of ML Models on Azure\nKnowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark etc.\n\n\nUniversal Electronics Inc. (NASDAQ: UEIC) is the worldwide leader in universal control and sensing technologies for the smart home. Its broad portfolio of patents includes QuickSet® software that utilizes the world’s most complete knowledge graph to detect and interact with thousands of entertainment and smart home devices. The company designs, develops, and manufactures innovative products that are used by the world’s leading brands in the audio, video, subscription broadcasting, connected home, home energy management, and mobile device markets. UEI’s many first-to-market innovations have helped transform the home entertainment control, home security, and home energy management and sensing industries.\n\nUniversal Electronics Inc. is an equal employment opportunity employer. We are proud of our diverse workforce and we believe having diverse teams that everyone brings their whole self to work everyday is key to all of our success. We welcome all people of different experiences, backgrounds, perspectives and abilities.",
         "Bengaluru",
         "528092.0",
         "/yr (est.)",
         "201 to 500 Employees",
         "--",
         "Company - Public",
         "Electronics Manufacturing",
         "Manufacturing",
         "$25 to $50 million (USD)",
         "3.5",
         "2.8",
         "3.0",
         "3.0",
         "3.6"
        ],
        [
         "427",
         "Tata Insights and Quants",
         "Data Scientist",
         "3.8",
         "COMPANY OVERVIEW\nTata Group is an Indian multinational conglomerate company headquartered in Mumbai, India. It encompasses seven business sectors: communications and information technology, engineering, materials, services, energy, consumer products and chemicals. Tata Group was founded in 1868 by Jamsetji Tata as a trading company. It has operations in more than 80 countries across six continents. Tata Group has over 100 operating companies with each of them operating independently.\nTata Sons is the promoter of all key Tata companies and holds the bulk of shareholding in these companies.\n\nBACKGROUND The Tata companies together serve over million consumer and commercial customers today across several products and services. In order for the Tata companies to better understand customer and client needs and preferences, action life stages, needs, value, and potential, and enhance value and experience; the Tata companies need to develop robust data and information management capability and customer analytics. The vision is to eventually create the best in-house capability for data analytics amongst any large corporate. To achieve the above aims, it has been decided to establish an independent Tata company focused on building a common data analytics platform and help Tata Group companies. This company is being incubated in the initial phase as a division of Tata Industries and will subsequently be structured as a separate company to build Big Data Analytics and Data Science capabilities catering to but not limited to the ‘Consumer’ brands of the group.\n\nTata Insights and Quants – Journey to Date\nCompany: Tata - Insights and Quants – A Newly started division by Tata Industries.\nhttp://www.livemint.com/Companies/PCgvCZILuJKV68UKVHZRJO/With-new-analytics-arm-Tata-aims-to-make-better-sense-of-da.html\nEmployer Brand: Tata iQ in 18 months of its inception was recognized in the list of Analytics India Magazine’s (AIM)\nTop 10 most desirable Analytics Indian Firms to work for in 2016:\nhttp://analyticsindiamag.com/top-10-analytics-firm-wish-worked-2016/\nGenerating Value for Customer: Fourteen Tata companies are partnering Tata Insights and Quants (Tata iQ), a Big Data firm, to analyse data collected from users, consumers and make sense of it to put changes in place\nhttp://www.livemint.com/Companies/5om8ebrv6p02jGCcRB3j3K/Tata-companies-use-Big-Data-to-craft-strategies.html\nhttps://cio.economictimes.indiatimes.com/news/strategy-and-management/how-ranjit-satyanath-plugs-into-it-to-power-up-croma-for-the-digital-era/65050926\nContributing to Community through big data:\nIn line with the Tata group’s philosophy of giving back more to the society than what it takes, Tata iQ, Tata group’s big data and decision Sciences Company.\nOkhai partners with Tata iQ to deliver big impact through big data\n\nCompany : Tata Insights and Quants\nRole : Data Scientist\nLevel : Analyst – Associate - Senior Associate\nRole Type : Individual Contributor\nLocation : Mumbai | Bangalore | Jamshedpur | Kalinga Nagar – All Options open\n\nJob Description The incumbent will be part of the Predictive Analytics, Digital Analytics, Data Sciences, Advanced Visualization, Insights & Experimentation team and will report to the Manager/Senior Manager. He/she will be an individual contributor working on multiple data sciences, advanced visualization and data management initiatives across multiple companies and industries leveraging traditional and big data. The incumbent will have the unique opportunity to witness the application of analytics across multiple industry verticals. Close partnership with business and the senior leadership of multiple Tata Companies will enable a clear understanding of the business perspectives and the application of analytics for solving real business problems.\n\nKey Responsibilities:\nApply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating/ running simulations to drive optimisation and improvement across business functions\nAssess accuracy of new data sources and data gathering techniques\nPerform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution\nApply Supervised, Unsupervised, Reinforcement Learning and Deep Learning algorithms\nApply advanced Machine Learning Algorithms and Statistics:\no Regression, Simulation, Scenario Analysis\no Time Series Modelling\no Classification - Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes\no Clustering, K-Means\no Ensemble Models - Random Forest, Boosting, Bagging\no Neural Networks\nLead and manage Proof of Concepts and demonstrate the outcomes quickly\nDocument use cases, solutions and recommendations\nWork analytically in a problem-solving environment\nWork in a fast-paced agile development environment\nCoordinate with different functional teams to implement models and monitor outcomes\nWork with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions - Operations, Products, Sales, Marketing, HR and Finance teams\nHelp program and project managers in the design, planning and governance of implementing Data Science solutions\n\nExperience and Skills:\n2-7 years of professional working experience in Analytics\nExperience in Retail, Financial Services and Manufacturing\nExperience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets\nExperience with distributed data/ computing tools: Hadoop, Hive, Spark, Python\nExperience with SQL\nExperience visualizing/ presenting data for stakeholders using matplot, ggplot or Excel or Tableau\nExcellent written and verbal communication skills for coordinating across teams\nEducation qualification:\nBachelors/ Masters in a quantitative discipline (Statistics, Econometrics, Mathematics, Engineering and Science)\n\nReach us on careers@tataiq.com",
         "Jamshedpur",
         "1000000.0",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Transportation Equipment Manufacturing",
         "Manufacturing",
         "$10+ billion (USD)",
         "3.7",
         "3.5",
         "3.7",
         "3.4",
         "3.5"
        ],
        [
         "434",
         "Spice Money",
         "Data Engineer",
         "3.9",
         "Spice Group>Spice Money Limited>Banking & Payments>Technology & Research>Core Tech>Shared Services\nIndia>North>Punjab>Punjab>Sas Nagar>Mohali\nRequired Experience\n2 - 4 Years\nPosted On\n12 Jan 2024\nBasic Section\nBAND\nI\nGrade\nG3\nDesignation\nSenior Engineer\nCampus/Non Campus\nNon- Campus\nEmployment Type\nPermanent\nHiring Type\nREPLACEMENT\nTAT\n45\nConfidential\nNo\nClosing Date\n31 Mar 2024\nCreated By\nVarundeep Kaur\nOrganisational\nEntity\nSpice Group\nCompany\nSpice Money Limited\nSBU\nBanking & Payments\nFunction\nTechnology & Research\nSub-Function\nCore Tech\nMicro Team\nShared Services\nCountry\nIndia\nRegion\nNorth\nState\nPunjab\nStat State\nPunjab\nDistrict\nSAS Nagar\nLocation\nMohali\nSkills\nSkill\nBIG DATA\nSQL\nDATA WAREHOUSING\nPYTHON 3\nMinimum Qualification\nB.TECH/B.E\nMCA\nCERTIFICATION\nNo data available\nWorking Language\nENGLISH\nJob Description\n2-4 yrs of experience\nProficient in Google BigQuery (aggregate functions, performance tuning, best practices of Google BigQuery, GCP, SQL, Data PubSub and Python\nMust have understanding of Dimensional modelling, ETL, Data Pipelines, Documentation like creating Source Target mapping\nBuilding scalable systems, performance tuning and secure programming",
         "Mohali",
         "687235.0",
         "/yr (est.)",
         "201 to 500 Employees",
         "--",
         "Company - Private",
         "Financial Transaction Processing",
         "Finance",
         "Unknown / Non-Applicable",
         "3.9",
         "3.8",
         "4.1",
         "3.7",
         "3.6"
        ],
        [
         "448",
         "Vega Intellisoft",
         "Data Scientist",
         "4.5",
         "Job Description:\nQualification: BE/BTECH/ME/MTech/MSC(CS/IT/IS/Data Science/Artificial Intelligence/Machine Learning/Deep Learning/Statistics Engineering (1st Division 70%)\n\nKey Skills:\nQualification: BE/BTECH/ME/MTech/MSC(CS/IT/IS/Data Science/Artificial Intelligence/Machine Learning/Deep Learning/Statistics Engineering (1st Division 70%)\n\nLocation:\nBangalore\n\nRequired Experience:\nMax 1 yrs\n\nPositions:\n2",
         "Bengaluru",
         "606630.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Private Practice / Firm",
         "Business Consulting",
         "Management & Consulting",
         "Unknown / Non-Applicable",
         "4.4",
         "4.3",
         "4.2",
         "4.4",
         "4.5"
        ],
        [
         "460",
         "Growexx",
         "Data Engineer",
         "4.2",
         "GrowExx is looking for a smart and passionate Data Engineer, who will design and fill a bespoke data warehousing environment for our company.\nKey Responsibilities:\nDesign architecture for data activation inclusive of an API gateway that can be consumed by client applications.\nDevelop and maintain scalable pipelines that deploy data out to product applications, website data Layers, and digital advertising platforms (Salesforce, Google, Facebook, etc.).\nDevelop and deploy scalable new features.\nIdentify and fix bugs to resolve data quality issues in a timely manner.\nDevelop, maintain, update Tableau reporting views and data sources.\nImplement a data monitoring framework that ensures production tables are always accurate.\nTake data science/machine learning model prototypes and prepare them for production deployments.\nImprove real-time data availability on an as-needed basis for activation use-cases.\nBuild pipelines that ingest digital advertising data on an as-needed basis.\nDocument all pipelines and maintain a data catalogue.",
         "Remote",
         "539530.5",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.3",
         "4.3",
         "4.1",
         "4.2",
         "4.3"
        ],
        [
         "463",
         "Capria Ventures",
         "Data Analyst",
         "4.0",
         "About The Role\nCapria is seeking a highly analytical and adaptable team player with a systems-oriented mindset to spearhead data analysis and reporting within the firm. The successful candidate will be responsible for overseeing Capria’s investment/portfolio data and systems, as well as generating impact and financial reports for Limited Partners (LPs) and internal stakeholders. The ideal candidate will possess around 2-4 years of relevant experience in data analysis and reporting, along with a foundational understanding of venture capital and/or private equity in emerging markets. Enthusiasm for working in a fast-paced, dynamic, global startup\nenvironment is essential. The candidate will collaborate closely with the Latin America team, as well as other teams focused on Africa and India. We are seeking a standout individual who will rapidly progress and assume increasing responsibility, both in the scope and depth of their leadership.\nAdditionally, the ideal candidate will be passionate about data and finding creative ways to unlock value through analysis and visualizations. They will thrive in the abstract, and be motivated to ensure complete and accurate data as a matter of pride and principle. They will be excited to and take satisfaction in developing processes that improve the efficiency of the teams they work with that will contribute to the overall success of Capria.\nKey Responsibilities\nData Management & Analysis – Develop and maintain data processes and systems\nMaintain, and update templates of reporting processes and systems.\nProject manage updates of reporting templates by gathering input from various stakeholders and contributors.\nSupport the transition of our data systems to Quantium, our new portfolio management software.\nImprove and maintain data architecture of data collection, analysis, and reporting in Quantium.\nReporting – Work closely with the investment and finance teams to generate quarterly and half-yearly reports for LPs\nProject manage and drive timely completion of quarterly and annual reports.\nCoordinate across global teams to gather and present updated information.\nParticipate in investment team meetings to keep abreast of latest developments in our protfolio, and strategize with leadership on what to present in reports.\nPortfolio Management – Generate analysis and reports for investment, fundraising and marketing teams to create value for the portfolio\nGenerate portfolio analysis used to drive internal discussions among the investment team to deliver 1:1 portfolio support and management.\nDisseminate and lead data presentation for fundraising and marketing teams, with analysis based on requirements from the respective audience.\nSupport data analysis work within transactions and current portfolio investments, as well as assist with ongoing strategy.\nSupport investment teams with transactions through direct involvement in fund and direct investments.\nData Auditing – Ensure the highest quality of data is reported promptly\nConduct deep quality assurance of our quarterly reporting data across our portfolio funds and companies with the investment team.\nInterface with and support fund managers as needed to collect quality data, on time.\nQualifications\nFluent in English.\nBachelor’s (Master’s preferred) degree in Economics, Finance, Business, Data Analytics or related fields.\n2-4 years of data analysis and reporting experience, including high proficiency in spreadsheets (Excel and Google Sheets), preferably in venture capital.\nTechnical skills in big data and visualizations (Python, SQL, etc.) is a plus.\nHigh attention to detail, highly organized, and highly motivated.\nExcellent at managing multiple projects across global teams, with comfort working across timezones and different cultures (this role requires early morning or late evenings 3-5x a week given the global nature of our team).\nDemonstrated aptitude as a fast learner of new skills and knowledge and a strong aptitude for using state-of-the-art technology for info-sharing & communications.\nExperience in a start-up environment or equivalent. We’re not a large firm – just like us, we’re looking for someone who knows how to get a lot done with limited resources and is looking to be challenged and interested in growing.\nOutstanding communication skills, both written and verbal.\nThrives on managing hard challenges in ambiguous settings.\nRole Type Full time\nLocation Bangalore, India",
         "Bengaluru",
         "562805.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Private Practice / Firm",
         "Investment & Asset Management",
         "Finance",
         "Less than $1 million (USD)",
         "3.4",
         "3.3",
         "4.0",
         "4.2",
         "3.8"
        ],
        [
         "480",
         "BOLD LLC",
         "Data Science Architect- I",
         "4.0",
         "Data Science Architect- I\nat BOLD View all jobs\nNoida, Uttar Pradesh, India\nBOLD is seeking Data Scientists who will be the part of the existing Data Science team, where you’ll combine your analytical skills and business knowledge to deliver key insights to our Product and Management teams. You’ll help drive product development using our vast user data sets to enhance our current products and to help us find inferences and relationships in this data to build new products.\nJOB DESCRIPTION\nABOUT THIS TEAM\nThe Data Science department at BOLD is responsible for discovering patterns and trends in datasets to get insights, creating predictive algorithms and data models, improving the quality of data or product offerings by utilizing machine learning techniques, distributing suggestions to other teams and top management, and using data tools such as Python and SQL.\nThe Data Science team actively collaborates with other vertical teams such as Engineering, Portals, BI, Product, Legal. Most of the projects are focused around problems that require a mix of natural language processing and machine learning. Some of the active projects are resume parsing, ranking, summary generation, data quality and scoring, content generation, job recommendations, and conversion analysis. Apart from the business initiatives, the team also explores state of the art methods and keeps them upto to date with technology.\nWHAT YOU’LL DO\n\nWHAT YOU’LL NEED\n\nWHAT’S GOOD TO HAVE\n\nEXPERIENCE-\n\nBENEFITS\nOUTSTANDING COMPENSATION\nCompetitive salary\nTax-friendly compensation structure\nBi-annual bonus\nAnnual/bi-annual appraisal\nEquity in company\n100% FULL HEALTH BENEFITS\nGroup Mediclaim, personal accident, & term life insurance\nPracto Plus health membership\nMental health and wellness (apps, additional support, etc.)\nFLEXIBLE TIME AWAY\n24 days paid leaves\nDeclared fixed holidays\nPaternity and maternity leave\nCompassionate and marriage leave\nCovid leave (up to 7 days)\nADDITIONAL BENEFITS\nInternet and home office reimbursement\nIn-office catered lunch, meals, and snacks\nCertification policy\nCab pick-up and drop-off facility\nQuarterly team outings and annual party\nMarriage, birthday, and Diwali gifts\nABOUT BOLD\nWE TRANSFORM WORK LIVES\nAs an established global organization, BOLD helps people find jobs. Our story is one of growth, success, and professional fulfillment. We create digital products that have empowered millions of people in 180 countries to build stronger resumes, cover letters, and CVs. The result of our work helps people interview confidently, finding the right job in less time. Our employees are experts, learners, contributors, and creatives.\nWE CELEBRATE AND PROMOTE DIVERSITY AND INCLUSION\nWe value our position as an Equal Opportunity Employer. We hire based on qualifications, merit, and our business needs. We don' discriminate regarding race, color, religion, gender, pregnancy, national origin or citizenship, ancestry, age, physical or mental disability, veteran status, sexual orientation, gender identity or expression, marital status, genetic information, or any other applicable characteristic protected by law.\nNoida, Uttar Pradesh, India\nData Science Architect- I\nSick time policy\n\"); }); $(\".cont-box ul li\").html(function(index,html){ return html.replace(\"Open office environment, lounge areas and shuffleboard.\",\"\nOpen office environment.\n\"); }); $(\".cont-box ul li\").html(function(index,html){ return html.replace(\"PPO & HMO m\",\"M\"); }); }, 2000); })(jQuery);",
         "Noida",
         "469574.0",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Architectural & Engineering Services",
         "Construction, Repair & Maintenance Services",
         "Unknown / Non-Applicable",
         "4.0",
         "5.0",
         "4.0",
         "5.0",
         "4.0"
        ],
        [
         "489",
         "IPRO INDIA",
         "Data Analyst",
         "4.0",
         "Candidate must have:\nStrong data warehousing concepts\nSQL database management\nPython programming experience\nPower BI development exposure\nHave experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data\nExperience in writing complex SQL statements and debugging/improving performance of SQL statements using query profilers",
         "Chandigarh",
         "539530.5",
         "/yr (est.)",
         "Unknown",
         "--",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.0",
         "4.0",
         "4.0",
         "4.0",
         "4.0"
        ],
        [
         "491",
         "Sciera",
         "Jr Data Scientist",
         "4.0",
         "Sciera Inc. is an Atlanta based Data & Technology company with 12 years’ experience of driving business results of Fortune 500 companies with unparalleled computing power and advanced data science capabilities. Sciera is focused on how we deal with petabyte-scale data and our applications' ability to respond to consumers in milliseconds. As a result, our technologies and solutions assist businesses in turning Big Data into actionable insights — and insights into business success.\nAt Sciera, our employees and their families are important to us. We seek individuals who are self-motivated, dependable, and who are equally productive while working alone or in a group. We expect candidates to contribute to the culture, diversity, and autonomy in which we thrive.\nSo, if you love challenges, a fast paced environment and being on the cutting edge of technology - this could very well be the opportunity for you.\nJob Location: Chennai\nJob Description 1-3 years of experience\nWe are looking for a Data Scientist to analyze large amounts of raw data to find patterns that will help improve our client’s business processes. We will rely on you to build data products to extract valuable business insights.In this role, you should be highly analytical with a flair for analysis, math/statistics and AIML.Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our clients analyze trends to make better decisions and develop new data products to serve our clients better.\nRoles and responsibilities :\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data\nAnalyze large amounts of information to discover trends and patterns\nBuild predictive models and machine-learning algorithms\nCombine models through ensemble modeling\nPresent information using data visualization techniques\nPropose solutions and strategies to business challenges\nCollaborate with engineering and product development teams\nRequirements and skills\nProven experience as a Data Scientist or Data Analyst\nData management for analytics\nExperience in data mining and text mining\nUnderstanding of machine-learning and operations research\nAnalytical mind and business acumen\nStrong math skills (specifically applied statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills\n\nKnowledge of Tools:\nKnowledge of R, SQL and Python\nExperience with at least two of the major frameworks – Tensorflow, PyTorch, MXNet,\nSagemaker, H2O, SparkML\nFamiliarity with Scala, Java or C++ is an asset\nExperience using business intelligence tools (e.g. Tableau) and data frameworks (e.g.\nHadoop)\nShould have completed models in customer life cycle and/or NLP\nEducational Qualifications:\nBachelors in Computer Science, Engineering or relevant field or master degree in computer applications, Statistics, Operations research\nMaster degree in Data Science or other quantitative field is preferred\nExperience\nShould have a 1-3 years of experience in analytics/data science in marketing/customer\nanalytics and NLP.",
         "Chennai",
         "670820.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "--",
         "Company - Private",
         "Accounting & Tax",
         "Finance",
         "Less than $1 million (USD)",
         "4.4",
         "3.5",
         "4.1",
         "4.3",
         "4.4"
        ],
        [
         "543",
         "Fusemachines",
         "Data Analyst",
         "3.4",
         "About Fusemachines\nFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 450 full-time employees). Fusemachines' AI educational program has made world-class AI education available, accessible, and affordable to students around the world. Fusemachines seeks to bring its global expertise in AI to transform companies around the world.\nAbout the role:\nThis is a remote, contract position, working in the Publishing-Media Sector.\nJob Description:\nWe are seeking a talented and experienced Data Analyst with expertise in Looker and GCP to join our team. The Data Analyst will be responsible for gathering, interpreting, analyzing, and visualizing large and complex datasets to provide insights and support data-driven decision-making within the organization.\nResponsibilities:\nData Collection and modeling: Gathering data from various sources such as EDWH,databases, spreadsheets, APIs, and other relevant sources to support business requirements, and creating the corresponding semantic layer.\nData Cleaning and Preprocessing: Reviewing and organizing data to ensure accuracy, consistency, and completeness. This may involve handling missing values, removing outliers, and transforming data into a suitable format for analysis.\nData Analysis: Applying statistical techniques and analytical methods to examine data and identify patterns, trends, relationships and insights that inform business decisions. This will involve using tools like SQL, LookML, Python or specialized data analysis software.\nData Visualization : Design, build and maintain visual representations of data through charts, graphs, and dashboards to communicate insights effectively to stakeholders. Data visualization tools like Looker and Python libraries (e.g., Matplotlib, Seaborn).\nReporting: Summarizing and presenting findings from data analysis in a clear and concise manner. This includes creating reports, slide decks, or presentations to communicate insights and recommendations to non-technical stakeholders.\nData Governance including Quality Assurance: Ensuring the accuracy, consistency, and integrity of data by performing quality checks and validation procedures. This involves identifying and resolving data discrepancies or errors.\nData Mining: Identifying patterns, trends, and correlations in large datasets to extract meaningful information and support business objectives. This may involve using techniques like clustering, classification, regression, or association analysis.\nStatistical Analysis: Applying statistical methods and hypothesis testing to draw meaningful conclusions from data and make data-driven recommendations.\nIdentifying and implementing best practices for business intelligence, data visualization, reporting and analysis.\nCollaborating with Teams: Working closely with cross-functional teams, such as business analysts, data engineers, data scientists and decision-makers, to understand their requirements, provide analytical support, identify key metrics and contribute to data-driven initiatives to solve business challenges.\nContinuous Learning: Staying updated with industry trends, new analytical techniques, and tools to enhance data analysis capabilities and improve efficiency.\nRequirements:\nBachelor's or master's degree in a quantitative field such as statistics, mathematics, or computer science.\nAt least 5 years of experience in data analytics, with a focus on business intelligence and data visualization.\nAt least 2 years of experience using Looker and LookML to design, build, and maintain dashboards and reports.\nStrong SQL skills and experience working with complex data sets and Enterprise Data Warehouse, especially BigQuery.\nExperience with data modeling and schema design, using LookML.\nStrong analytical and problem-solving skills with the ability to translate complex data into actionable insights.\nExcellent communication and collaboration skills with the ability to work effectively with cross-functional teams.\nDemonstrated leadership experience with the ability to mentor and develop junior analysts.\nExperience with data governance, data quality, and data integrity efforts.\nAttention to Detail: Being meticulous and paying attention to detail is critical in data analysis. Small errors or inaccuracies can lead to misleading results, so data analysts should have a keen eye for detail and double-check their work.\nStrong Communication Skills are essential to convey complex technical concepts and insights to non-technical stakeholders effectively.\nStrong project management skills with the ability to manage multiple projects and priorities simultaneously.\nIf you are a data-driven individual with strong leadership skills and experience with Looker, LookML and GCP, we encourage you to apply for this exciting opportunity.\nEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.\neP0fVOwo3b",
         "Pune",
         "364005.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "--",
         "Company - Private",
         "Internet & Web Services",
         "Information Technology",
         "$25 to $50 million (USD)",
         "3.6",
         "3.0",
         "3.7",
         "3.0",
         "3.6"
        ],
        [
         "560",
         "GUJARAT FLUOROCHEMICALS",
         "Data Scientist",
         "4.3",
         "Company\nGujarat Fluorochemicals Limited\n\nGrade / Level\nIII\n\nDivision / Department\nInformation Technology\n\nJob Purpose\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nLead the Analytics track for Project e-Parivartan which comprises of approx. 35 dashboards, 200 KPI’s, 120 personas,\nBuild up the 5 yrs Data Analytics track in consultation with relevant stakeholders with a vision of making the organization a Data Driven Organisation,\nIdentify the use cases around AI/ ML – Video Analytics and Natural language Processing on the CCTV footages for identification and automatic alerts for safety violation (Fire hazard, PPE ….)\nSkills and academic qualifications\nFunctional Skills\nFunctional Skills Required -\n• Strong problem solving skills with an emphasis on product development. • Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets. • Knowledge of a variety of machine learning\nTechnical Skills required -\nMin 12 Months Data Science Program; Project Management (PMP, PRINCE); Certifications in any of the below domains: Statistics and machine learning, coding languages C, C++, Java Script, Databases: R, Python, SLQ, etc. Any of the repor",
         "Noida",
         "591502.0",
         "/yr (est.)",
         "1001 to 5000 Employees",
         "--",
         "Company - Private",
         "Chemical Manufacturing",
         "Manufacturing",
         "$10+ billion (USD)",
         "4.2",
         "4.0",
         "4.0",
         "3.8",
         "3.9"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 57
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_avg_estimate</th>\n",
       "      <th>salary_estimate_payperiod</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_founded</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>revenue</th>\n",
       "      <th>career_opportunities_rating</th>\n",
       "      <th>comp_and_benefits_rating</th>\n",
       "      <th>culture_and_values_rating</th>\n",
       "      <th>senior_management_rating</th>\n",
       "      <th>work_life_balance_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Data Scientist - Fresher</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Data-Scientist-Fresher-24011\\n\\nLoca...</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>416516.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Junior Software Engineer - Data Science - Fresher</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Data-Scientist-Fresher-24012\\n\\nLoca...</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>382623.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Data-Scientist-24012\\n\\nLocation: Hy...</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TVS Supply Chain Solutions</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Department\\nWarehouse Operations\\nJob posted o...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>255288.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>501 to 1000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Shipping &amp; Trucking</td>\n",
       "      <td>Transportation &amp; Logistics</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Data Scientist - Python/ Machine Learning</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Machine-Learning-24015\\n\\nLocation: ...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Data-Scientist-240111\\n\\nLocation: G...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>469574.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Reliance Games</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>3.5</td>\n",
       "      <td>CAREERS\\nData Analyst\\nCompany: Reliance Games...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>469012.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Video Game Publishing</td>\n",
       "      <td>Media &amp; Communication</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Syneos Health Clinical</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Description\\nSyneos Health® is a leading fully...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Biotech &amp; Pharmaceuticals</td>\n",
       "      <td>Pharmaceutical &amp; Biotechnology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>JLL</td>\n",
       "      <td>Sustainability Data Analyst</td>\n",
       "      <td>3.9</td>\n",
       "      <td>JLL supports the Whole You, personally and pro...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>$5 to $10 billion (USD)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Rotork</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Company Description\\n\\nRotork is the market-le...</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>569738.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electronics Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$500 million to $1 billion (USD)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Veranex, Inc.</td>\n",
       "      <td>Clinical Data Coordinator 2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Minimum Requirement\\nBachelor’s degree or inte...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Chemical Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Junior Machine Learning Engineer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Machine-Learning-24016\\n\\nLocation: ...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>WCG</td>\n",
       "      <td>Jr. Data &amp; Analytics Engineer</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Description and Requirements\\nJOB SUMMARY:\\nTh...</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Biotech &amp; Pharmaceuticals</td>\n",
       "      <td>Pharmaceutical &amp; Biotechnology</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Leegality</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is a remote position.\\nCompany Mission\\n\\...</td>\n",
       "      <td>India</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Ventra Health, Inc.</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Job Summary:\\nThe Data Engineer works independ...</td>\n",
       "      <td>India</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Healthcare Services &amp; Hospitals</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>BDIPlus</td>\n",
       "      <td>Data Engineer ||</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Job Role: Data Engineer II\\nAbout BDIPlus:\\nBD...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1025086.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>UnitedHealthcare</td>\n",
       "      <td>Data Analyst 2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>663325.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Healthcare Services &amp; Hospitals</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Toolyt</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.8</td>\n",
       "      <td>We are looking for a passionate certified Data...</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>/mo (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Konceive Development Center Pvt. Ltd.</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Job Description:\\nResponsibilities:\\nCollect, ...</td>\n",
       "      <td>Panchkula</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>/mo (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Public Relations</td>\n",
       "      <td>Media &amp; Communication</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Syneos Health Clinical</td>\n",
       "      <td>Senior Clinical Data Associate</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Description\\nSenior Clinical Data Associate\\nS...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Biotech &amp; Pharmaceuticals</td>\n",
       "      <td>Pharmaceutical &amp; Biotechnology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Junior Machine Learning Engineer - Fresher</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Machine-Learning-Fresher-24011\\n\\nLo...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Tech27 Systems Ltd.</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The required skills are :\\nPost graduate degre...</td>\n",
       "      <td>Calicut</td>\n",
       "      <td>438178.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Ventra Health, Inc.</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Job Summary:\\nVentra Health is seeking a skill...</td>\n",
       "      <td>India</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Healthcare Services &amp; Hospitals</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Rojgar Group</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Job Location\\nRemote work from: All Location\\n...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Cybage</td>\n",
       "      <td>BI- Data Analytics</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BI- Data Analytics\\nLocation:\\nHyderabad, Gand...</td>\n",
       "      <td>Gāndhīnagar</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>5001 to 10000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Bharat Light &amp; Power</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Location: Bangalore\\nSkill Sets:\\nStrong learn...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>613600.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Zappian</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>About The Opportunity-\\n\\nA data analyst is re...</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>608360.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet &amp; Web Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Zappian</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.0</td>\n",
       "      <td>About the Opportunity-\\n\\nWe are seeking a hig...</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet &amp; Web Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Tridiagonal Solutions</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Tridiagonal Solutions Pvt. Ltd. (https://dataa...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$5 to $25 million (USD)</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Dentsu Aegis Network</td>\n",
       "      <td>Data management Intern</td>\n",
       "      <td>3.6</td>\n",
       "      <td>The purpose of this role is to provide real-wo...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>5001 to 10000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Advertising &amp; Public Relations</td>\n",
       "      <td>Media &amp; Communication</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>TechnoServe Inc.</td>\n",
       "      <td>Data Analyst Associate - PMA</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Job Description: Associate / Senior Associate ...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>522673.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Grantmaking &amp; Charitable Foundations</td>\n",
       "      <td>Non-profit &amp; NGO</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>EIE Instruments</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job Description\\nCompany:\\nEIE Instruments Pvt...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>/mo (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Machinery Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>Data Analyst - R&amp;D</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Responsibilities:\\nArchitect a data-based solu...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>824049.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Transportation Equipment Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>APA Engineering</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>We believe in the power of talented individual...</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>387298.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Architectural &amp; Engineering Services</td>\n",
       "      <td>Construction, Repair &amp; Maintenance Services</td>\n",
       "      <td>Less than $1 million (USD)</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>NISC Export Services</td>\n",
       "      <td>Data Mapping</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Job title\\nData Analyst\\nReports To Team Leade...</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Transaction Network Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>An extraordinarily talented group of individua...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>474342.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>501 to 1000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>JP infotech</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>3.9</td>\n",
       "      <td>SR. BIG DATA ENGINEER\\nETL BIGDATA AWS SQL DAT...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>CapB InfoteK</td>\n",
       "      <td>Remote nCode GlyphWorks enginnering Test Data ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For one of our ongoing project, we need experi...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>619793.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Business Consulting</td>\n",
       "      <td>Management &amp; Consulting</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>ONX</td>\n",
       "      <td>ZOHO Data Analyst</td>\n",
       "      <td>2.8</td>\n",
       "      <td>About ONX HOMES:\\nONX Homes is an integrated D...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>316571.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Universal Electronics Inc.</td>\n",
       "      <td>Software Engineer (Data Science)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>At UEI you will be part of a world class team ...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>528092.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electronics Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$25 to $50 million (USD)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Tata Insights and Quants</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>COMPANY OVERVIEW\\nTata Group is an Indian mult...</td>\n",
       "      <td>Jamshedpur</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Transportation Equipment Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Spice Money</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Spice Group&gt;Spice Money Limited&gt;Banking &amp; Paym...</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>687235.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Financial Transaction Processing</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Vega Intellisoft</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Job Description:\\nQualification: BE/BTECH/ME/M...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>606630.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Private Practice / Firm</td>\n",
       "      <td>Business Consulting</td>\n",
       "      <td>Management &amp; Consulting</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Growexx</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4.2</td>\n",
       "      <td>GrowExx is looking for a smart and passionate ...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Capria Ventures</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>About The Role\\nCapria is seeking a highly ana...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>562805.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Private Practice / Firm</td>\n",
       "      <td>Investment &amp; Asset Management</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Less than $1 million (USD)</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>BOLD LLC</td>\n",
       "      <td>Data Science Architect- I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Science Architect- I\\nat BOLD View all jo...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>469574.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Architectural &amp; Engineering Services</td>\n",
       "      <td>Construction, Repair &amp; Maintenance Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>IPRO INDIA</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Candidate must have:\\nStrong data warehousing ...</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Sciera</td>\n",
       "      <td>Jr Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sciera Inc. is an Atlanta based Data &amp; Technol...</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>670820.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Accounting &amp; Tax</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Less than $1 million (USD)</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Fusemachines</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.4</td>\n",
       "      <td>About Fusemachines\\nFusemachines is a leading ...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>364005.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet &amp; Web Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$25 to $50 million (USD)</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>GUJARAT FLUOROCHEMICALS</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Company\\nGujarat Fluorochemicals Limited\\n\\nGr...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>591502.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Chemical Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Cityinfo Services</td>\n",
       "      <td>DATA ANALYST</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Introduction\\nExecute processes to monitor dat...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>322490.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Advent InfoSoft Pvt Ltd</td>\n",
       "      <td>Data Management Executive</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Responsibilites\\nFree listing, positing trade ...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>E2E Infoware Management Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist / Advanced Analytics – Machine ...</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>536656.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>2003</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>--</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>JOB PURPOSE\\n\\nBuild &amp; Deploy Machine learning...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Transportation Equipment Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Sitare Foundation</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Overview\\nDesignation: Data Entry Operator\\nDe...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>204573.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Civic, Welfare &amp; Social Services</td>\n",
       "      <td>Non-profit &amp; NGO</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>KRSNAA Diagnostics</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Experience: 1-5 Yrs\\nJob Location: Pune Head O...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>182166.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Medical Testing &amp; Clinical Laboratories</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Sanfoundry</td>\n",
       "      <td>Machine Learning Engineer - Fresher</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Code: Machine-Learning-Fresher-24012\\n\\nLo...</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>Education</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   company  \\\n",
       "4                               Sanfoundry   \n",
       "6                               Sanfoundry   \n",
       "12                              Sanfoundry   \n",
       "17              TVS Supply Chain Solutions   \n",
       "20                              Sanfoundry   \n",
       "33                              Sanfoundry   \n",
       "36                          Reliance Games   \n",
       "46                  Syneos Health Clinical   \n",
       "51                                     JLL   \n",
       "55                                  Rotork   \n",
       "68                           Veranex, Inc.   \n",
       "80                              Sanfoundry   \n",
       "84                                     WCG   \n",
       "97                               Leegality   \n",
       "149                    Ventra Health, Inc.   \n",
       "160                                BDIPlus   \n",
       "164                       UnitedHealthcare   \n",
       "192                                 Toolyt   \n",
       "203  Konceive Development Center Pvt. Ltd.   \n",
       "208                 Syneos Health Clinical   \n",
       "218                             Sanfoundry   \n",
       "224                    Tech27 Systems Ltd.   \n",
       "226                    Ventra Health, Inc.   \n",
       "232                           Rojgar Group   \n",
       "263                                 Cybage   \n",
       "270                   Bharat Light & Power   \n",
       "273                                Zappian   \n",
       "289                                Zappian   \n",
       "300                  Tridiagonal Solutions   \n",
       "322                   Dentsu Aegis Network   \n",
       "330                       TechnoServe Inc.   \n",
       "350                        EIE Instruments   \n",
       "351                Maruti Suzuki India Ltd   \n",
       "367                        APA Engineering   \n",
       "368                   NISC Export Services   \n",
       "372           Transaction Network Services   \n",
       "380                            JP infotech   \n",
       "388                           CapB InfoteK   \n",
       "394                                    ONX   \n",
       "395             Universal Electronics Inc.   \n",
       "427               Tata Insights and Quants   \n",
       "434                            Spice Money   \n",
       "448                       Vega Intellisoft   \n",
       "460                                Growexx   \n",
       "463                        Capria Ventures   \n",
       "480                               BOLD LLC   \n",
       "489                             IPRO INDIA   \n",
       "491                                 Sciera   \n",
       "543                           Fusemachines   \n",
       "560                GUJARAT FLUOROCHEMICALS   \n",
       "567                      Cityinfo Services   \n",
       "571                Advent InfoSoft Pvt Ltd   \n",
       "575       E2E Infoware Management Services   \n",
       "584                Maruti Suzuki India Ltd   \n",
       "596                      Sitare Foundation   \n",
       "597                     KRSNAA Diagnostics   \n",
       "616                             Sanfoundry   \n",
       "\n",
       "                                             job_title  company_rating  \\\n",
       "4                             Data Scientist - Fresher             4.0   \n",
       "6    Junior Software Engineer - Data Science - Fresher             4.0   \n",
       "12                               Junior Data Scientist             4.0   \n",
       "17                                 Data Entry Operator             3.4   \n",
       "20           Data Scientist - Python/ Machine Learning             4.0   \n",
       "33                                      Data Scientist             4.0   \n",
       "36                                      Data Analytics             3.5   \n",
       "46                                    Data Scientist I             3.8   \n",
       "51                         Sustainability Data Analyst             3.9   \n",
       "55                                        Data Analyst             3.7   \n",
       "68                         Clinical Data Coordinator 2             4.0   \n",
       "80                    Junior Machine Learning Engineer             4.0   \n",
       "84                       Jr. Data & Analytics Engineer             3.2   \n",
       "97                                        Data Analyst             4.0   \n",
       "149                                      Data Engineer             3.3   \n",
       "160                                   Data Engineer ||             4.1   \n",
       "164                                     Data Analyst 2             3.6   \n",
       "192                                       Data Analyst             4.8   \n",
       "203                                       Data Analyst             4.6   \n",
       "208                     Senior Clinical Data Associate             3.8   \n",
       "218         Junior Machine Learning Engineer - Fresher             4.0   \n",
       "224                                     DATA SCIENTIST             4.0   \n",
       "226                                       Data Analyst             3.3   \n",
       "232                                     Data Analytics             3.6   \n",
       "263                                 BI- Data Analytics             4.0   \n",
       "270                                     Data Scientist             4.0   \n",
       "273                                       Data Analyst             4.0   \n",
       "289                                Data Science Intern             4.0   \n",
       "300                                Data Science Intern             3.4   \n",
       "322                             Data management Intern             3.6   \n",
       "330                       Data Analyst Associate - PMA             4.1   \n",
       "350                                       Data Analyst             3.9   \n",
       "351                                 Data Analyst - R&D             3.9   \n",
       "367                                       Data Analyst             4.0   \n",
       "368                                       Data Mapping             3.6   \n",
       "372                                     Data Scientist             3.4   \n",
       "380                                  Big Data Engineer             3.9   \n",
       "388  Remote nCode GlyphWorks enginnering Test Data ...             1.0   \n",
       "394                                  ZOHO Data Analyst             2.8   \n",
       "395                   Software Engineer (Data Science)             3.5   \n",
       "427                                     Data Scientist             3.8   \n",
       "434                                      Data Engineer             3.9   \n",
       "448                                     Data Scientist             4.5   \n",
       "460                                      Data Engineer             4.2   \n",
       "463                                       Data Analyst             4.0   \n",
       "480                          Data Science Architect- I             4.0   \n",
       "489                                       Data Analyst             4.0   \n",
       "491                                  Jr Data Scientist             4.0   \n",
       "543                                       Data Analyst             3.4   \n",
       "560                                     Data Scientist             4.3   \n",
       "567                                       DATA ANALYST             3.9   \n",
       "571                          Data Management Executive             2.6   \n",
       "575                                     Data Scientist             4.0   \n",
       "584                                     Data Scientist             3.9   \n",
       "596                                Data Entry Operator             3.0   \n",
       "597                                       Data Analyst             3.3   \n",
       "616                Machine Learning Engineer - Fresher             4.0   \n",
       "\n",
       "                                       job_description     location  \\\n",
       "4    Job Code: Data-Scientist-Fresher-24011\\n\\nLoca...    Hyderābād   \n",
       "6    Job Code: Data-Scientist-Fresher-24012\\n\\nLoca...    Hyderābād   \n",
       "12   Job Code: Data-Scientist-24012\\n\\nLocation: Hy...    Hyderābād   \n",
       "17   Department\\nWarehouse Operations\\nJob posted o...    Bengaluru   \n",
       "20   Job Code: Machine-Learning-24015\\n\\nLocation: ...       Mumbai   \n",
       "33   Job Code: Data-Scientist-240111\\n\\nLocation: G...      Gurgaon   \n",
       "36   CAREERS\\nData Analyst\\nCompany: Reliance Games...         Pune   \n",
       "46   Description\\nSyneos Health® is a leading fully...       Remote   \n",
       "51   JLL supports the Whole You, personally and pro...    Bengaluru   \n",
       "55   Company Description\\n\\nRotork is the market-le...      Chennai   \n",
       "68   Minimum Requirement\\nBachelor’s degree or inte...    Bengaluru   \n",
       "80   Job Code: Machine-Learning-24016\\n\\nLocation: ...       Remote   \n",
       "84   Description and Requirements\\nJOB SUMMARY:\\nTh...    Karnataka   \n",
       "97   This is a remote position.\\nCompany Mission\\n\\...        India   \n",
       "149  Job Summary:\\nThe Data Engineer works independ...        India   \n",
       "160  Job Role: Data Engineer II\\nAbout BDIPlus:\\nBD...    Bengaluru   \n",
       "164  Optum is a global organization that delivers c...    Bengaluru   \n",
       "192  We are looking for a passionate certified Data...       Jaipur   \n",
       "203  Job Description:\\nResponsibilities:\\nCollect, ...    Panchkula   \n",
       "208  Description\\nSenior Clinical Data Associate\\nS...       Remote   \n",
       "218  Job Code: Machine-Learning-Fresher-24011\\n\\nLo...        Noida   \n",
       "224  The required skills are :\\nPost graduate degre...      Calicut   \n",
       "226  Job Summary:\\nVentra Health is seeking a skill...        India   \n",
       "232  Job Location\\nRemote work from: All Location\\n...       Remote   \n",
       "263  BI- Data Analytics\\nLocation:\\nHyderabad, Gand...  Gāndhīnagar   \n",
       "270  Location: Bangalore\\nSkill Sets:\\nStrong learn...    Bengaluru   \n",
       "273  About The Opportunity-\\n\\nA data analyst is re...       Bhopal   \n",
       "289  About the Opportunity-\\n\\nWe are seeking a hig...       Bhopal   \n",
       "300  Tridiagonal Solutions Pvt. Ltd. (https://dataa...         Pune   \n",
       "322  The purpose of this role is to provide real-wo...    Bengaluru   \n",
       "330  Job Description: Associate / Senior Associate ...       Mumbai   \n",
       "350  Job Description\\nCompany:\\nEIE Instruments Pvt...    Ahmedabad   \n",
       "351  Responsibilities:\\nArchitect a data-based solu...    Bengaluru   \n",
       "367  We believe in the power of talented individual...      Chennai   \n",
       "368  Job title\\nData Analyst\\nReports To Team Leade...    Hyderābād   \n",
       "372  An extraordinarily talented group of individua...        Noida   \n",
       "380  SR. BIG DATA ENGINEER\\nETL BIGDATA AWS SQL DAT...       Remote   \n",
       "388  For one of our ongoing project, we need experi...    Bengaluru   \n",
       "394  About ONX HOMES:\\nONX Homes is an integrated D...    Bengaluru   \n",
       "395  At UEI you will be part of a world class team ...    Bengaluru   \n",
       "427  COMPANY OVERVIEW\\nTata Group is an Indian mult...   Jamshedpur   \n",
       "434  Spice Group>Spice Money Limited>Banking & Paym...       Mohali   \n",
       "448  Job Description:\\nQualification: BE/BTECH/ME/M...    Bengaluru   \n",
       "460  GrowExx is looking for a smart and passionate ...       Remote   \n",
       "463  About The Role\\nCapria is seeking a highly ana...    Bengaluru   \n",
       "480  Data Science Architect- I\\nat BOLD View all jo...        Noida   \n",
       "489  Candidate must have:\\nStrong data warehousing ...   Chandigarh   \n",
       "491  Sciera Inc. is an Atlanta based Data & Technol...      Chennai   \n",
       "543  About Fusemachines\\nFusemachines is a leading ...         Pune   \n",
       "560  Company\\nGujarat Fluorochemicals Limited\\n\\nGr...        Noida   \n",
       "567  Introduction\\nExecute processes to monitor dat...    Bengaluru   \n",
       "571  Responsibilites\\nFree listing, positing trade ...        Delhi   \n",
       "575  Data Scientist / Advanced Analytics – Machine ...      Chennai   \n",
       "584  JOB PURPOSE\\n\\nBuild & Deploy Machine learning...        Delhi   \n",
       "596  Overview\\nDesignation: Data Entry Operator\\nDe...      Gurgaon   \n",
       "597  Experience: 1-5 Yrs\\nJob Location: Pune Head O...         Pune   \n",
       "616  Job Code: Machine-Learning-Fresher-24012\\n\\nLo...    Hyderābād   \n",
       "\n",
       "     salary_avg_estimate salary_estimate_payperiod             company_size  \\\n",
       "4               416516.0                /yr (est.)        1 to 50 Employees   \n",
       "6               382623.0                /yr (est.)        1 to 50 Employees   \n",
       "12              539530.5                /yr (est.)        1 to 50 Employees   \n",
       "17              255288.0                /yr (est.)    501 to 1000 Employees   \n",
       "20              539530.5                /yr (est.)        1 to 50 Employees   \n",
       "33              469574.0                /yr (est.)        1 to 50 Employees   \n",
       "36              469012.0                /yr (est.)      51 to 200 Employees   \n",
       "46              539530.5                /yr (est.)         10000+ Employees   \n",
       "51              539530.5                /yr (est.)         10000+ Employees   \n",
       "55              569738.0                /yr (est.)   1001 to 5000 Employees   \n",
       "68              539530.5                /yr (est.)                  Unknown   \n",
       "80              539530.5                /yr (est.)        1 to 50 Employees   \n",
       "84              539530.5                /yr (est.)   1001 to 5000 Employees   \n",
       "97              539530.5                /yr (est.)      51 to 200 Employees   \n",
       "149             539530.5                /yr (est.)   1001 to 5000 Employees   \n",
       "160            1025086.0                /yr (est.)                  Unknown   \n",
       "164             663325.0                /yr (est.)         10000+ Employees   \n",
       "192              40000.0                /mo (est.)        1 to 50 Employees   \n",
       "203              35000.0                /mo (est.)        1 to 50 Employees   \n",
       "208             539530.5                /yr (est.)         10000+ Employees   \n",
       "218             539530.5                /yr (est.)        1 to 50 Employees   \n",
       "224             438178.0                /yr (est.)      51 to 200 Employees   \n",
       "226             539530.5                /yr (est.)   1001 to 5000 Employees   \n",
       "232             650000.0                /yr (est.)        1 to 50 Employees   \n",
       "263             539530.5                /yr (est.)  5001 to 10000 Employees   \n",
       "270             613600.0                /yr (est.)      51 to 200 Employees   \n",
       "273             608360.0                /yr (est.)                  Unknown   \n",
       "289             539530.5                /yr (est.)                  Unknown   \n",
       "300             539530.5                /yr (est.)      51 to 200 Employees   \n",
       "322             539530.5                /yr (est.)  5001 to 10000 Employees   \n",
       "330             522673.0                /yr (est.)      51 to 200 Employees   \n",
       "350              17500.0                /mo (est.)      51 to 200 Employees   \n",
       "351             824049.0                /yr (est.)         10000+ Employees   \n",
       "367             387298.0                /yr (est.)        1 to 50 Employees   \n",
       "368             539530.5                /yr (est.)     201 to 500 Employees   \n",
       "372             474342.0                /yr (est.)    501 to 1000 Employees   \n",
       "380            1700000.0                /yr (est.)        1 to 50 Employees   \n",
       "388             619793.0                /yr (est.)                  Unknown   \n",
       "394             316571.0                /yr (est.)                  Unknown   \n",
       "395             528092.0                /yr (est.)     201 to 500 Employees   \n",
       "427            1000000.0                /yr (est.)                  Unknown   \n",
       "434             687235.0                /yr (est.)     201 to 500 Employees   \n",
       "448             606630.0                /yr (est.)        1 to 50 Employees   \n",
       "460             539530.5                /yr (est.)      51 to 200 Employees   \n",
       "463             562805.0                /yr (est.)        1 to 50 Employees   \n",
       "480             469574.0                /yr (est.)                  Unknown   \n",
       "489             539530.5                /yr (est.)                  Unknown   \n",
       "491             670820.0                /yr (est.)        1 to 50 Employees   \n",
       "543             364005.0                /yr (est.)      51 to 200 Employees   \n",
       "560             591502.0                /yr (est.)   1001 to 5000 Employees   \n",
       "567             322490.0                /yr (est.)      51 to 200 Employees   \n",
       "571             539530.5                /yr (est.)        1 to 50 Employees   \n",
       "575             536656.0                /yr (est.)      51 to 200 Employees   \n",
       "584             539530.5                /yr (est.)         10000+ Employees   \n",
       "596             204573.0                /yr (est.)                  Unknown   \n",
       "597             182166.0                /yr (est.)                  Unknown   \n",
       "616             539530.5                /yr (est.)        1 to 50 Employees   \n",
       "\n",
       "    company_founded          employment_type  \\\n",
       "4                --            Self-employed   \n",
       "6                --            Self-employed   \n",
       "12               --            Self-employed   \n",
       "17               --        Company - Private   \n",
       "20               --            Self-employed   \n",
       "33               --            Self-employed   \n",
       "36               --        Company - Private   \n",
       "46               --        Company - Private   \n",
       "51               --         Company - Public   \n",
       "55               --         Company - Public   \n",
       "68               --        Company - Private   \n",
       "80               --            Self-employed   \n",
       "84               --        Company - Private   \n",
       "97               --        Company - Private   \n",
       "149              --        Company - Private   \n",
       "160              --        Company - Private   \n",
       "164              --         Company - Public   \n",
       "192              --        Company - Private   \n",
       "203              --        Company - Private   \n",
       "208              --        Company - Private   \n",
       "218              --            Self-employed   \n",
       "224              --        Company - Private   \n",
       "226              --        Company - Private   \n",
       "232              --        Company - Private   \n",
       "263              --         Company - Public   \n",
       "270              --        Company - Private   \n",
       "273              --        Company - Private   \n",
       "289              --        Company - Private   \n",
       "300              --        Company - Private   \n",
       "322              --         Company - Public   \n",
       "330              --        Company - Private   \n",
       "350              --        Company - Private   \n",
       "351              --         Company - Public   \n",
       "367              --        Company - Private   \n",
       "368              --        Company - Private   \n",
       "372              --        Company - Private   \n",
       "380              --        Company - Private   \n",
       "388              --        Company - Private   \n",
       "394              --        Company - Private   \n",
       "395              --         Company - Public   \n",
       "427              --        Company - Private   \n",
       "434              --        Company - Private   \n",
       "448              --  Private Practice / Firm   \n",
       "460              --        Company - Private   \n",
       "463              --  Private Practice / Firm   \n",
       "480              --        Company - Private   \n",
       "489              --        Company - Private   \n",
       "491              --        Company - Private   \n",
       "543              --        Company - Private   \n",
       "560              --        Company - Private   \n",
       "567              --        Company - Private   \n",
       "571              --        Company - Private   \n",
       "575            2003        Company - Private   \n",
       "584              --         Company - Public   \n",
       "596              --        Company - Private   \n",
       "597              --        Company - Private   \n",
       "616              --            Self-employed   \n",
       "\n",
       "                                    industry  \\\n",
       "4                    Colleges & Universities   \n",
       "6                    Colleges & Universities   \n",
       "12                   Colleges & Universities   \n",
       "17                       Shipping & Trucking   \n",
       "20                   Colleges & Universities   \n",
       "33                   Colleges & Universities   \n",
       "36                     Video Game Publishing   \n",
       "46                 Biotech & Pharmaceuticals   \n",
       "51                               Real Estate   \n",
       "55                 Electronics Manufacturing   \n",
       "68                    Chemical Manufacturing   \n",
       "80                   Colleges & Universities   \n",
       "84                 Biotech & Pharmaceuticals   \n",
       "97   Information Technology Support Services   \n",
       "149          Healthcare Services & Hospitals   \n",
       "160  Information Technology Support Services   \n",
       "164          Healthcare Services & Hospitals   \n",
       "192  Enterprise Software & Network Solutions   \n",
       "203           Advertising & Public Relations   \n",
       "208                Biotech & Pharmaceuticals   \n",
       "218                  Colleges & Universities   \n",
       "224            Computer Hardware Development   \n",
       "226          Healthcare Services & Hospitals   \n",
       "232  Information Technology Support Services   \n",
       "263  Information Technology Support Services   \n",
       "270  Enterprise Software & Network Solutions   \n",
       "273                  Internet & Web Services   \n",
       "289                  Internet & Web Services   \n",
       "300  Information Technology Support Services   \n",
       "322           Advertising & Public Relations   \n",
       "330     Grantmaking & Charitable Foundations   \n",
       "350                  Machinery Manufacturing   \n",
       "351   Transportation Equipment Manufacturing   \n",
       "367     Architectural & Engineering Services   \n",
       "368            Computer Hardware Development   \n",
       "372  Information Technology Support Services   \n",
       "380  Information Technology Support Services   \n",
       "388                      Business Consulting   \n",
       "394                              Real Estate   \n",
       "395                Electronics Manufacturing   \n",
       "427   Transportation Equipment Manufacturing   \n",
       "434         Financial Transaction Processing   \n",
       "448                      Business Consulting   \n",
       "460  Information Technology Support Services   \n",
       "463            Investment & Asset Management   \n",
       "480     Architectural & Engineering Services   \n",
       "489  Information Technology Support Services   \n",
       "491                         Accounting & Tax   \n",
       "543                  Internet & Web Services   \n",
       "560                   Chemical Manufacturing   \n",
       "567                              Real Estate   \n",
       "571            Computer Hardware Development   \n",
       "575                                       --   \n",
       "584   Transportation Equipment Manufacturing   \n",
       "596         Civic, Welfare & Social Services   \n",
       "597  Medical Testing & Clinical Laboratories   \n",
       "616                  Colleges & Universities   \n",
       "\n",
       "                                          sector  \\\n",
       "4                                      Education   \n",
       "6                                      Education   \n",
       "12                                     Education   \n",
       "17                    Transportation & Logistics   \n",
       "20                                     Education   \n",
       "33                                     Education   \n",
       "36                         Media & Communication   \n",
       "46                Pharmaceutical & Biotechnology   \n",
       "51                                   Real Estate   \n",
       "55                                 Manufacturing   \n",
       "68                                 Manufacturing   \n",
       "80                                     Education   \n",
       "84                Pharmaceutical & Biotechnology   \n",
       "97                        Information Technology   \n",
       "149                                   Healthcare   \n",
       "160                       Information Technology   \n",
       "164                                   Healthcare   \n",
       "192                       Information Technology   \n",
       "203                        Media & Communication   \n",
       "208               Pharmaceutical & Biotechnology   \n",
       "218                                    Education   \n",
       "224                       Information Technology   \n",
       "226                                   Healthcare   \n",
       "232                       Information Technology   \n",
       "263                       Information Technology   \n",
       "270                       Information Technology   \n",
       "273                       Information Technology   \n",
       "289                       Information Technology   \n",
       "300                       Information Technology   \n",
       "322                        Media & Communication   \n",
       "330                             Non-profit & NGO   \n",
       "350                                Manufacturing   \n",
       "351                                Manufacturing   \n",
       "367  Construction, Repair & Maintenance Services   \n",
       "368                       Information Technology   \n",
       "372                       Information Technology   \n",
       "380                       Information Technology   \n",
       "388                      Management & Consulting   \n",
       "394                                  Real Estate   \n",
       "395                                Manufacturing   \n",
       "427                                Manufacturing   \n",
       "434                                      Finance   \n",
       "448                      Management & Consulting   \n",
       "460                       Information Technology   \n",
       "463                                      Finance   \n",
       "480  Construction, Repair & Maintenance Services   \n",
       "489                       Information Technology   \n",
       "491                                      Finance   \n",
       "543                       Information Technology   \n",
       "560                                Manufacturing   \n",
       "567                                  Real Estate   \n",
       "571                       Information Technology   \n",
       "575                       Information Technology   \n",
       "584                                Manufacturing   \n",
       "596                             Non-profit & NGO   \n",
       "597                                   Healthcare   \n",
       "616                                    Education   \n",
       "\n",
       "                              revenue  career_opportunities_rating  \\\n",
       "4            Unknown / Non-Applicable                          4.5   \n",
       "6            Unknown / Non-Applicable                          4.5   \n",
       "12           Unknown / Non-Applicable                          4.5   \n",
       "17           Unknown / Non-Applicable                          3.2   \n",
       "20           Unknown / Non-Applicable                          4.5   \n",
       "33           Unknown / Non-Applicable                          4.5   \n",
       "36           Unknown / Non-Applicable                          3.8   \n",
       "46           Unknown / Non-Applicable                          3.5   \n",
       "51            $5 to $10 billion (USD)                          3.7   \n",
       "55   $500 million to $1 billion (USD)                          3.5   \n",
       "68           Unknown / Non-Applicable                          3.7   \n",
       "80           Unknown / Non-Applicable                          4.5   \n",
       "84         $100 to $500 million (USD)                          2.7   \n",
       "97           Unknown / Non-Applicable                          4.9   \n",
       "149          Unknown / Non-Applicable                          3.2   \n",
       "160          Unknown / Non-Applicable                          4.1   \n",
       "164          Unknown / Non-Applicable                          3.6   \n",
       "192          Unknown / Non-Applicable                          4.9   \n",
       "203          Unknown / Non-Applicable                          4.5   \n",
       "208          Unknown / Non-Applicable                          3.5   \n",
       "218          Unknown / Non-Applicable                          4.5   \n",
       "224          Unknown / Non-Applicable                          3.6   \n",
       "226          Unknown / Non-Applicable                          3.2   \n",
       "232          Unknown / Non-Applicable                          3.6   \n",
       "263          Unknown / Non-Applicable                          3.9   \n",
       "270          Unknown / Non-Applicable                          4.1   \n",
       "273          Unknown / Non-Applicable                          3.3   \n",
       "289          Unknown / Non-Applicable                          3.3   \n",
       "300           $5 to $25 million (USD)                          3.4   \n",
       "322          Unknown / Non-Applicable                          3.4   \n",
       "330          Unknown / Non-Applicable                          4.1   \n",
       "350          Unknown / Non-Applicable                          3.2   \n",
       "351                $10+ billion (USD)                          3.7   \n",
       "367        Less than $1 million (USD)                          3.2   \n",
       "368          Unknown / Non-Applicable                          3.0   \n",
       "372        $100 to $500 million (USD)                          3.2   \n",
       "380          Unknown / Non-Applicable                          5.0   \n",
       "388          Unknown / Non-Applicable                          1.0   \n",
       "394          Unknown / Non-Applicable                          2.7   \n",
       "395          $25 to $50 million (USD)                          3.5   \n",
       "427                $10+ billion (USD)                          3.7   \n",
       "434          Unknown / Non-Applicable                          3.9   \n",
       "448          Unknown / Non-Applicable                          4.4   \n",
       "460          Unknown / Non-Applicable                          4.3   \n",
       "463        Less than $1 million (USD)                          3.4   \n",
       "480          Unknown / Non-Applicable                          4.0   \n",
       "489          Unknown / Non-Applicable                          4.0   \n",
       "491        Less than $1 million (USD)                          4.4   \n",
       "543          $25 to $50 million (USD)                          3.6   \n",
       "560                $10+ billion (USD)                          4.2   \n",
       "567          Unknown / Non-Applicable                          4.0   \n",
       "571          Unknown / Non-Applicable                          2.6   \n",
       "575                $10+ billion (USD)                          4.7   \n",
       "584                $10+ billion (USD)                          3.7   \n",
       "596          Unknown / Non-Applicable                          3.0   \n",
       "597          Unknown / Non-Applicable                          3.4   \n",
       "616          Unknown / Non-Applicable                          4.5   \n",
       "\n",
       "     comp_and_benefits_rating  culture_and_values_rating  \\\n",
       "4                         4.3                        4.6   \n",
       "6                         4.3                        4.6   \n",
       "12                        4.3                        4.6   \n",
       "17                        2.9                        3.0   \n",
       "20                        4.3                        4.6   \n",
       "33                        4.3                        4.6   \n",
       "36                        3.2                        3.4   \n",
       "46                        3.5                        3.8   \n",
       "51                        3.5                        3.8   \n",
       "55                        3.2                        3.5   \n",
       "68                        3.4                        3.6   \n",
       "80                        4.3                        4.6   \n",
       "84                        3.1                        2.7   \n",
       "97                        4.8                        5.0   \n",
       "149                       3.0                        3.2   \n",
       "160                       4.0                        4.0   \n",
       "164                       3.5                        3.7   \n",
       "192                       4.6                        4.9   \n",
       "203                       4.6                        4.5   \n",
       "208                       3.5                        3.8   \n",
       "218                       4.3                        4.6   \n",
       "224                       2.2                        3.5   \n",
       "226                       3.0                        3.2   \n",
       "232                       2.0                        3.6   \n",
       "263                       3.6                        4.0   \n",
       "270                       3.8                        4.0   \n",
       "273                       2.9                        3.9   \n",
       "289                       2.9                        3.9   \n",
       "300                       2.8                        3.0   \n",
       "322                       3.2                        3.7   \n",
       "330                       3.6                        4.3   \n",
       "350                       3.9                        3.3   \n",
       "351                       4.0                        3.4   \n",
       "367                       3.1                        3.3   \n",
       "368                       3.1                        3.1   \n",
       "372                       3.3                        3.3   \n",
       "380                       4.2                        4.7   \n",
       "388                       1.0                        1.0   \n",
       "394                       3.0                        2.7   \n",
       "395                       2.8                        3.0   \n",
       "427                       3.5                        3.7   \n",
       "434                       3.8                        4.1   \n",
       "448                       4.3                        4.2   \n",
       "460                       4.3                        4.1   \n",
       "463                       3.3                        4.0   \n",
       "480                       5.0                        4.0   \n",
       "489                       4.0                        4.0   \n",
       "491                       3.5                        4.1   \n",
       "543                       3.0                        3.7   \n",
       "560                       4.0                        4.0   \n",
       "567                       3.9                        3.9   \n",
       "571                       3.1                        2.6   \n",
       "575                       4.7                        5.0   \n",
       "584                       4.0                        3.4   \n",
       "596                       3.3                        2.9   \n",
       "597                       3.0                        3.1   \n",
       "616                       4.3                        4.6   \n",
       "\n",
       "     senior_management_rating  work_life_balance_rating  \n",
       "4                         4.7                       4.6  \n",
       "6                         4.7                       4.6  \n",
       "12                        4.7                       4.6  \n",
       "17                        3.0                       3.0  \n",
       "20                        4.7                       4.6  \n",
       "33                        4.7                       4.6  \n",
       "36                        2.9                       3.1  \n",
       "46                        3.5                       3.9  \n",
       "51                        3.5                       3.7  \n",
       "55                        3.4                       3.9  \n",
       "68                        3.1                       4.2  \n",
       "80                        4.7                       4.6  \n",
       "84                        2.5                       2.8  \n",
       "97                        4.9                       4.9  \n",
       "149                       3.0                       3.5  \n",
       "160                       3.8                       3.5  \n",
       "164                       3.3                       3.6  \n",
       "192                       4.9                       4.6  \n",
       "203                       4.5                       4.7  \n",
       "208                       3.5                       3.9  \n",
       "218                       4.7                       4.6  \n",
       "224                       2.8                       3.8  \n",
       "226                       3.0                       3.5  \n",
       "232                       2.3                       2.0  \n",
       "263                       3.7                       3.9  \n",
       "270                       3.9                       3.9  \n",
       "273                       3.3                       3.3  \n",
       "289                       3.3                       3.3  \n",
       "300                       2.9                       3.2  \n",
       "322                       3.4                       3.5  \n",
       "330                       4.1                       4.0  \n",
       "350                       3.2                       3.8  \n",
       "351                       3.3                       3.1  \n",
       "367                       3.0                       3.2  \n",
       "368                       3.4                       3.8  \n",
       "372                       2.9                       3.4  \n",
       "380                       4.2                       4.2  \n",
       "388                       1.0                       1.0  \n",
       "394                       2.7                       2.7  \n",
       "395                       3.0                       3.6  \n",
       "427                       3.4                       3.5  \n",
       "434                       3.7                       3.6  \n",
       "448                       4.4                       4.5  \n",
       "460                       4.2                       4.3  \n",
       "463                       4.2                       3.8  \n",
       "480                       5.0                       4.0  \n",
       "489                       4.0                       4.0  \n",
       "491                       4.3                       4.4  \n",
       "543                       3.0                       3.6  \n",
       "560                       3.8                       3.9  \n",
       "567                       4.1                       4.0  \n",
       "571                       3.1                       2.6  \n",
       "575                       4.7                       4.7  \n",
       "584                       3.3                       3.1  \n",
       "596                       3.0                       2.9  \n",
       "597                       3.0                       2.9  \n",
       "616                       4.7                       4.6  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"industry\"] == \"--\") | (data[\"sector\"] == \"--\") | (data[\"company_founded\"] == \"--\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab83c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where company_founded is \"--\"\n",
    "data.drop(data[data[\"company_founded\"] == \"--\"].index, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c808bafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "89733423-a0fb-4c14-88a7-28055f8eb6d6",
       "rows": [
        [
         "company",
         "0"
        ],
        [
         "job_title",
         "0"
        ],
        [
         "company_rating",
         "0"
        ],
        [
         "job_description",
         "0"
        ],
        [
         "location",
         "0"
        ],
        [
         "salary_avg_estimate",
         "0"
        ],
        [
         "salary_estimate_payperiod",
         "0"
        ],
        [
         "company_size",
         "0"
        ],
        [
         "company_founded",
         "0"
        ],
        [
         "employment_type",
         "0"
        ],
        [
         "industry",
         "0"
        ],
        [
         "sector",
         "0"
        ],
        [
         "revenue",
         "0"
        ],
        [
         "career_opportunities_rating",
         "0"
        ],
        [
         "comp_and_benefits_rating",
         "0"
        ],
        [
         "culture_and_values_rating",
         "0"
        ],
        [
         "senior_management_rating",
         "0"
        ],
        [
         "work_life_balance_rating",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 18
       }
      },
      "text/plain": [
       "company                        0\n",
       "job_title                      0\n",
       "company_rating                 0\n",
       "job_description                0\n",
       "location                       0\n",
       "salary_avg_estimate            0\n",
       "salary_estimate_payperiod      0\n",
       "company_size                   0\n",
       "company_founded                0\n",
       "employment_type                0\n",
       "industry                       0\n",
       "sector                         0\n",
       "revenue                        0\n",
       "career_opportunities_rating    0\n",
       "comp_and_benefits_rating       0\n",
       "culture_and_values_rating      0\n",
       "senior_management_rating       0\n",
       "work_life_balance_rating       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13e8b7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "job_description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_avg_estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "salary_estimate_payperiod",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_founded",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "industry",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sector",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "revenue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "career_opportunities_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "comp_and_benefits_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "culture_and_values_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "senior_management_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "work_life_balance_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "13cad4ce-3b67-4f0e-9f71-d8702e79cb0d",
       "rows": [
        [
         "0",
         "ABB",
         "Junior Data Analyst",
         "4.0",
         "Junior Data Analyst\nTake your next career step at ABB with a global team that is energizing the transformation of society and industry to achieve a more productive, sustainable future. At ABB, we have the clear goal of driving diversity and inclusion across all dimensions: gender, LGBTQ+, abilities, ethnicity and generations. Together, we are embarking on a journey where each and every one of us, individually and collectively, welcomes and celebrates individual differences.\n\nYou will be working as Junior Data Analyst and will be part of Process Automation Business Area for Measurement and Analytics division based in Bangalore, India. In this role you will be reporting to COE Data Management and Analytics Manager and will be responsible for performing data analytics activities and developing analytical solutions to enable business in strategy development for existing and potential products, systems or services.\nYour responsibilities\nUsing data systems to help gather, measure, organize and analyze data, providing sound market and competitive intelligence analysis related to market and trends\nPreparing analysis of internal sales, technical and financial data, interprets resulting data using statistical tools and making recommendations to Sales, Marketing, Finance and Product Management\nMaking diagnostic and predictive recommendations to management of existing gaps and new opportunities for growth, identifying global trends and patterns across various dimensions\nExtracting and analyzing data from sales or financial tools and preparing reports for management to give insights on trends, patterns and predictions across geographies\nAssisting in the development of analytical tools and solutions to support management to drive key business decisions. Training business stakeholders on proper usage of dashboards and monitors on-going data quality\nYour background\nB.E or B. Tech or BCA or Bachelor's in Data Science\nMinimum 1 to 2 years of experience in Data Analytics and visualization\nHands on experience in Basic or Advanced Excel, Basic Statistics, ETL tools, Power BI(Basic),Basic SQL,ML and Python\nAbility to adapt, problem solving skills and give recommendations to stakeholders\nEffective time management while handling business critical tasks\nGood teamwork and collaboration with cross functional teams to meet business deliverables\nGood communication skills\nMore about us\nABB's Measurement & Analytics division is among the world's leading manufacturers and suppliers of smart instrumentation and analyzers. With thousands of experts around the world and high-performance digital technology, ABB's team is dedicated to making measurement easy for its industrial and energy customers to let them operate more efficiently and profitably. We look forward to receiving your application (documents submitted in English are appreciated). If you want to discover more about ABB, take another look at our website www.abb.com. It has come to our attention that the name of ABB is being used for asking candidates to make payments for job opportunities (interviews, offers). Please be advised that ABB makes no such requests. All our open positions are made available on our career portal for all fitting the criteria to apply. ABB does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection to recruitment with ABB, even if is claimed that the money is refundable. ABB is not liable for such transactions. For current open positions you can visit our career website https://global.abb/group/en/careers and apply. Please refer to detailed recruitment fraud caution notice using the link https://global.abb/group/en/careers/how-to-apply/fraud-warning Work model: on site #LI-onsite",
         "Bengaluru",
         "325236.0",
         "/yr (est.)",
         "10000+ Employees",
         "1883",
         "Company - Public",
         "Electronics Manufacturing",
         "Manufacturing",
         "$10+ billion (USD)",
         "3.7",
         "3.6",
         "4.0",
         "3.5",
         "3.9"
        ],
        [
         "10",
         "News Corp",
         "Data Analyst",
         "3.6",
         "Job Description :\nJob Title: Analytics Engineer\nJob Location: Bengaluru, Karnataka\nWork Arrangement: Hybrid (3 days per week in office)\nKey Responsibilities:\nCollaborate with cross-functional teams to understand data requirements and objectives.\nExtract, transform, and load (ETL) data from various sources into the Google Cloud Platform environment.\nDevelop and optimize SQL queries for data retrieval and analysis.\nCreate and maintain dashboards using Looker Studio / Data Studio for reporting and visualization of key metrics.\nPerform exploratory data analysis to identify trends, patterns, and anomalies.\nAssist in the development of data-driven solutions and recommendations for business improvements.\nConduct data quality checks and ensure data integrity throughout the entire data lifecycle.\nImplement workflow orchestration (preferably Airflow) to automate data pipelines and enhance operational efficiency.\nSupport the integration and transformation of data from various sources into a centralized data warehouse.\nQualifications:\n2+ years of experience in SQL for data manipulation and analysis.\nFamiliarity with operating in the Google Cloud Platform environment.\nProficient in creating and maintaining reports and dashboards using Looker Studio / Data Studio.\nStrong analytical and problem-solving skills.\nExcellent communication and teamwork abilities.\nDetail-oriented with a focus on data accuracy and quality.\nPreferred Qualifications:\nFamiliarity with other data visualization tools (e.g., Tableau, Power BI).\nBasic programming skills (e.g., Python) for data preprocessing and automation.\nKnowledge of statistical analysis and modeling techniques.\nThis job is posted with NTS Technology Services Pvt. Ltd.\nJob Category:\nNews Corp is a global, diversified media and information services company focused on creating and distributing authoritative and engaging content to consumers throughout the world. The company comprises businesses across a range of media, including: news and information services, book publishing, digital real estate services, cable network programming in Australia, and pay-tv distribution in Australia.\nHeadquartered in New York, the activities of News Corp are conducted primarily in the United States, Australia, and the United Kingdom.",
         "Bengaluru",
         "522206.0",
         "/yr (est.)",
         "10000+ Employees",
         "2013",
         "Company - Public",
         "Publishing",
         "Media & Communication",
         "$5 to $10 billion (USD)",
         "3.5",
         "3.4",
         "3.3",
         "3.2",
         "3.5"
        ],
        [
         "20",
         "Infosys",
         "Healthcare Data Analyst",
         "3.8",
         "A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction. • You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain. • You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews. • You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\nHealthcare Data analyst ,PL/SQL, SQL, Data mapping, STTM creation, Data profiling, Reports\nnull\nHealthcare,Data Analytics",
         "Chennai",
         "533713.0",
         "/yr (est.)",
         "10000+ Employees",
         "1981",
         "Company - Public",
         "Information Technology Support Services",
         "Information Technology",
         "$10+ billion (USD)",
         "3.8",
         "3.0",
         "4.0",
         "3.5",
         "3.7"
        ],
        [
         "22",
         "JPMorgan Chase & Co",
         "Data Analyst",
         "4.0",
         "JOB DESCRIPTION\n\nYou will be part of a team that will take a problem statement, find & acquire the relevant data, design & build the prototype, the solution, maintain and document.\nJob responsibilities\nExecutes creative software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems\nDevelops secure high-quality production code, and reviews and debugs code written by others\nIdentifies opportunities to eliminate or automate remediation of recurring issues to improve overall operational stability of software applications and systems\nRequired qualifications, capabilities, and skills\nExperience across the data lifecycle\nProgramming languages like Python, Java, Scala, etc.\nAdvanced SQL (e.g., joins and aggregations)\nScripting skills e.g. Python, R and experience with tools such as Alteryx or similar tool\nStrong understanding of data and database methodologies as well as hands on relational and cloud based systems (Databricks and/or AWS Cloud experience)\nBachelor’s degree in a relevant quantitative field (e.g. Engineering, Computer Science, Information Technology, Statistics, Business Analytics, Mathematics)\n2+ years of work experience across broad range of analytics platforms, languages, and tools (Databricks, AWS, SQL, Python and Spark, etc.)\nPreferred qualifications, capabilities, and skills\nStrong understanding of CI/CD Pipelines in a globally distributed environment using Git, Bit-Bucket, Jenkins, etc.\nExperience with the entire Software Development Life Cycle (SDLC) including planning, analysis, development and testing of new applications and enhancements to existing application.\nKnowledge of IAM (Identity Access Management) and ServiceNow\nFamiliarity with modern front-end technologies and building APIs\nStrong experience in cloud technologies\nAdvanced at Git, Scripting, Cloudformation / Terraform\nExperience customizing changes in a tool to generate data products\nCandidates must be able to physically work in our Bengaluru Office in evening shift - 2 PM to 11PM IST. The specific schedule will be determined and communicated by direct management.\nABOUT US\n\nJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.\n\nWe recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.\n\n\n\nABOUT THE TEAM\nOur Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We’re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions – all while ranking first in customer satisfaction.\n\n\nThe CCB Data & Analytics team responsibly leverages data across Chase to build competitive advantages for the businesses while providing value and protection for customers. The team encompasses a variety of disciplines from data governance and strategy to reporting, data science and machine learning. We have a strong partnership with Technology, which provides cutting edge data and analytics infrastructure. The team powers Chase with insights to create the best customer and business outcomes.",
         "India",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "1799",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "3.9",
         "3.6",
         "3.7"
        ],
        [
         "23",
         "Alcon",
         "Data Analyst - Digital Health",
         "3.8",
         "Key Responsibilities\nCollect and analyze large data sets to identify trends and insights that inform business decisions\nCollaborate with cross-functional teams to develop and implement data-driven solutions that improve business outcomes\nDevelop dashboards and reports to communicate findings and insights to stakeholders.\nBuild and maintain databases and data systems to ensure accuracy and accessibility of information for analytics\nCreates and modifies computer programs to extract information from company databases\nIdentify opportunities to improve data collection and analysis processes and make recommendations to optimize workflows\nFoster a culture of creativity, collaboration, speed, innovation, and engineering excellence.\nKey Requirements/Qualifications\nMinimum Qualifications\nBachelor’s degree in statistics, data science, or a related technical discipline.\n2+ years of hands-on experience in data preparation and analysis of large-scale datasets.\n2+ years of experience in Dashboard/BI and Data visualization tools (eg. Tableau, Quicksight, power BI)\n2+ year of health care and health care data\nProficient in SQL, Python, R and Excel\nStrong analytical and problem-solving skills, with attention to detail and accuracy.\nThrives in dynamic, cross-functional team environments. Possesses a team-first mindset, valuing diverse perspectives and contributing to a collaborative work culture.\nApproaches challenges with a positive and can-do attitude. Willing to challenge the status quo, demonstrating ability to understand when and how to take appropriate risks to drive performance.\nStrong communication and collaboration skills to deliver business solutions\nAlcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",
         "Bengaluru",
         "784161.0",
         "/yr (est.)",
         "10000+ Employees",
         "1945",
         "Company - Public",
         "Biotech & Pharmaceuticals",
         "Pharmaceutical & Biotechnology",
         "$5 to $10 billion (USD)",
         "3.4",
         "3.9",
         "3.6",
         "3.3",
         "3.5"
        ],
        [
         "26",
         "Wipro",
         "Data Analyst",
         "3.7",
         "Bengaluru, India\nGSH\n3036410\nJob Description\nGlobal Sales Enablement and Operations (GSE&O) is engaged in the strategic approach to enhance\nsales performance by improving sales productivity and efficiency, to increase and drive revenues for\nthe company. The key goals of GSE is to manage a healthy funnel, increase deal conversions, driving\norganizational alignment to sales function by designing and managing best-in-class sales processes\nand providing deep data insights for decision making.\n\nGSE is looking for specialist Business Data Analyst who has a passion to be a\npart of a strategic function with a direct impact on growing revenues for the organization. As part of\nthe GSE&O, you will be responsible for designing reports & dashboards, assessing the sales data,\nidentifying key sales patterns, and developing projections that aid in executive decision making.\n\n\nRoles & Responsibilities:\n\nRoles & Responsibilities -\n\nDesign, Execute and Manage Sales Analytics and Reporting globally for sales insights\nProvide actionable insights from huge volume of data (Both Structured and Unstructured)\nusing Data Mining, Data Cleansing techniques.\nCollecting, analyzing, and processing data to measure key performance indicator against\nbusiness objectives and benchmarks for the organization\nCollaborating with senior management to lead and implement process & policy changes\nAnalyze results and set up reports, design dashboards containing relevant KPI, measures that\nenable informed decision making\nDriving user forums and platforms for best practices sharing and knowledge harvesting to\nimprove sales operations\n\n\nQualifications:\n\nRequirments and Qualifications -\n\nPost-graduate degree in Management from premier institutes with more than 8 years of experience\nExperience in Advanced sales analytical and reporting skills\nExperience in sales operations and reporting, executive insight generation\nHands-On experience in working with Power BI / Tableau / Data Visualization tools\nProficient in formulating interactive dashboards/reports involving complex data using\nAdvanced Excel, VBA, etc.\nStrong leadership and communication skills\nKnowledge of current trends and practices relating to sales force effectiveness/ productivity\nanalytics and Insights generation.\nExcellent communication and presentation skills\n\nIf you encounter any suspicious mail, advertisements, or persons who offer jobs at Wipro, please email us at helpdesk.recruitment@wipro.com. Do not email your resume to this ID as it is not monitored for resumes and career applications.\nAny complaints or concerns regarding unethical/unfair hiring practices should be directed to our Ombuds Group at ombuds.person@wipro.com\n\nWe are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, caste, creed, religion, gender, marital status, age, ethnic and national origin, gender identity, gender expression, sexual orientation, political orientation, disability status, protected veteran status, or any other characteristic protected by law.\n\nWipro is committed to creating an accessible, supportive, and inclusive workplace. Reasonable accommodation will be provided to all applicants including persons with disabilities, throughout the recruitment and selection process. Accommodations must be communicated in advance of the application, where possible, and will be reviewed on an individual basis. Wipro provides equal opportunities to all and values diversity.",
         "Bengaluru",
         "494975.0",
         "/yr (est.)",
         "10000+ Employees",
         "1945",
         "Company - Public",
         "Information Technology Support Services",
         "Information Technology",
         "$5 to $10 billion (USD)",
         "3.6",
         "3.2",
         "3.7",
         "3.3",
         "3.5"
        ],
        [
         "27",
         "NatWest Group",
         "Data Analyst, AVP",
         "4.1",
         "Our people work differently depending on their jobs and needs. From hybrid working to flexible hours, we have plenty of options that help our people to thrive.\nThis role is based in India and as such all normal working days must be carried out in India.\nJoin us as a Data & Analytics Analyst\nThis is an opportunity to take on a purpose-led role in a cutting edge Data & Analytics team\nYou’ll be consulting with our stakeholders to understand their needs and identify suitable data and analytics solutions to meet them along with business challenges in line with our purpose\nYou’ll bring advanced analytics to life through visualisation to tell powerful stories and influence important decisions for key stakeholders, giving you excellent recognition for your work\nWe're offering this role at associate vice president level\nWhat you'll do\nAs a Data & Analytics Analyst, you’ll be driving the use of advanced analytics in your team to develop business solutions which increase the understanding of our business, including its customers, processes, channels and products. You’ll be working closely with business stakeholders to define detailed, often complex and ambiguous business problems or opportunities which can be supported through advanced analytics, making sure that new and existing processes are designed to be efficient, simple and automated where possible.\nAs well as this, you’ll be:\nLeading and coaching your colleagues to plan and deliver strategic project and scrum outcomes\nPlanning and delivering data and analytics resource, expertise and solutions, which brings commercial and customer value to business challenges\nCommunicating data and analytics opportunities and bringing them to life in a way that business stakeholders can understand and engage with\nAdopting and embedding new tools, technologies and methodologies to carry out advanced analytics\nDeveloping strong stakeholder relationships to bring together advanced analytics, data science and data engineering work that is easily understandable and links back clearly to our business needs\nThe skills you'll need\nWe’re looking for someone with a passion for data and analytics together with knowledge of data architecture, key tooling and relevant coding languages. Along with advanced analytics knowledge, you’ll bring an ability to simplify data into clear data visualisations and compelling insight using appropriate systems and tooling.\nYou’ll also demonstrate:\nStrong knowledge of data management practices and principles\nExperience of translating data and insights for key stakeholders\nGood knowledge of data engineering, data science and decisioning disciplines\nStrong communication skills with the ability to engage with a wide range of stakeholders\nCoaching and leadership experience with an ability to support and motivate colleagues",
         "Gurgaon",
         "579938.0",
         "/yr (est.)",
         "10000+ Employees",
         "1727",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "3.7",
         "3.5",
         "4.2",
         "3.7",
         "4.3"
        ],
        [
         "31",
         "eminenture",
         "Data Analyst",
         "4.0",
         "Fly high with your expertise in data analysis & have a successful career here.\nEducation:\nMinimum Graduation\n\nData Analyst\nResponsibilities\nExcellent verbal and written skills\nGood command on Excel (Vlookup, Hlookup, Pivot Tables, Conditional Formatting, If Conditioning and other advanced Excel tools like VBA and Macros)\nComfortable with UK –Shift Timing (13:00 to 22:00)\nEfficiency to work on outbound and in-house projects\nEducation\nMinimum Graduation\n\nBenefits\nPerks and Incentives for Incorporating with Us!\nPaid Holidays\nSick Days Off\nHealthcare\nCommuter Benefits\nRelocate\nLife Insurance\nHealth Savings\nLearning & Development\nGlobal Career",
         "Delhi",
         "539530.5",
         "/yr (est.)",
         "51 to 200 Employees",
         "2011",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "$1 to $5 million (USD)",
         "3.9",
         "3.4",
         "3.9",
         "3.7",
         "3.7"
        ],
        [
         "32",
         "Intercontinental Exchange",
         "Data Analyst I",
         "3.8",
         "Job Purpose\nConducts analysis, verification, remediation and communicates the quality of publicly recorded information that is strategically abstracted, keyed, and located by third party vendors.\nIntent is to control content, integrity, and reliability of data through process knowledge and research.\nDuties can include, but are not limited to quality control, data analysis, locating, vendor feedback, and reporting functions.\nResponsibilities\nPerform quality control of data using appropriate department applications and procedures.\nAnalyze and verify transmitted vendor data of keyed documents.\nAnalyze and verify completed and corrected documents listed under failed validation or business rules.\nReview and Analyze document images and data fields that need to be captured for various document and court case types.\nRespond and/or provide clarification to vendor questions.\nProvide vendor feedback for errors identified within transmitted data and QC of error rate statistics.\nReview and analyze QC, Upload, Missing document, Suspend, and other related reports.\nIdentify, remediate and/or physical repair of data issues.\nReconcile and document all failures within existing processes and validations.\nAssure that data is accurate and meets department and industry standards.\nPerforms other related duties as assigned.\nKnowledge and Experience\nBasic knowledge of real estate data with an emphasis on public records.\nFamiliarity with the various facets of public record data maintenance.\nKnowledge of county specific nuances relating to recorded document and court cases.\nWorking knowledge of public record data maintenance, applicable applications and proficient in entering data into internal applications.\nKnowledge on Recorder Data, Deed data and foreclosure is required.\nKnowledge on Mortgage document, Deed of trust is required.\nKnowledge on Foreclosure, NOD (Notice of default), NOS (Notice of sale), Title document would be good.\nStrong analytical skills, with experience in quality assurance.\nKnowledge of balancing and correction procedures.\nStrong verbal and written communication skills.\nKnowledge on SQL would be added advance but not mandatory.\nBasic computer skills, including efficiency with MS Office suite applications & emphasis on MS Excel.\nAbility to work collaboratively with others.\nAbility to manage multiple tasks and prioritize to meet deadlines successfully.\nOrganized and results driven.\nDomain knowledge w.r.t US Mortgage recording and assessor side is mandatory.\nSchedule\nThis role offers work from home flexibility of up to 2 days per week.",
         "Hyderābād",
         "469042.0",
         "/yr (est.)",
         "5001 to 10000 Employees",
         "2000",
         "Company - Public",
         "Stock Exchanges",
         "Finance",
         "$5 to $10 billion (USD)",
         "3.5",
         "3.7",
         "3.5",
         "3.3",
         "3.6"
        ],
        [
         "33",
         "Infifresh Foods",
         "Data Analyst",
         "3.6",
         "Job Information\nDepartment Name\nCentral\nIndustry\nFMCG/Foods/Beverage\nRequired Skills\ntableau\ndata visualization\n+1\nEducation\nAny degree\nJob Category\nDesk Job\nWork Experience\n1-3 years\nCity\nBangalore\nState/Province\nKarnataka\nCountry\nIndia\nZip/Postal Code\n560034\nJob Description\nJob Description:**\n\nAs a Data Analyst at Captain Fresh, you will play a crucial role in helping our organization make data-driven decisions. The ideal candidate will have 2+ years of experience and possess strong SQL and Excel skills. You will be responsible for understanding, exploring, analyzing, and merging different datasets using Excel and other data tools. You will also have a deep understanding of relational databases, CRUD operations, star schema, and the ability to combine, extract, and aggregate data to create meaningful insights.\n\nKey Responsibilities:\n\n1. **Data Analysis:**\n\nUse SQL to query and extract data from relational databases.\n\nClean and transform data to ensure its accuracy and consistency.\n\nPerform data analysis and generate actionable insights from diverse datasets.\n\n2. **Excel Expertise:**\n\nUtilize Excel to create and maintain spreadsheets, conduct data manipulation, and build simple dashboards for reporting.\n\nMerge and consolidate data from various sources to support business decision-making.\n\n3. **Database Management:**\n\nWork with relational databases to understand data schemas and perform CRUD operations.\n\nDesign and maintain efficient data pipelines for data extraction and transformation.\n\n4. **Data Visualization:**\n\nCreate easy-to-understand visualizations and reports to communicate data findings effectively.\n\nCollaborate with other teams to build interactive dashboards that provide real-time insights.\n\n5. **Problem Solving and Analysis:**\n\nIdentify trends, patterns, and anomalies in data.\n\nConduct root cause analysis and provide recommendations for process improvement.\n\nRequirements\nQualifications:\n\nBachelor's degree in a relevant field (e.g., Computer Science, Statistics, Data Science).\n\n2+ years of experience as a Data Analyst.\n\nProficiency in SQL and Excel.\n\nStrong understanding of relational databases and data modeling concepts.\n\nKnowledge of CRUD operations and star schema.\n\nAbility to combine, extract, and aggregate data for various analytical purposes.\n\nExcellent problem-solving skills and a curious, inquisitive mindset.\n\nStrong communication and collaboration skills.\n\nAbility to work independently and in a team-oriented environment.\n\nQuick learner and adaptable to new technologies and concepts.",
         "Bengaluru",
         "948683.0",
         "/yr (est.)",
         "Unknown",
         "2019",
         "Company - Private",
         "Fishery",
         "Agriculture",
         "Unknown / Non-Applicable",
         "3.5",
         "3.6",
         "3.6",
         "3.2",
         "3.4"
        ],
        [
         "36",
         "Valenta BPO",
         "Data Analyst",
         "3.2",
         "Data Analyst\nFULL TIME | VALENTA AI | INDIA\n\nJob Information\nIndustry\nIT Services\nCurrent Openings\n1\nWork Experience\n4-5 years\nSalary\n500000-600000\nCity\nBangalore North\nState/Province\nKarnataka\nZip/Postal Code\n560002\nJob Description\nAs a Data Analyst you will play a pivotal role in the visualization and analysis of critical data for high-impact projects. You will be responsible for creating, modifying, and maintaining complex data dashboards, primarily for our clients in the sports and construction sectors. This role requires a high level of proficiency in Power BI, Excel, and other data visualization tools, along with strong communication skills for client interactions.\n\n\n\nKey Responsibilities:\n\nData Visualization and Dashboard Development:\n\nDevelop and maintain data dashboards using Power BI, ensuring accurate and real-time representation of data.\nMake periodic updates to dashboards based on client feedback, including publishing different versions in separate workspaces.\n\nData Validation and Delivery:\n\nEngage in data validation processes to ensure accuracy and reliability of dashboard data.\nDeliver finalized dashboards to clients, ensuring they meet specified requirements.\n\nClient Interaction and Support:\n\nActively participate in weekly meetings to discuss client requirements and feedback.\nRespond to client queries regarding dashboard visualizations and data interpretation.\nTrain clients on understanding and using the dashboards effectively.\nCollaborate with team members, guiding them in client communication and issue resolution.\n\nProject Management and Reporting:\n\nMaintain a task tracker to manage and prioritize ad-hoc tasks and project deliverables.\nEnsure clear communication of project statuses and updates within the team and to stakeholders.\n\nTechnical Skills and Maintenance:\n\nUtilize complex DAX functions and data preparation techniques in Power BI.\nApply SQL queries in Snowflake for advanced data analysis.\nPerform routine maintenance and updates of dashboards based on client feedback and changing requirements.\n\n\nTechnical Skills:\n\nAdvanced Proficiency in Power BI:\n\nExpertise in creating complex dashboards and visualizations tailored to client needs.\nSkilled in using DAX (Data Analysis Expressions) for creating custom calculations and advanced data manipulation.\nExperience with data preparation and modeling within Power BI, including the use of Power Query.\n\nExcel Mastery:\n\nAdvanced skills in Excel for data analysis, including the use of pivot tables, advanced formulas, and data visualization techniques.\nAbility to manage large datasets within Excel and integrate Excel with other data tools.\n\nLucid Charts:\n\nProficiency in using Lucid Charts for creating flowcharts, process diagrams, and other visual representations of data and workflows.\n\nSQL and Database Management:\n\nCompetence in writing and optimizing SQL queries, particularly within Snowflake environments.\nUnderstanding of database structures and the ability to efficiently extract, transform, and load data (ETL).\n\nFamiliarity with Microsoft 365 Suite:\n\nComfortable using various applications within the Microsoft 365 suite, such as SharePoint, Teams, and others for collaboration and data sharing.\nAbility to integrate these tools with data analysis workflows.\n\nData Analysis and Problem Solving:\n\nStrong analytical skills with the ability to derive insights and recommendations from datasets.\nSkill in identifying, analyzing, and resolving complex data-related issues.\n\nCommunication and Training:\n\nAbility to clearly articulate technical concepts to non-technical audiences, including clients.\nExperience in training clients or team members on the use of data tools and dashboards.\n\n\n\nRequirements\nQualifications:\n\nBachelor’s degree in Data Science, Statistics, Computer Science, or a related field.\nProficient in Power BI, Excel (advanced), and Lucid Charts.\nExperience with SQL and familiarity with Snowflake.\nStrong analytical skills and attention to detail.\nExcellent communication and client-handling skills.\nAbility to work in a fast-paced, dynamic environment.\n\nPreferred Experience:\n\nPrior experience in data analysis or a similar role.\nKnowledge of Microsoft 365 suite.\nExperience working with data in the sports and/or construction industries.",
         "Bengaluru",
         "550000.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2014",
         "Company - Private",
         "HR Consulting",
         "Human Resources & Staffing",
         "Unknown / Non-Applicable",
         "3.2",
         "2.7",
         "3.1",
         "3.1",
         "3.6"
        ],
        [
         "37",
         "PhonePe",
         "Senior Data Analyst",
         "4.1",
         "About PhonePe Group:\nPhonePe is India’s leading digital payments company with 50 crore (500 Million) registered users and 3.7 crore (37 Million) merchants covering over 99% of the postal codes across India. On the back of its leadership in digital payments, PhonePe has expanded into financial services (Insurance, Mutual Funds, Stock Broking, and Lending) as well as adjacent tech-enabled businesses such as Pincode for hyperlocal shopping and Indus App Store which is India's first localized App Store. The PhonePe Group is a portfolio of businesses aligned with the company's vision to offer every Indian an equal opportunity to accelerate their progress by unlocking the flow of money and access to services.\nCulture\nAt PhonePe, we take extra care to make sure you give your best at work, Everyday! And creating the right environment for you is just one of the things we do. We empower people and trust them to do the right thing. Here, you own your work from start to finish, right from day one. Being enthusiastic about tech is a big part of being at PhonePe. If you like building technology that impacts millions, ideating with some of the best minds in the country and executing on your dreams with purpose and speed, join us!\nSDA, Analytics - PhonePe\nWho are we looking for?\nFirst principle problem solver and good executor who is passionate about working with data and various data processing systems. If you’re a curious mind and like to question the status quo, then you’d fit right in with us.\nWhat would you get if you work with us?\nYou'll be closely working with senior analysts in a team related to key principles around data, which includes ingestion, storage and consumption. You'll get to interact with some of the smartest professionals that the country has to offer and get exposure to all facets of building a data platform at scale. You get complete ownership and responsibility of BI processing and products of a specific area - right from problem identification to implementation at the org level.\nWhat would you get to do in this role?\nEnd-to-end BI partnership and collaboration will include designing and implementing everything related to data processing.\nDrive data accuracy, processing efficiency and consumptions convenience of data and platform.\nEfficient in SQL; able to write advance script, optimize and data model for processing.\nCollaborate closely with the business, and product analyst to understand the business problem and translate them into the right data processing problem statement.\nHave a strong problem-solving mindset and be able to apply the right analytical approach for solving the same.\nBe able to influence stakeholders across various functions to drive initiatives & data driven decision making\nAble to work closely with the data engineering team to debug and identify the issue.\n\nWhat do you need to have to apply for this position?\nMinimum 2 years of analytics or BI experience in relevant roles\nStrong problem-solving & analyst-relevant technical skills\nAbility to write complex queries on SQL to manipulate, and consolidate multiple data sources for the purpose of dashboarding and Data processing.\nIntuition for data and ability to handle big data sources\nStrong working knowledge in Data process monitoring tools(like Airflow, Grafana) and visualization tools like PowerBI, Tableau and Qliksense\nUnderstanding data analysis and automation languages such as R and Python is advantageous.\nStrong communication skills; Ability to clearly explain thoughts and ideas either verbally or in written form.\nUnderstanding of dashboarding principles and prior experience building such dashboards.\nPhonePe Full Time Employee Benefits (Not applicable for Intern or Contract Roles)\nInsurance Benefits - Medical Insurance, Critical Illness Insurance, Accidental Insurance, Life Insurance\nWellness Program - Employee Assistance Program, Onsite Medical Center, Emergency Support System\nParental Support - Maternity Benefit, Paternity Benefit Program, Adoption Assistance Program, Day-care Support Program\nMobility Benefits - Relocation benefits, Transfer Support Policy, Travel Policy\nRetirement Benefits - Employee PF Contribution, Flexible PF Contribution, Gratuity, NPS, Leave Encashment\nOther Benefits - Higher Education Assistance, Car Lease, Salary Advance Policy\nWorking at PhonePe is a rewarding experience! Great people, a work environment that thrives on creativity, the opportunity to take on roles beyond a defined job description are just some of the reasons you should work with us. Read more about PhonePe on our blog.",
         "Bengaluru",
         "777892.0",
         "/yr (est.)",
         "5001 to 10000 Employees",
         "2015",
         "Company - Private",
         "Internet & Web Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.0",
         "4.2",
         "4.1",
         "3.7",
         "3.8"
        ],
        [
         "40",
         "Lloyds Technology Centre",
         "Data Analyst",
         "3.3",
         "General information\nName\nData Analyst\nRef #\n1170\nPosting Date\nThursday, January 4, 2024\nCountry\nIndia\nCity\nHyderabad\nPlatform\nEnterprise Risk\nJob Family\nData Science\nKey Skills\nPython, SQL, Java, Scala or Go\nDescription & Requirements\nData Analyst\nEnterprise Risk| Data\nWork for Lloyds Technology Centre who are part of Lloyds Banking Group, the UK's largest digital bank, where you’ll make a genuine difference, be able to develop yourself and be part of a culture where everyone's contribution is recognized.\nOpportunity to be a part of a mission; shaping finance as a force for good - Lloyds Banking Group’s mission is to create a sustainable and inclusive future for people and businesses, shaping finance as a force for good. We, at Lloyds Technology Centre, play a key part in delivering this*. We are also guided by our values in shaping the way we work and how we make decisions. This creates an environment where colleagues love to work and can make a positive impact.\nRange of exclusive benefits and rewards - We value your contributions and will ensure that your total reward experience reflects the expertise you bring and impact you create. We also strive to provide a holistic proposition that meets your wellbeing needs. Our total reward practices help us create an ecosystem where you can thrive, ensuring your essential needs are met so you can focus on your personal growth and future success.\nCareer elevating opportunities - At Lloyds Technology Centre, you will be empowered to take charge of your career journey through personalized career mentorship from experienced mentors, leadership development programs, and stretch assignments. You will be able to access opportunities for continuous learning and exposure to new experiences through job shadowing and cross-functional collaboration on projects.\nFuture skill building opportunities - Being part of Lloyds Banking Group, who are known for their market leading practices in learning and development, Lloyds Technology Centre is committed to help you achieve your personal and professional aspirations. You will have access to role specific learning pathways & training, targeted accelerated development programs and professional certifications & qualifications.\nInclusive and diverse workplace - At Lloyds Technology Centre, you will be part of an inclusive workplace where everyone feels valued, respected, and empowered. We embrace and celebrate diversity at every level of our workforce, valuing and respecting you for your unique identity.\nWhat you’ll do:\nEnterprise Risk platform plays a critical role in creating and running the ecosystem of cross-cutting channel capabilities, driving simplification and modernization, enabling business platforms to focus on the creation of customer and colleague experiences.\nAs a Data Analyst within the Enterprise Risk Platform and the Data Lab, you’ll be working on regular high quality and trusted resource reporting and analysis in line with our reporting timetable for our customers.\nDefining and tracking progress against our Strategic Workforce plan.\nOptimizing resource forecasts, working with GCOO teams to understand variances and encourage best practices.\nCreating resource models in support of the new Platform model, including tracking progress during the adoption.\nAdopting a continuous improvement mindset and looking for opportunities to automate and transform our processes.\nSourcing data from a variety of systems and create analysis to support the team in delivering insight to our customers.\nEngaging with our partners and customers as required to ensure their needs are fulfilled and insight is shared effectively.\n\nWhat you’ll need:\nBachelor's degree (or equivalent) in engineering.\nExcellent skills like Data analysis, problem solving and Data Modelling.\nExperience in handling reporting packages like Business Objects, programming (JavaScript, XML, or ETL frameworks), databases.\nProficient in using programming languages like SQL, Oracle, MATLAB.\nWorking knowledge on database design development, data models, techniques for data mining, and segmentation.\n\nNice to have skills:\nExposure to data visualization software like Tableau, QlikView.\nGood logical reasoning, problem-solving, and communication skills.\nKnowledge of working with any reporting tools like Python or Microsoft Excel or RapidMiner or KNIME or Power BI or Apache Spark or Talend or Splunk.\nAbout working for Lloyds Technology Centre:\nOur new technology Centre in Hyderabad will be home to highly skilled technology and data specialists who will be driving our transformation and delivering great outcomes for Lloyds Banking Group’s customers. Our office is situated in a sought-after location that features easy transport links and excellent facilities, all aimed at enabling you to achieve a great work-life balance.\nWorking with us means being part of our aspirational and transformative journey of redefining the fintech landscape, while building an organization that welcomes all. We’re committed to providing an exceptional employee experience through our policies, practices, and development opportunities to support you in achieving your potential.\nThis is a once in a career opportunity to shape your future and help us make our mark in India. Are you ready to help shape your future, as well as ours?\nJoin us and grow with purpose.\n*Lloyds Technology Centre does not offer financial services in India.",
         "Hyderābād",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "1695",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "Unknown / Non-Applicable",
         "3.2",
         "3.4",
         "3.2",
         "2.9",
         "3.2"
        ],
        [
         "44",
         "Sectigo",
         "Data Analyst",
         "3.4",
         "Who We Are!\nAt Sectigo, we align around our mission and pride ourselves in helping thousands of customers sleep better at night.\n“When people think Online trust management, they think Sectigo because we offer our customers unparalleled peace of mind.”\nHow we show up with each other and our customers every day is just as important, and we win as #OneSectigo by living out our core values - Support, Excellence, Collaboration, Teamwork, Integrity, Growth and Openness. We are committed to investing in our diverse teams where everyone understands their role and how they support our strategic goals, we drive operational excellence through scale and efficiency, and we strive to delight our customers and become the market leader in our industry. If you aspire to join a driven team that holds each other accountable to meeting our lofty goals and you’d like to be part of our growth story in delivering a market leading user experience, we’d like to talk to you.\nWhat We Are Looking For:\nThe Data Analyst reports to the Head of FP&A with significant exposure to executive leadership. They will collaborate cross-functionally to ensure that operational decisions are supported by financial metrics. They will build financial models and complete analyses that will produce insights and help support strategic decisions. They will participate in and drive the forecasting and budgeting process. The FP&A team is a scaling function within the business which will allow this role to participate in a wide range of projects and responsibilities.\nWhat You’ll Be Doing:\nCollaborate with the Head of FP&A and the finance team to produce standard periodic reporting (monthly and weekly financial reports and dashboards), including variance analysis and explanations\nParticipate in the annual budget and reforecast process including project management, engagement with the senior management team, and assessment/presentation of results\nProactively identify and expand ways for the FP&A function to impact the business\nParticipate in the presentation of results to the senior management team\nDevelop KPIs and analyses to track key business metrics such as ARR, customer retention, sales performance, forecasting accuracy, and others\nPartner with the Accounting team to ensure accurate reporting and integration of actuals into forecasts\nPerform various ad hoc analysis as directed by the CEO/CFO\nDevelop relationships across the entire organization to gain a detailed understanding of all aspects of the business operations and trust amongst the senior leaders and provide analytical support as needed\nBe a resource for analysis and due diligence related to M&A activity\nRequirements:\nEducation\nDegree in Finance, Accounting, or similar\nExperience\n2+ years professional experience including financial forecasting\nExperience in private equity, investment banking, or investor relations strongly preferred\nExperience forecasting and analyzing SaaS B2B topline strongly preferred\nTechnical skill set including SQL, PowerBI, or similar data/visualization tools preferred\nTalents and Desired Qualifications:\nStrong analytical skills with a proven track record of delivering actionable insights\nUnderstanding of GAAP\nAdvanced Excel modeling and Power Point\nStrong communication, interpersonal, and presentation skills\nManagement Responsibilities:\nNone\nUDEo4BJaAv",
         "Chennai",
         "636962.0",
         "/yr (est.)",
         "201 to 500 Employees",
         "2008",
         "Company - Private",
         "Computer Hardware Development",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.0",
         "2.9",
         "3.0",
         "3.0",
         "3.3"
        ],
        [
         "45",
         "Wrike Careers Page",
         "Customer Support Data Analyst",
         "3.8",
         "Wrike is the most powerful work management platform. Built for teams and organizations looking to collaborate, create, and exceed every day, Wrike brings everyone and all work into a single place to remove complexity, increase productivity, and free people up to focus on their most purposeful work.\nOur vision: A world where everyone is free to focus on their most purposeful work, together.\nRole Overview:\nWe're looking for Customer Support Analyst, who will be conducting research and delivering business insights to support data-driven decision-making and optimization of business processes in Customer Support team\nWrike Support is a diverse, multicultural team, responsible for building relationships with our customers and assisting them with any challenges they encounter. In this role, you will be responsible for providing business insights based on data analysis and assisting to implement change management based on those findings, defining key business metrics, and supporting the management team with the reporting and ad-hoc analysis required to make crucial business decisions.\nAt Wrike, we believe that work should be both challenging and fun. We're growing rapidly and provide excellent opportunities for professional growth. We're smart, passionate, friendly, and professional and are looking for the same qualities in you.\nJob Scope and Accountabilities:\nCompile, interpret, and present weekly & monthly reports on key metrics (SLA attainment, customer satisfaction, team load & efficiency, etc.)\nAutomate recurrent reports, create, maintain and improve appropriate dashboards and data sources\nConduct ad hoc analysis and deliver business insights to support data-driven decision-making in both run-the-business and change-the-business activities\nPartner with Operations and Leadership teams to implement new metrics and approaches to resolve possible areas for process improvement\nCollect historical data and directional inputs from stakeholders to forecast team load and capacity\nExperience Requirements\nGood knowledge of SQL, databases (we use Google BigQuery) and statistics basics\nKnowledge of BI tools (we use Tableau, Zendesk Explore) and proven experience in data visualization\nStrong analytical and problem-solving skills\nDesired Skills\nExperience working within a customer support/success organization, understanding customer lifecycle and support processes is a plus\nA tendency to think about overall business value rather than numbers and charts\nCommunicative and friendly; a strong team player, ready to learn\nExperience with Python\nInterpersonal skills:\nDisplay great people skills, connecting effectively with individuals, demonstrating friendliness, empathy, and tact, and maintaining composure under pressure during difficult interpersonal situations.\nCritical thinker, generally curious—a true problem solver\nPassionate about learning and improving every day, and motivated to excel\nOpen to feedback; coachable\nStrong team player\nSelf-starter with strong ownership skills, willing to go above and beyond the job\ndescription\nCreative and innovative\n#LI-JM1\nWho Is Wrike and Our Culture\nWe're a team of innovators and creators who solve the complex work problems of today and tomorrow.\nHybrid work mode\n\nWrike promotes a hybrid work mode and we meet in the office 3 times a week. This work mode supports our culture of collaboration and solving problems fast to deliver business outcomes and win together.\nOur persona\nSmart: We love what we do, and we're great at it because this is our domain. Our combined knowledge in this space is unmatched.\nDedicated: We get up every day focused on helping our customers win. We're committed to helping our teammates win, too!\nApproachable: We're friendly, easy to get along with, considerate, and helpful.\nOur culture and Values\nDeliver Business Outcomes\nBe better than the competition\nMove fast. Then, move faster\nKnow our customers\nWe win together\nHave courage\n\nCheck out our LinkedIn Life Page, Instagram, Wrike Engineering Team, Medium, Meetup.com, Youtube for a feel for what life is like at Wrike.",
         "Bengaluru",
         "562146.0",
         "/yr (est.)",
         "1001 to 5000 Employees",
         "2006",
         "Company - Private",
         "Software Development",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.4",
         "3.7",
         "3.9",
         "3.3",
         "4.1"
        ],
        [
         "47",
         "Wipro Limited",
         "Data Privacy/Data Analyst",
         "3.7",
         "Overview:\n\nRole Purpose\nThe purpose of this role is to interpret data and turn intoinformation (reports, dashboards, interactive visualizations etc) whichcan offer ways to improve a business, thus affecting business decisions.\nDos\n\nManaging the technical scope of the project in line with therequirements at all stages\nGather information from various sources (data warehouses,database, data integration and modelling) and interpret patterns andtrends\nDevelop record management process and policies\nBuild and maintain relationships at all levels within the clientbase and understand their requirements.\nProviding sales data, proposals, data insights and accountreviews to the client base\nIdentify areas to increase efficiency and automation ofprocesses\nSet up and maintain automated data processes\nIdentify, evaluate and implement external services and tools tosupport data validation and cleansing.\nProduce and track key performance indicators\n\nAnalyze the data sets and provide adequate information\nLiaise with internal and external clients to fully understanddata content\nDesign and carry out surveys and analyze survey data as per thecustomer requirement\nAnalyze and interpret complex data sets relating tocustomer’s business and prepare reports for internal and externalaudiences using business analytics reporting tools\nCreate data dashboards, graphs and visualization to showcasebusiness performance and also provide sector and competitorbenchmarking\nMine and analyze large datasets, draw valid inferences andpresent them successfully to management using a reporting tool\nDevelop predictive models and share insights with the clients asper their requirement\n\nStakeholder Interaction\n\nStakeholder Type\n\nStakeholder Identification\n\nPurpose of Interaction\n\nInternal\n\nProject Manager/ Database Lead\n\nRegular reporting & updates\n\nExternal\n\nClients\n\nClient engagement, reviews etc\n\nDisplay\n\nLists the competencies required to perform this role effectively:\nFunctional Competencies/ Skill\nLeveraging Technology – Knowledge of current and upcomingtechnology (automation, tools and systems) to build efficiencies andeffectiveness in own function/ Client organization – Expert\nProcess Excellence - Ability to follow the standards and norms toproduce consistent results, provide effective control and reduction ofrisk – Expert\nTechnical knowledge – knowledge of various programminglanguages/ software (Python, Microsoft Excel, VBA, Matlab, SQL etc) andtools on data analytics - Expert\n\nCompetency Levels\n\nFoundation\n\nKnowledgeable about the competency requirements. Demonstrates (inparts) frequently with minimal support and guidance.\n\nCompetent\n\nConsistently demonstrates the full range of the competencywithout guidance. Extends the competency to difficult and unknownsituations as well.\n\nExpert\n\nApplies the competency in all situations and is serves as a guideto others as well.\n\nMaster\n\nCoaches others and builds organizational capability in thecompetency area. Serves as a key resource for that competency and isrecognised within the entire organization.\n\nBehavioral Competencies\nFormulation &Prioritization\nClient centricity\nExecution Excellence\nPassion for Results\nConfidence\nBusiness Acumen\n\nDeliver\n\nNo.\n\nPerformance Parameter\n\nMeasure\n\n1.\n\nAnalyses data sets and provide relevant information to the client\n\nNo. Of automation done, On-Time Delivery, CSAT score, Zero customerescalation, data accuracy",
         "Bengaluru",
         "494975.0",
         "/yr (est.)",
         "10000+ Employees",
         "1945",
         "Company - Public",
         "Information Technology Support Services",
         "Information Technology",
         "$5 to $10 billion (USD)",
         "3.6",
         "3.2",
         "3.7",
         "3.3",
         "3.5"
        ],
        [
         "51",
         "HP",
         "Data Analyst",
         "4.1",
         "Data Analyst\nTo support HP Proactive Insights Experience Management (PIXM) Services, we are looking for an experienced Data Analyst who can perform advanced data analysis to support HP strategic accounts and provide ongoing value to HP customers in different areas of operations.\nThe role focuses on working with Technical Service Delivery Managers (TDM) and automation engineers to analyze and proactively solve employee experience issues for customers. The role is expected to work collaboratively with TDMs, Professional Services & Customer Success teams.\nThe primary responsibilities of the role are as follows:\nAnalyze, baseline, and benchmark customers’ digital experience scores to drive actionable insights for ongoing operations.\nInfluence customer IT business decisions using proven data analytics and business insights.\nLead data analysis projects from end to end, including business and data requirements gathering, data modeling, data validation, and visualization.\nCollaborate with customers to integrate data analysis into IT operations and streamline their incident and problem management processes.\nStay current on new product features and technologies to the level required for the above activities.\nQualifications\nBA/BS preferred in computer science, computer engineering, or mathematics.\nMinimum of 3-5 years of experience in technical consulting, data analytics, and IT operations roles\nAbility to perform data analysis on large datasets to drive actionable insights and automation.\nProven use of business intelligence and data visualization tools (Power BI, Tableau, AWS Quick sight, SQL, Python, etc.) to deliver insights and analysis.\nExcellent communication skills. Ability to present to senior IT leaders and defend analytical results and recommendations.\nExtensive knowledge of Microsoft Windows, MacOS operating systems and applications\nExperience in workplace management, network management, software productivity, and collaboration tool management\nExperience with enterprise transformation projects (e.g., Win10, Win11, O365 migration)\nGood knowledge of IT infrastructure, networking, and applications\nGood knowledge of IT operations and ITIL methodology\nWorking knowledge of Windows PowerShell, Bash scripting\nAbility to quickly learn new technologies in an unsupervised environment.\nEnthusiasm for working in an international, collaborative, and fast-paced environment and learning new technologies.\nPreferred: Experience with digital employee experience management platforms such as HP Proactive Insights, Nexthink, 1E Tachyon, and VMware Workspace One Intelligence. Experience working in a Scrum Agile development environment.\nFluency in English, with excellent written, digital, and verbal communication skills; knowledge of other languages would be a plus.\n\nAbout HP\n\nYou’re out to reimagine and reinvent what’s possible—in your career as well as the world around you.\nSo are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\n\nHP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\n\nOur history: HP’s commitment to diversity, equity and inclusion – it's just who we are.\nFrom the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",
         "Bengaluru",
         "869528.0",
         "/yr (est.)",
         "10000+ Employees",
         "1939",
         "Company - Public",
         "Computer Hardware Development",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.7",
         "3.7",
         "4.3",
         "3.8",
         "4.2"
        ],
        [
         "55",
         "JPMorgan Chase & Co",
         "Reference Data Analyst - Team Leader",
         "4.0",
         "JOB DESCRIPTION\n\nJob Summary:- The Client Account Services (CAS) team manages and supports the delivery of a global strategy across Investor Services products for Client Documentation, Accounts, and Entitlements. Additionally, they are expected to contribute to a wider team, provide regular progress updates, maintain an understanding of client requirements / documentations, approach their work with a control-mindset, and demonstrate an understanding/application of policies and procedures. Credentials Strong People management skills (Associate),Good leadership skills and ability to motivate team ,Have strong verbal and written communication skills, Good team player and self-motivated, Strong analytical skills, Desire to work in a fast-paced environment with multiple deliverables, Proven skills in time management, organization, and attention to detail, Proficiency in Microsoft Office suite of applications Preferred experienced with new age tools like Alteryx, Tableau, Xceptor etc.\nJob Responsibilities :-\nAccurate and timely completion of daily by self and team. Ensure all activities are completed within SLA.\nAppropriate research of all exceptions\nWork with upstream teams to fix all exceptions\nTimely response and prompt to all client queries and rush requests\nProcess improvement to generate efficiency saves and improve on the turnaround time to the client\nStakeholder interactions – set appropriate expectations with respect to timelines and details as required\nConduct appropriate testing's for all changes and enhancements in the system\nControl and maintain inventories of all UTs and SOPs.\nRequired qualifications, capabilities and skills -\nPreferred qualifications, capabilities and skills –\nCandidate should have good knowledge and understanding of static/reference data process\nCandidate should have strong attention to detail in review of documents and review capabilities on various product and types.\nCandidate should possess the ability to work under pressure and to meet deadlines\nPrior experience in similar Domain will be an added advantage and should be a requirement at manager and above level\nABOUT US\n\nJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.\n\nWe recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.\n\n\n\nABOUT THE TEAM\nThe Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world’s most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.\n\n\nOperations teams develop and manage innovative, secure service solutions to meet clients’ needs globally. Developing and using the latest technology, teams work to deliver industry-leading capabilities to our clients and customers, making it easy and convenient to do business with the firm. Teams also drive growth by refining technology-driven customer and client experiences that put users first, providing an unparalleled experience.",
         "Bengaluru",
         "657267.0",
         "/yr (est.)",
         "10000+ Employees",
         "1799",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "3.9",
         "3.6",
         "3.7"
        ],
        [
         "61",
         "JPMorgan Chase & Co",
         "Reference Data Analyst",
         "4.0",
         "JOB DESCRIPTION\n\nJoin the team that is responsible for leading projects to support strategic and business change initiatives\nDo you enjoy making a difference through project management, risk management, financial analysis, and regulatory reporting? This is an exciting career opportunity to showcase your knowledge, skills, and abilities. You have found the right team.\nAs the Data Transformation Lead, in the Party Reference Data Operations Team you will be responsible for leading projects to support strategic and business change initiatives driven by Reference Data Strategy and Party Reference Data operations. You will work closely with the Client Account Services Party Reference Data leadership team to facilitate information sharing, operational readiness and ongoing BAU effectiveness. You will have solid time management, organizational and effective prioritization skills. You will use your high level of Excel, PowerPoint, and SharePoint skills as well as excellent ability to communicate effectively across multiple lines of business and various leadership levels on a regular basis.\nJob responsibilities\nAnalyze, design, and implement new operating models\nDesign and deliver procedures and training to support new and existing operating models\nPartner with Global Party Reference Data process leads on current state assessment, defining solutions, testing, and implementing operating models for party creation and maintenance\nIdentify operational synergies with Client Onboarding, Know Your Customer (KYC) and other business stakeholders to eliminate redundant and/or manual processes\nWork with Business and Operations Stakeholder management\nAct as the supportive source of knowledge for all Standard Operating Procedures (SOPs) and internal policy documents\nPartner with Reference Data Strategy, Project, and Technology to implement the future state data models and domains, including defining the target operating model within the Utility\nRequired qualifications, capabilities, and skills\n2+ years of experience in data management, process management, business process reengineering or related field\nProject management and change management experience\nProcess modeling experience in defining new or changes to business and operations processes\nPrior writing experience creating documents, papers, policies, or procedures that are professional, comprehensive, and easily understood\nDemonstrated ability to obtain Subject Matter Expert (SME) knowledge of multiple processes\nExperience creating and presenting business updates\nSolid time management, organizational skills, and effective prioritization skills\nPreferred qualifications, capabilities, and skills\nParty reference data\nClient onboarding\nKnow Your Customer (KYC)\nRegulatory mandates such as MIFID, NCMR, EMIR, CCPA\nABOUT US\n\nJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.\n\nWe recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.\n\n\n\nABOUT THE TEAM\nThe Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world’s most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.\n\n\nOperations teams develop and manage innovative, secure service solutions to meet clients’ needs globally. Developing and using the latest technology, teams work to deliver industry-leading capabilities to our clients and customers, making it easy and convenient to do business with the firm. Teams also drive growth by refining technology-driven customer and client experiences that put users first, providing an unparalleled experience.",
         "Bengaluru",
         "657267.0",
         "/yr (est.)",
         "10000+ Employees",
         "1799",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "3.9",
         "3.6",
         "3.7"
        ],
        [
         "63",
         "BookMyShow",
         "Data Analyst - I",
         "3.9",
         "Your Profile\nResponsible for churning out regular as well as ad-hoc reports for multiple business verticals\nWorking on customer segmentation, retention and growth metrics to help CRM/Product teams with relevant target groups for upcoming Movies/Events\nCoordinating with teams to understand business problems and work towards solving them\nShould be able to make sense of large datasets, and derive actionable insights from it\nShould be able to comprehend business problem and solve it using the available data\nShould be able to work with product, technology and marketing teams to identify gaps in the data capture strategy. Implement processes that ensure data consistency and accuracy\nShould be able to identify trends/patterns within the data, draw insights out of it and share actionable steps with business teams\nFlexible to work as an individual contributor as well as a Team player\nYour Checklist\nShould have good understanding on writing SQL queries, joins etc. and also advanced Excel functions\nMinimum 2 years’ experience on data / Product analysis in leading eCommerce and/ or Internet companies\nExperience with Google Analytics\nGood understanding of any data visualisation tool like Tableau/Data Studio/Power BI/Quicksight/Qliksense\nPast experience of working on any data warehouse like Amazon Redshift / Snowflake / BigQuery would be an added advantage\nExperience on Python/R and statistical modelling would be an added advantage",
         "Mumbai",
         "375292.0",
         "/yr (est.)",
         "501 to 1000 Employees",
         "1999",
         "Company - Private",
         "Ticket Sales",
         "Arts, Entertainment & Recreation",
         "Unknown / Non-Applicable",
         "3.8",
         "3.5",
         "3.6",
         "3.5",
         "3.4"
        ],
        [
         "64",
         "Opalforce, Inc.",
         "HR Data Analyst",
         "4.0",
         "Job Title: HR Data Analyst\nLocation: Bangalore\nHigh Level JD:\nCollect, compile, and analyze HR Data for trends with regard to recruitment practices, retention/turnover and apply\nthis data to make recommendatios\nExcellent knowledge of Microsoft Office Suite, and Excel and the ability to createcharts,spreadsheets and presentations\nCompiling reports of data results and presenting these to senior managers.\nA minimum of 2 years experience in similar role.\nAbility to work with cross-functional teams\n\nAbout Opalforce, Inc. :\n\nOpalForce Inc is a renowned Google cloud partner. A global leader with more than 20 years of experience in providing enterprise-level solutions to industries sectors like Healthcare, Entertainment, Retail, Government, Education, and Manufacturing. OpalForce has proven expertise in Google Cloud Platform, Infrastructure Modernization, Cloud Migration, Scaling Production Workloads, Kubernetes on GCP, Production Machine Learning, Gsuite Licenses. OpalForce has started its journey in Santa Clara, California in the year 2000, and associated with Fortune 1000 companies to transform and innovate them with Data and machine intelligence, & Cloud consulting, and engineering.",
         "Bengaluru",
         "529150.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2001",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.5",
         "4.5",
         "4.5",
         "4.5",
         "4.5"
        ],
        [
         "65",
         "Ignitho",
         "Data Analyst Associate",
         "4.3",
         "Location:\nChennai, Tamil Nadu\n\nOpenings:\n5\n\nSalary Range:\n\nDescription:\nRoles and responsibilities:\nAssist in solving data-related problems and challenges within the organization.\nAssist in building and validating predictive models under the guidance of senior analysts or data scientists.\nPerform basic data analysis using tools like Excel, SQL, or statistical software.\nGenerate descriptive statistics and visualizations to understand the data.\nBe open to learning and seeking guidance from experienced professionals.\nEmployment details:\nTraining period : 6 months ( With Stipend )\nThere will be a 2-year employment agreement which they must sign, we will not take any originals of their educational certificates.\nOpen to work in UK Shift (3PM to 12AM)",
         "Chennai",
         "835332.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2016",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.4",
         "4.1",
         "4.3",
         "4.1",
         "4.4"
        ],
        [
         "66",
         "LKQ India",
         "Data Analyst",
         "3.8",
         "Location : Bengaluru\n\nShift Timings : General Shift\nSkills :\nBRD\nrequirement gathering\ndata validation\ndata analyze\nCoordination between User & development team. database data warehousing\nvisualization experience.\nJob Description :\nCollects, analyzes and validates data in the enterprise data warehouse against source systems and data governance policies to ensure proper data availability to business team members.\nWork with business teams and BI team to determine and document requirements for requests or issues related to data, reports, analysis, and training.\nIdentifies opportunities for transitioning ad hoc analysis into standardized reporting and dashboarding.\nCreates procedures and best practices for users of business intelligence tools.\nAssists team leads in team delivery management practices to ensure timely delivery of work to the business.\nCommunicates progress and changes being made to the business intelligence tools to business team members.\nDocuments data governance policies and practices\nAssumes other duties as assigned.",
         "Bengaluru",
         "611782.0",
         "/yr (est.)",
         "10000+ Employees",
         "1998",
         "Company - Public",
         "Automotive Parts & Accessories Stores",
         "Retail & Wholesale",
         "$5 to $10 billion (USD)",
         "3.7",
         "3.6",
         "3.9",
         "3.6",
         "3.9"
        ],
        [
         "67",
         "NEAR",
         "Big Data Analyst",
         "4.3",
         "Description\nYou will be joining Near, one of the fastest-growing Enterprise SaaS companies, and experience a true start-up culture with the freedom to experiment and innovate. At Near, we believe that great culture is not just about work; it’s work + life. We not only encourage our employees to dream big but also give them the freedom and the tools to do so.\nYour responsibilities will include extracting data from various sources, and interpreting and analyzing it to deliver actionable insights. You will also be responsible for presenting it effectively to enable data-driven decision-making through reporting, analysis, and optimization.\nThis will be a work-from-office role, based in our state-of-the-art office in Koramangala, Bangalore.\nA Day in the Life\nAbility to pull out reports from a complex web of Data Lakes, Data Warehouses, and Data Marts.\nDevelop techniques to analyze and work with big data tools and frameworks.\nBuild reusable and optimized code for future use.\nCollaborate with product managers and suggest appropriate solutions for analytics deliverables.\nEnsure all the deliverables are undertaken in a timely manner with zero errors.\nGet feedback and improve on efficiency.\nHelp the team synthesize both quantitative and qualitative data into insights that deepen our understanding of our product performance and user behavior.\nWhat You Bring to the Role\n0 -3 Years of experience in Data warehousing tools and technologies.\nExceptional skills in SQL, Python/ Pyspark.\nExceptional problem-solving, analytical, and organizational skills with an eye for detail.\nPassionate about learning new technologies.\nExperience with any Data Visualization or BI/reporting tool will be a plus.\nWork experience with AWS or any other cloud platform will be a plus.\nExperience in big data will a plus.",
         "Bengaluru",
         "774730.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2012",
         "Company - Private",
         "Enterprise Software & Network Solutions",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.2",
         "4.0",
         "4.3",
         "3.8",
         "4.3"
        ],
        [
         "76",
         "Infosys",
         "FHIR Data Analyst",
         "3.8",
         "A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction. • You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain. • You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews. • You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n• At least 1 year of experience in HL7 FHIR implementation. • Deep knowledge of HL7 FHIR 4.0.1 standard • Knowledge of FHIR implementation guides like DaVinci, CARIN, US Core etc. • Experience performing data mapping of Source data sets to FHIR resources • Analyzes the business needs, defines detailed requirements, and provides potential solutions/approaches with the business stakeholders • Strong experience and understanding of Agile Methodologies • Strong written and oral communication and interpersonal skills • Strong analytical, planning, organizational, time management and facilitation Skills • Strong understanding and experience of SDLC and documentation skills • Proficiency in Microsoft Suite (Word, Excel, Access, PowerPoint, Project, Visio, Outlook), Microsoft SQL Studio, JIRA\nnull\nHealthcare->FHIR/ HL 7",
         "Bengaluru",
         "468897.0",
         "/yr (est.)",
         "10000+ Employees",
         "1981",
         "Company - Public",
         "Information Technology Support Services",
         "Information Technology",
         "$10+ billion (USD)",
         "3.8",
         "3.0",
         "4.0",
         "3.5",
         "3.7"
        ],
        [
         "78",
         "Quantiphi",
         "Data Analyst",
         "4.3",
         "While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.\n\nIf working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!\nRole: Analyst - Sales Operations\nExperience Level: 2 to 4 Years\nWork location: Mumbai or Bangalore\nRole & Responsibilities:\n Analyzing and developing sales operations policies and procedures.\n Working with sales representatives from different regions/practices to confirm process, collect timely\ninputs towards projections and identify opportunities for improvement.\n Assisting in managing compliance program and sales operations help desk.\n Maintaining existing sales reports and designs new reports as needed.\n Participates in the evaluation, selection, and implementation of a decision-support tool.\n Acting as primary liaison on sales force automation projects/trends.\n Coordinating with cross functional teams to timely report revenue forecasts, establishing high levels of\nquality, accuracy, and consistency.\n Assist with maintaining the functional areas of data management, forecasting, contacts, leads,\nopportunities, dashboards and reports, and ensuring data integrity throughout our CRM system.\n Establishing effective analysis of sales force trends and performance in an effort to identify greater\nefficiencies and better manage and understand process bottlenecks and inconsistencies throughout the\nentire sales lifecycle.\n Performing ad hoc analysis for senior management to provide data support for business decisions.\n Evaluating new tools and platforms to improve reporting and sales operations.\nIf you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",
         "Mumbai",
         "647159.0",
         "/yr (est.)",
         "1001 to 5000 Employees",
         "2013",
         "Company - Private",
         "Business Consulting",
         "Management & Consulting",
         "Unknown / Non-Applicable",
         "4.1",
         "4.0",
         "4.0",
         "4.0",
         "3.5"
        ],
        [
         "81",
         "Agile CRM Inc.",
         "Data Analyst",
         "3.1",
         "Advanced experience using MS SQL, Excel and dashboard reporting is required.\nAdvanced experience with Power BI is required.\nExcellent process-documentation skills.\nDemonstrated analytical and problem-solving skills are a must.\nExperience in data analytics and reporting, market trends/analysis, etc.\nExcellent verbal and written communication skills for effective communication to internal teams\nAbility to manage multiple projects simultaneously, while meeting regular deadlines\nDemonstrated ability to work independently, and take initiative.\nFlexibility to work overtime hours (nights and weekends) when required.\nA minimum of experience in business intelligence and reporting, or a related field.\nExceptional analytical and conceptual thinking skills.\nExperience creating detailed reports and giving presentations.\nA track record of following through on commitments.\nExcellent planning, organizational, and time management skills.\nA history of leading and supporting successful projects.\nJob Type: Full-time\nPay: ₹700,000.00 - ₹900,000.00 per year\nBenefits:\nHealth insurance\nSchedule:\nFixed shift\nMonday to Friday\nMorning shift\nExperience:\ntotal work: 3 years (Required)\nAbility to Commute:\nMadhapur, Hyderabad, Telangana (Required)\nAbility to Relocate:\nMadhapur, Hyderabad, Telangana: Relocate before starting work (Required)\nWork Location: In person",
         "India",
         "800000.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2013",
         "Company - Private",
         "Enterprise Software & Network Solutions",
         "Information Technology",
         "Unknown / Non-Applicable",
         "2.9",
         "2.8",
         "2.8",
         "3.0",
         "2.9"
        ],
        [
         "85",
         "Airtel India",
         "Data Analyst",
         "4.1",
         "About the Company:\nAirtel is a leading telecom solutions provider in the country with over 300m subscribers. Our endeavor to keep building a value chain for our customers gives us various problem statements to solve for. We as an Organization strongly believe in data driven decision making and thrive on solving complex business problems with Analytics & Data Science.\nAbout the Position:\nWe are looking for a Data Analyst to join our Product & Business Analytics team at Airtel .\nThis role will be leading analytics for a division/pod. You will be expected to drive data driven decision making with senior management, own metrics for a pod.\nSolves business/product problems with accuracy and reliability\nCreate and explain data driven insights to a varied set of stakeholders\nChallenge the status quo and shape the analytics roadmap\nDrive clarity and bring forth creative solutions\nResponsibilities:\nDevelop an in-depth understanding of user journeys on Airtel Digital Channels and generate data driven insights & recommendations to help product/business in meticulous decision making\nEnd-to-end ownership of key metrics, work with respective stakeholders to understand areas we need to measure and ensure the needle is moving in the right direction\nDevelop strong hypothesis , execute A/B experiments and identify area of opportunities with strong confidence level\nWork cross-functionally to define problem statements, collect data, build analytical models and make recommendations\nIdentify and implement streamlined processes for data reporting, dashboarding and communication\nCollaborate with Product for data tracking and implementation of tools like Clickstream, Google analytics, Branch, Moengage etc.\nQualifications and Skills Requirements:\nB.Tech/BE degree in Computer Science/related technical field or Statistics/Operations Research background\n2+ years of experience in core business analytics/product analytics\nHands on experience on SQL, Python\nExperience of working on large datasets (big data)\nExcellent with data visualization and strong understanding of Tableau, Superset\nStrong problem-solving skills and should be able to engage senior management with data\nExperience with data structures & feature modelling. Ability to effectively manage and communicate data mart plans to internal customers\nEffective communication skills and experience working across multiple teams will be a plus (data engineering, data analytics, product squads)",
         "Gurgaon",
         "464758.0",
         "/yr (est.)",
         "10000+ Employees",
         "1995",
         "Company - Public",
         "Telecommunications Services",
         "Telecommunications",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "3.9",
         "3.7",
         "3.6"
        ],
        [
         "93",
         "Bursys",
         "Data Analyst Tranee",
         "3.7",
         "We are seeking a highly motivated and detail-oriented individual to join our team as a Data Analyst. As a Data Analyst, you will be responsible for collecting, processing, and analyzing data to provide valuable insights that will drive business decision-making.\nKey Responsibilities:\nCollect and gather data from various sources, ensuring data accuracy and completeness.\nClean, preprocess, and organize raw data for analysis.\nCommunicate findings to team members and management effectively.\nMaintain and update databases, ensuring data integrity and security.\nWork closely with cross-functional teams to understand business requirements and goals.\nStay updated on industry trends and advancements in data analytics.\nQualifications:\nBachelor’s degree in a relevant field such as Statistics, Computer Science, or related discipline.\nExcellent communication skills and Knowledge of machine learning concepts and algorithms.\nStrong analytical and problem-solving skills.\nJob Type: Full Time\nJob Location: Panchkula India",
         "Panchkula",
         "529150.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2005",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.7",
         "3.5",
         "3.5",
         "3.5",
         "3.5"
        ],
        [
         "94",
         "Tata Consultancy Services",
         "Data Analyst",
         "3.8",
         "Job Description\nJob Description\nDear Candidate\nGreetings from TCS !!!\n\nWe are looking for SAS SQL- DATA ANALYST\n\nExperience Range: 2-6 Years\nLocation: Chennai,Kolkata\n\nDesired Competencies (Technical/Behavioral Competency)\n\n1. Advanced/Expert SAS/SQL,\n2. Advanced/Expert Data Analysis,\n3. Advanced/Expert Excel\n\n1. Advanced Critical Thinking\n2. Intermediate Knowledge of Pharmacy Claims & Drug Data\n\nDesired Candidate Profile\nQualifications :BACHELOR OF TECHNOLOGY",
         "Chennai",
         "398701.0",
         "/yr (est.)",
         "10000+ Employees",
         "1968",
         "Company - Public",
         "Software Development",
         "Information Technology",
         "$10+ billion (USD)",
         "3.7",
         "3.1",
         "3.9",
         "3.3",
         "3.8"
        ],
        [
         "96",
         "ICON",
         "Lab Data Analyst I",
         "3.8",
         "At ICON, it’s our people that set us apart. Our diverse teams enable us to become a better partner to our customers and help us to fulfil our mission to advance and improve patients’ lives.\n\nOur ‘Own It’ culture is driven by four key values that bring us together as individuals and set us apart as an organisation: Accountability & Delivery, Collaboration, Partnership and Integrity. We want to be the Clinical Research Organisation that delivers excellence to our clients and to patients at every touch-point. In short, to be the partner of choice in drug development.\n\nThat’s our vision. We’re driven by it. And we need talented people who share it.\nIf you’re as driven as we are, join us. You’ll be working in a dynamic and supportive environment, with some of the brightest and the friendliest people in the sector, and you’ll be helping shape an industry.\n\nJOB-DESCRIPTION\nRecognize, exemplify and adhere to ICON's values which center around our commitment to People, Clients and Performance.\nAs a member of staff, the employee is expected to embrace and contribute to our culture of process improvement with a focus on streamlining our processes adding value to our business and meeting client needs.\nTravel (approximately <10%) domestic and/or international.\nMain contact for the Sponsors in all matters regarding our laboratories Global Data Services team.\nSign off on behalf of all ILS Global Data Services on study related agreements.\nAttend all meetings as required.\nPerform review of client specifications/requirements and offer suggestions and solutions that are agreeable to both the client and ILS Global Data Services team.\nManage and perform setup of each study to ensure that there are no issues when it comes to creating, QC’ing, and transmitting protocol specific data files in accordance with client specifications and departmental procedures.\nCommunicate directly with external clients to ensure that study goals are met. Complete GDS paper work and documentation in accordance with GDS SOP’s. (Data Export Agreement)\nConfigure database settings to ensure proper data content (data mapping).\nPartner with the Project Management team and external clients to add, remove, update and troubleshoot ICOLABS users and user accounts for various protocols in according to GDS ICOLABS SOP’s.\nWork within the ICOLABS system to add, remove; update users and user accounts for different protocols.\nTrain other Global Data Services staff as needed.\nPerforms additional relevant responsibilities as requested by management.\n\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\nKnowledge of Microsoft Office.\nExcellent oral and written communication skills.\nExperience with databases, medical terminology, clinical trials, or the ICOLIMS, Business Objects systems preferred.\nAbility to deal with high stress, excellent organizational skills, ability to multitask, good communication skills, and to be detail oriented.\nAll requirements for the Lab Data Analyst in-training position have been completed. (Or an alternative combination of experience, education, and training determined by management to be equivalent to the foregoing)\n\nBenefits of Working in ICON:\nOur success depends on the quality of our people. That’s why we’ve made it a priority to build a culture that rewards high performance and nurtures talent.\n\nWe offer very competitive salary packages. And to keep them competitive, we regularly benchmark them against our competitors. Our annual bonuses reflect delivery of performance goals – both ours and yours.\nWe also provide a range of health-related benefits to employees and their families and offer competitive retirement plans – and related benefits such as life assurance – so you can save and plan with confidence for the years ahead.\nBut beyond the competitive salaries and comprehensive benefits, you’ll benefit from an environment where you are encouraged to fulfil your sense of purpose and drive lasting change.\n\nICON is an equal opportunity and inclusive employer and is committed to providing a workplace free of discrimination and harassment. All qualified applicants will receive equal consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.\nIf, because of a medical condition or disability, you need a reasonable accommodation for any part of the application process, or in order to perform the essential functions of a position, please let us know through the form below.",
         "Bengaluru",
         "421485.0",
         "/yr (est.)",
         "10000+ Employees",
         "1990",
         "Company - Public",
         "Biotech & Pharmaceuticals",
         "Pharmaceutical & Biotechnology",
         "$2 to $5 billion (USD)",
         "3.6",
         "3.5",
         "3.7",
         "3.4",
         "3.7"
        ],
        [
         "97",
         "Nineleaps Technology Solutions Pvt Ltd",
         "Data Analyst",
         "4.2",
         "Nineleaps is a boutique technology-consulting firm, that helps funded ventures and enterprises accelerate their product development and data efforts. We are 450+ people strong and based out of Bangalore, India. Over the past 8 years, our community of engineers has delivered over 200 intuitive and pragmatic solutions to our clients’ more complex challenges. We have gained multiple levels of expertise by working with market leaders, technology giants, and the latest disruptors of many industries such as Retail, e-Business, Advertising, Finance, Transportation, Healthcare, and Education.\nWe are looking for skilled Data Analysts who can analyze data and derive data insights to assist organizations in making decisions.\nPrimary Responsibilities:\nEnhancing data collection procedures\nProcessing, cleansing & verifying the integrity of data\nUtilizing cloud databases & on-prem Microsoft databases\nExamine and correct data that has been corrupted\nStatistical analysis\nWork with management and technical teams to establish essential metrics and KPIs, as well as their analytical requirements\nData visualization\nDeveloping business intelligence reports & dashboards\nProvide actionable information to various stakeholders to assist them in making well-informed decisions\nDetermine and implement data acquisition and integration logic to guarantee optimal performance and scalability of the systems\nDesired Skills and Experience:\nStrong understanding of data mining, data models, segmentation techniques, and database design development\nAbility to structure, analyze, and extract data according to business requirements\nStrong SQL Experience, Power BI / Tableau / Google Data Studio\nApplied statistics or experimentation (i.e. A/B testing) experience in an industry setting\nExperience with programming languages and frameworks such as Python, JavaScript, XML, and ETL\nStrong analytical abilities, including the ability to gather, organize, analyze, and distribute large volumes of data with precision and attention to detail\n(Or) Send in your resumes to jobs@nineleaps.com\nOverview\nLocation\nBangalore\nExperience\n1 to 4 years",
         "Bengaluru",
         "572576.0",
         "/yr (est.)",
         "201 to 500 Employees",
         "2014",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.1",
         "3.8",
         "4.0",
         "3.8",
         "3.8"
        ],
        [
         "103",
         "UBS",
         "Data Analyst",
         "3.9",
         "India\nBusiness development, Business management, administration and support, Risk\nGroup Functions\nJob Reference #\n284924BR\nCity\nHyderabad\nJob Type\nFull Time\nYour role\nDo you have strong analytical skills? Are you familiar with statistical concepts and able to transform data into bespoke content? Do you want to help us expand our data platform?\n\nWe’re looking for a data analyst to:\n\nprovide analytics and reporting support on a broad range of risk and operational data for our business and senior management\nassess and enhance the data collection procedure and automate reporting processes using SQL, VBA\nTransform, visualize data and create dashboards using Excel, Alteryx, Power BI & Tableau\nrun the necessary operational and data governance services required for data integrity\nenhance existing data repository to ensure stakeholders’ efficient access to data\nresearch and explore new data sources and analytics tools to continuously enhance our solutions\nYour team\nYou’ll be working in the Metrics and Reporting team in Hyderabad. Our team works closely with our business stakeholders, Automation and IT teams to support the availability and analytics of high quality operational and business data. As a data analyst, you'll play an important role in assessing the business and operational risks and overseeing the reporting of issues and their sustainable remediation.\nYour expertise\nideally 2-3 years’ relevant experience of working in data analysis in financial services, data operations, data platforms\nstrong analytical and coding skills, familiar with programming languages such as Python\ninterested in digitalization and have an affinity with technology like Power BI, Alteryx Tableau, SQL, Data science skills\nbachelor’s/master’s degree in finance, business administration or related field\nHand on experience in verifying data accuracy, using statistical tools to analyze complex data to interpret trends and patterns and creating data systems and reports for management.\ninquisitive, able to challenge effectively and manage conflicting stakeholder needs\nself-driven and focused on the details, with a good understanding of the banking industry\nstrong communicator, with a collaborative personality and the ability to complete tasks independently\nHow we hire\nThis role requires an assessment on application. Learn more about how we hire: www.ubs.com/global/en/careers/experienced-professionals.html",
         "Hyderābād",
         "727518.0",
         "/yr (est.)",
         "10000+ Employees",
         "1862",
         "Company - Public",
         "Investment & Asset Management",
         "Finance",
         "$10+ billion (USD)",
         "3.6",
         "3.5",
         "3.9",
         "3.5",
         "3.8"
        ],
        [
         "105",
         "S&P Global",
         "Data Analyst",
         "4.1",
         "About the Role:\nGrade Level (for internal use): 08\nThe Rol e: Data Analyst\n\nThe Team : You will be part of the Data Team, which deals with the collection, processing, and analysis of data from the energy and agriculture industries. The team provides and maintains accurate, complete, and timely datasets, taking into account the global interests and needs of business units internally and externally.\n\nThe Impact : We provide the highest quality content that is essential for our clients to make decisions with conviction. As a Data Analyst, you will use our internal tools to support the integrity and comprehensiveness of the data set obtained from internal and external public research sources, such as government and regulatory documents, industry journals, and analyst reports.\n\nResponsibilities:\nWork with SQL and Python tools to solve problems and ensure database quality\nCollecting, analyzing, extracting, and entering high-quality data (financial and non-financial data) into work tools in accordance with the guidelines' criteria\nFilter Data by reviewing reports and performance indicators to identify and correct code problems\nHave a solid working understanding of the processes, the dataset's operation, and the available work tools\nProviding input and ideas for new collection methods and product enhancements related to the dataset\nAchieve predetermined individual and team objectives, including providing results at the highest level.\nWhat We’re Looking For:\nBachelor’s degree in information technologies, computer science or equivalent\nA drive to learn and master new technologies and techniques\nStrong mathematical & numeracy skills.\nStrong analytical and communication skills\nGood understanding of Python and SQL languages\nIntermediate understanding of databases such as SQL Server or Snowflake\nUnderstanding of reporting & data visualization tools such as PowerBI and Tableau.\nUnderstanding of ETL framework and ETL tools (e.g. Alteryx)\nProblem-solving skills\nStrong attention to detail\nAbility to work in an agile team environment\nFlexible Working: We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.\n\nReturn to Work: Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace.\n\nAbout S&P Global Commodity Insights\nAt S&P Global Commodity Insights, our complete view of global energy and commodities markets enables our customers to make decisions with conviction and create long-term, sustainable value.\nWe’re a trusted connector that brings together thought leaders, market participants, governments, and regulators to co-create solutions that lead to progress. Vital to navigating Energy Transition, S&P Global Commodity Insights’ coverage includes oil and gas, power, chemicals, metals, agriculture and shipping.\nS&P Global Commodity Insights is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.\n\nFor more information, visit http://www.spglobal.com/commodity-insights .\n\nWhat’s In It For You?\n\nOur Purpose:\nProgress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.\n\nOur world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.\n\nOur People:\nWe're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.\n\nFrom finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.\n\nOur Values:\nIntegrity, Discovery, Partnership\n\nAt S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.\n\nBenefits:\nWe take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.\n\nOur benefits include:\nHealth & Wellness: Health care coverage designed for the mind and body.\n\nFlexible Downtime: Generous time off helps keep you energized for your time on.\n\nContinuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.\n\nInvest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.\n\nFamily Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.\n\nBeyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.\nFor more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/\n\nDiversity, Equity, and Inclusion at S&P Global:\nAt S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.\n\n-----------------------------------------------------------\n\nEqual Opportunity Employer\nS&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.\n\nIf you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.\n\nUS Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.\n\n----------------------------------------------------------- ANLYTC203 - Entry Professional (EEO Job Group)\n\nJob ID: 293364\nPosted On: 2024-01-01\nLocation: Bangalore, Karnataka, India",
         "Bengaluru",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "1860",
         "Company - Public",
         "Research & Development",
         "Management & Consulting",
         "$10+ billion (USD)",
         "3.8",
         "3.8",
         "4.2",
         "3.8",
         "4.2"
        ],
        [
         "108",
         "Kovai.co",
         "Data Analyst",
         "4.5",
         "Kovai.co, the fastest growing SaaS organization is a premier enterprise software company offering multiple products at scale both in the enterprise arena and in the B2B SaaS space.\nWe are a technology partner of choice for many of the world’s leading enterprises to manage and monitor their Microsoft BizTalk and Azure Serverless environments.\n\nWe always stand out from the crowd with our product team consisting of thinkers and innovators who are redefining the way robust Enterprise Software and SaaS products are built. Headquartered in London, U.K and with a development center in Coimbatore, India, our engineers have niche skills and in-depth domain knowledge.\n\nTrusted by over 1,000+ businesses around the world.\n\nKey Products:\n\nBizTalk360\nServerless360\nDocument360\nChurn360\nKovai.co Awards & Recognitions:\n\nKovai.co wins the title “Bootstrap Champ” at The Economic Times Startup Awards 2021.\nWinner of Bootstrapped SaaS start-up of the year by SaaS BOOMi.\nNASSCOM Recognizes Document360 at Emerge 50 Awards 2021.\n\nWe wish to be known for our values of integrity, teamwork and excellence. As we grow, we ensure that our culture remains at the heart of Kovai.co.\nWe are constantly on the lookout for smart people who are passionate about building great products, designing great experiences, building scalable platforms, and making customers happy. If you’re looking to make an impact, Kovai.co is the place for you. If this describes you, feel free to have a look at our openings in our career page and apply to be a part of the $30 million journey!\n\nOpportunity: Data Analyst\n\nWhat you’ll do on the job:\n\nCollecting and interpreting data, analysing results, identifying patterns and trends in data sets.\nSegregation, classification, and analysis of data.\nWriting reports based on insights gained from data analysis\nWriting Python code for achieving the business outcomes\nBuilding visualisations and metrics for showcasing business metrics\nPerforming data quality checks for quality assurance\nDocumenting data analysis, business logics and metrics methodology\nSupports innovative analytical thinking & solutions that results into improved business performance.\n\nWho’ll be a good fit:\n\nProven work experience of 1-2 years as a Data Analyst.\nStrong in mathematics - statistics, probability, algebra, set theory, time series, calculus, graph theory, etc.\nExperience with data wrangling, web scraping, data schema preparation\nData extraction, Data cleaning, Data cleansing, Data transformation, Report building and automation.\nProficient in SQL, Python coding & BI Tool such as Tableau ,PowerBI\nWrite scalable scripts to fetch or modify data from API endpoints.\nExcellent critical thinking, verbal, and written communication skills.\nData science background is an advantage, Exposure to cloud technology is preferred\n\nPerks:\n\nCollaborative and fun team.\nFlat organizational structure.\nRewards and recognition.\nHealth care benefits.\nUpskill allowance.\nLocated at the heart of the city with world class infrastructure\n\nIf this excites you, apply for this opportunity, and the team would love to get on a call with you to discuss further.",
         "Coimbatore",
         "438621.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2010",
         "Company - Private",
         "Enterprise Software & Network Solutions",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.6",
         "4.1",
         "4.3",
         "4.5",
         "4.5"
        ],
        [
         "116",
         "Hudson's Bay Company",
         "Jr. Data Analyst",
         "3.6",
         "Job Description\nDay in the Life:\nThe Data Analyst will be part of a dynamic team that supports the execution of initiatives in Data Analytics. They work cross functionally with teams to develop and deliver projects that will drive success at The Bay. They will interact with project stakeholders, business leaders and collaborate with a team of data experts to leverage data and perform deep dive analyses and build data/reporting products. They will explore new insights and innovation by leveraging advanced analytics to derive data backed insights. This is the perfect role that provides an opportunity to gain further advanced experience in retail business initiatives and understanding of retail analytics and insights.\n\nWhat You Will Do:\nAssist in defining project scope and objectives and developing plans to monitor and track progress.\nCommunication of the analysis processes and insights to stakeholders and other analytics teams across the organization.\nPartner and align with stakeholders across the banners to brainstorm, test and develop analysis that delivers quick insights to confirm or deny business hypotheses.\nProactively identify analytical opportunities that will lead to improved business results\nActively contribute to enhancing the analytics team’s foundational and scalable processes and best practices for data extraction, manipulation, analysis, provision of insights, and the mechanism to drive actions or decision making\nParticipate in defining analytic requirements for new projects and contribute to the delivery of new dashboards and reports.\nProvide ad-hoc analysis support\n\nWhat You Will Need:\nUniversity degree required, preferred in Statistics, Business Analytics, or related field\nExperience in Business Intelligence/Visualization experience\n2+ year in SQL and/or Python\nStrong data mining and analytical skills and able to translate findings into clear, actionable insights and recommendations\nGood communication skills with the ability to explain technical concepts to a diverse audience in business terms.\nAbility to “storytell” through analytics and presentation materials\nCreative thinker and solutions oriented, committed to driving business improvements\nAbility to handle multiple demands and competing priorities.\nProactive approach to problem-solving, working collaboratively, and supporting the team.\nAbility to be flexible and adaptable while operating independently and as part of a team.\nJob Qualifications\nThe Fabric of Hudson’s Bay\nHudson's Bay has established a reputation for quality and style through an unrivaled assortment of products and categories including fashion, home, beauty, food concepts, and more. Hudson's Bay operates under the HBC brand portfolio. Founded in 1670, HBC is North America's oldest company. Hudson’s Bay helps Canadians live their best style of life by operating thebay.com featuring Marketplace, one of the largest premium life & style digital platforms in Canada, with a seamless connection to a network of Hudson’s Bay stores from coast to coast.\nAt Hudson’s Bay, smart, high-performing team members will challenge you to learn and grow every day.\nWe’d love for you to join us in our mission to help Canadians live their best style of life! Stay connected with us on Instagram, Facebook, Twitter, TikTok, and LinkedIn\nThank you for your interest In Hudson’s Bay. We look forward to reviewing your application.\nAs an equal opportunity employer, Hudson’s Bay is committed to providing you with a barrier-free, inclusive and accessible workplace to lead a brilliant career.",
         "Bengaluru",
         "539530.5",
         "/yr (est.)",
         "10000+ Employees",
         "1670",
         "Company - Public",
         "Department, Clothing & Shoe Stores",
         "Retail & Wholesale",
         "$10+ billion (USD)",
         "3.2",
         "3.1",
         "3.4",
         "3.1",
         "3.5"
        ],
        [
         "118",
         "iXceed Solutions",
         "Data Analyst",
         "4.7",
         "Job Title: Data Analyst (Product Development domain)\nLocation: Gurugram, Haryana\nRole Type: Permanent (Onsite)\nMust Required:\nData Analyst should be from Product Development domain\nOne should have an idea of Data Engineering as well, as in Knowledge of Data Development using Python etc.\nJob Description:\nCompany Overview: Veera is a dynamic and innova/ve browser company commi3ed to\nleveraging data-driven insights to op/mize decision-making and drive business success. We\nare seeking a skilled and mo/vated Data Analyst to join our growing team and contribute to\nthe company's strategic objec/ves.\nPosi9on Overview: As a Data Analyst at Veera, you will play a crucial role in transforming\nraw data into ac/onable insights that inform key business decisions. You will work closely\nwith cross-func/onal teams to gather, analyze, and interpret data, providing valuable\nrecommenda/ons that enhance our overall performance and compe//veness in the market.\nResponsibilities:\nData Collection and Processing:\nCollect, clean, and pre-process large datasets from various sources to ensure data accuracy\nand reliability.\nImplement data quality checks and valida/on procedures to maintain the integrity of our\ndata.\nData Analysis:\nPerform exploratory data analysis to iden/fy trends, pa3erns, and correla/ons in the data.\nConduct sta/s/cal analyses to extract meaningful insights and provide data-driven\nrecommenda/ons.\nReporting and Visualization:\nCreate and maintain dashboards and reports to communicate key performance indicators\nand trends to stakeholders.\nU/lize visualiza/on tools (e.g., ReDash, Tableau, Power BI) to present complex data in an\naccessible and understandable format.\nCollaboration:\nWork closely with cross-func/onal teams to understand business requirements and provide\nanaly/cal support for decision-making processes.\nCollaborate with Engineering and other func/ons to ensure data infrastructure meets\nanaly/cal needs.\nContinuous Improvement:\nStay abreast of industry trends, best prac/ces, and emerging technologies in data analysis.\nPropose and implement improvements to exis/ng processes to enhance the efficiency and\neffec/veness of data analysis ac/vi/es.\nRequirements:\nDegree in Data Science, Sta/s/cs, Mathema/cs, Computer Science, or a related field.\n3-5 years of proven & relevant experience as a Data Analyst or in a similar role.\nStrong proficiency in data analysis tools and programming languages (e.g., SQL, Python).\nExperience with data visualiza/on tools (e.g., ReDash, Tableau, Power BI).\nExposure & Experience with Data Engineering is an added advantage\nSolid understanding of sta/s/cal concepts and methods.\nExcellent communica/on and presenta/on skills.\nA3en/on to detail and the ability to work independently as well as collabora/vely within a\nteam.\nJob Types: Full-time, Permanent\nSalary: ₹1,500,000.00 - ₹2,500,000.00 per year\nApplication Question(s):\nOne should have an idea of Data Engineering as well, as in Knowledge of Data Development using Python?\nExperience:\ntotal work: 5 years (Required)\nProduct Development domain: 2 years (Required)\nProduct Analyst: 2 years (Required)\nSQL: 1 year (Required)\nPython: 3 years (Required)\nData visualization: 2 years (Required)\nB2C: 2 years (Required)\nMobile applications: 2 years (Required)\nWork Location: In person",
         "Gurgaon",
         "2000000.0",
         "/yr (est.)",
         "501 to 1000 Employees",
         "2012",
         "Company - Private",
         "Staffing, Recruitment & Subcontracting",
         "Human Resources & Staffing",
         "$5 to $25 million (USD)",
         "4.7",
         "4.4",
         "4.7",
         "4.6",
         "4.7"
        ],
        [
         "121",
         "kaleidofin",
         "Data Analyst",
         "3.4",
         "Who we are?\nKaleidofin is a fintech with a focus on the informal sector, we provide solutions tailored to the customer’s goals and are intuitive to use. We are working towards creating fair and transparent financial solutions that can target millions of customers and enterprises in India that don’t have easy access to formal financial planning.\n‍\nIn a very short time span, global investors such as Oiko Credit, Flourish, Omidyar Network andBlume Ventures have supported Kaleidofin’s well thought out business model. The firm’s latest round was Series B of funding led by The Dell Foundation & The Bill & Melinda Gates foundation inMay 2022. Kaleidofin is recertified as a Great Place to Work from September’22.\n‍\nThe company won the Amazon AI Conclave award for Fintech, was one of only ten startups chosen for the Google LaunchPad Accelerator program in 2019, was recognized as India’s Most InnovativeWealth, Asset and Investment Management Service/Product by the Internet & Mobile Association of India (IAMAI) and was selected to present at United Nations General Assembly Special Task ForceEvent.\n‍\nWith its focus to harness mobile technology to deliver a paperless experience as well as its focus to harness technology and analytics to predict the right product for the right customer, Kaleidofin aims to become a leading FinTech player bringing financial solutions to everyone.\n‍\nTo know more about Kaleidofin, do visit our site https://kaleidofin.com\nWhat you’ll do?\nWe are looking for a developer to design and deliver strategic data-centric insights leveraging the next generation analytics and BI technologies. We want someone who is data-centric and insight-centric, less report centric. We are looking for someone wishing to make an impact by enabling innovation and growth; someone with passion for what they do and a vision for the future.\nBe the analytical expert in Kaleidofin, managing ambiguous problems by using data to execute sophisticated quantitative modeling and deliver actionable insights.\nDevelop comprehensive skills including project management, business judgment, analytical problem solving and technical depth.\nBecome an expert on data and trends, both internal and external to Kaleidofin.\nCommunicate key “state of the business” metrics and develop dashboards to enable teams to understand business metrics independently.\nCollaborate with stakeholders across teams to drive data analysis for key business questions, communicate insights and drive the planning process with company executives.\nAutomate scheduling and distribution of reports and support auditing and value realization.\nPartner with enterprise architects to define and ensure proposed Business Intelligence solutions adhere to an enterprise reference architecture.\nDesign robust data-centric solutions and architecture that incorporates technology and strong BI solutions to scale up and eliminate repetitive tasks.\nLocation: Chennai/Bangalore, mandatory work from office - hybrid\n‍\nWho you need to be?\nExperience leading development efforts through all phases of SDLC.\n3+ years experience designing Analytics and Business Intelligence solutions and working on developing meaningful visualizations.\nAbility to handle complex data structures and have strong command on Writing Complex DAX function, Power Query, Power Apps.\nExperience in Building Power BI Data Model, Dashboard & Reports using various Chart, Slicer, Pivot and Custom Visuals.\nStrong command on Power bi / Tableau is a must.\nHands on experience in SQL, data management, and scripting (preferably Python).\nStrong data visualization design skills, data modeling and inference skills.\nHands-on and experience in managing small teams.\nFinancial services experience preferred, but not mandatory.\nStrong knowledge of architectural principles, tools, frameworks, and best practices.\nExcellent communication and presentation skills to communicate and collaborate with alllevels of the organization.\nIf you fit the bill, write to me at\ncareers@kaleidofin.com\nJob location\nChennai/Bangalore",
         "Chennai",
         "539530.5",
         "/yr (est.)",
         "51 to 200 Employees",
         "2017",
         "Company - Private",
         "Investment & Asset Management",
         "Finance",
         "$5 to $25 million (USD)",
         "3.1",
         "2.7",
         "2.7",
         "3.0",
         "2.4"
        ],
        [
         "126",
         "Simplex Services",
         "Data Analyst/Power BI Reporting",
         "4.0",
         "Simplex requires a Power BI Developer to build and maintain BI and analytics solutions that transform data into knowledge.\nThe right candidate must have business understanding and problem-solving skills with experience in data and business analysis. The candidate should also have good analytical ability alongside excellent communication skills.\nEmployment Type: Full-time\nRoles & Responsibilities:\nPower BI Report development.\nAnalyse data and display it in reports to aid decision-making.\nUse SQL queries to get the best results.\nFor a better understanding of the data, use filters and visualizations.\nConvert business needs into technical specifications and establish a timetable for job completion.\nAnalytical thinking for translating data into informative reports and visuals.\nConnecting data sources, importing data, and transforming data for Business intelligence.\nBuilding Analysis Services reporting models.\nShould be able to develop tabular and multidimensional models that are compatible with data warehouse standards.\nVery good communication skills must be able to discuss the requirements effectively with the client teams, and with internal teams.\nGood to have:\nYou are an ambitious and self-motivated professional.\nYou have a healthy competitive nature and always strive to do your best.\nYou are committed to learning every day and take personal pride in the work that you deliver.\nYou are calm under pressure, and you have a strong work ethic.\nMulti-tasking comes easily to you, and you do not need to learn how to manage your time effectively.\nMust have:\nShould be proficient in software development.\nMandate to have experience with BI tools and systems such as Power BI, Tableau, and SAP.\nKnowledge of Microsoft BI Stack.\nPrior experience in data-related tasks.\nMastery of data analytics .\nBe familiar with MS SQL Server BI Stack tools and technologies, such as SSRS and TSQL, Power Query, MDX, PowerBI, and DAX .\nAnalytical thinking for converting data into relevant reports and graphics.\nCapable of enabling row-level data security.\nKnowledge of Power BI application security layer models .\nProficient in doing advanced-level computations on the data set.\nSimplex-Services, headquartered in Brighton, formed in 2014, specialises in information technology consulting and the implementation of IT services across all industries. Our agile, dynamic teams of IT and business strategy enablers allow us to cut across the limitations of large-scale organisations by delivering services and solutions with speed, precision and flexibility. With over 100 years of corporate experience amongst our founding members, we offer our clients immediate advice and tailored solutions to your strategy. With a fresh approach to IT and practical awareness that any solution needs to be end user-centric and aligned to a strategy, Simplex Services have the capabilities to resolve small- and large- scale projects, whether in-house or through smart source frameworks.\nShare your resume at careers@simplex-services.com, if interested.\nJob Location: UK & India",
         "India",
         "539530.5",
         "/yr (est.)",
         "1 to 50 Employees",
         "2014",
         "Company - Private",
         "Enterprise Software & Network Solutions",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.6",
         "4.5",
         "4.9",
         "5.0",
         "4.7"
        ],
        [
         "138",
         "iCRC",
         "BI Data Analyst",
         "3.9",
         "Duties and Responsibilities include but are not limited to:\n\nWhat will you be doing?\n\nInteract with internal and client teams to identify questions and issues for data analysis and experiments.\nDevelop and code software programs, algorithms and automated processes to cleanse, integrate and evaluate large data sets from multiple disparate sources.\nWork with massive and complex data sets from multiple sources, utilising big data tools and techniques to analyse, provide insight and validate hypotheses.\nPerforming deep dive analyses of experiments through reliable modelling methods that include numerous explanatory variables and covariates.\nTranslating analytical insights into concrete, actionable recommendations for business, process or product improvements.\nMaking recommendations for the collection of new data or the refinement of existing data sources and storage.\nCollaborate with subject matter experts to deliver and solve real-world engineering problems with ML and data science.\nCollaborate across the business to influence change and bring ideas to life.\nCreate solutions that will benefit the wider community.\nContribute to creating a more sustainable future.\n\nWhat we'll love about you\n\nMinimum Educational Qualification- Engineering Graduate\n1 - 5 years' experience in a data science environment (experience may be corporate, research/government or academia)\nAbility to manipulate and analyse complex, high-volume, high dimensionality data and metadata from varying sources.\nPassion for empirical research and for answering hard questions with data.\nKnowledge of analytical tools and big data technologies (Map/Reduce, Hadoop, Hive, etc).\nFamiliarity with relational/non-relational data manipulation, machine learning, and scientific statistical analysis.\nAbility to communicate complex quantitative analysis in a clear, precise, and actionable manner.\nFlexible analytical approach that allows for results at varying levels of precision.\nSolid understanding and experience with programming logic and various paradigms.\nGood Communication Skills",
         "Bengaluru",
         "460906.0",
         "/yr (est.)",
         "10000+ Employees",
         "1863",
         "Non-profit Organisation",
         "Civic, Welfare & Social Services",
         "Non-profit & NGO",
         "Unknown / Non-Applicable",
         "3.3",
         "3.6",
         "3.8",
         "3.1",
         "3.5"
        ],
        [
         "142",
         "Cargill",
         "Data Analyst - Price hub",
         "4.1",
         "Want to build a stronger, more sustainable future and cultivate your career? Join Cargill's global team of 155,000 employees who are committed to safe, responsible and sustainable ways to nourish the world. This position is in Cargill’s food ingredients and bio-industrial business, where we anticipate trends around taste, nutrition and safety to innovate and provide solutions to manufacturers, retailers and foodservice companies.\nJob Purpose and Impact\n\nThe Data Analyst - Price hub is responsible for delivering robust data support along with analytic inputs in business requirements and data management activities to support different business units within Cargill. In this role, you will contribute to the continuous process improvement on price data management, standardization and harmonization and you will be actively involved in developing and implementing action plans on business performance optimization. Key Accountabilities\n\nDeploy a basic understanding of the trading questions that data can help to solve. Mapping upstream data source fields to Price Hub attributes; along with formulating transformation rules for new/derived columns in mapping\nWork with data engineers to give them the requirement for them to create the data output flow. Test the output data within Price Hub to validate if it is as per the said rules and check for anomalies and relay them back to data engineers for corrections. Create documentation for the newly mapped data source for consumers for easy understanding and create adhoc SQL queries for consumers based on their requirements. Handle basic issues and problems under direct supervision, while escalating more complex issues to appropriate staff.\nOther duties as assigned Qualifications\n\nMinimum Qualifications\nBachelor's degree in a related field or equivalent experience\nMinimum of two years of experience in a related field Experience in MS office suite (Outlook, Excel, Word, Power Point) and entry level SQL\nPreferred Qualifications Experience in managing and planning pricing metadata such as data mining and analysis of price types such as exchange futures prices, options, cash, bids and offer price etc. Ability to make case across and help people learn the basic of data connection to web-based portal to power excel via Oracle Database Connectivity (ODBC)",
         "Gurgaon",
         "612372.0",
         "/yr (est.)",
         "10000+ Employees",
         "1865",
         "Company - Private",
         "Crop Production",
         "Agriculture",
         "Unknown / Non-Applicable",
         "3.8",
         "3.9",
         "4.1",
         "3.6",
         "3.8"
        ],
        [
         "144",
         "Amber Internet solutions",
         "Data Analyst",
         "4.3",
         "Data\nData Analyst\nPune, Maharashtra | Full Time\n\nAbout Amber\nLong-term accommodation booking platform for students (think booking.com for student housing). Amber helps 80M students worldwide, find and book full-time accommodations near their universities, without the hassle of negotiation, non-standardized and cumbersome paperwork, and broken payment process.\nWe are the leading student housing platform globally, with 1M student housing units listed in 6 countries and across 80 cities. We are growing rapidly and targeting $2B in annual gross bookings value by 2024.\n\nIf you are passionate about making international mobility and living, seamless and accessible, then - Join us in building the future of student housing!\n\nRoles and Responsibilities Include:-\nDeveloping and maintaining databases, data systems\nPerforming analysis to assess the quality and meaning of data\nGenerate dynamic dashboards and reports\nIdentify, analyze, and interpret patterns and trends in complex data sets that could be helpful for the diagnosis and prediction\nAssigning numerical value to essential business functions so that business performance can be assessed and compared over periods.\nAnalyzing local, national, and global trends that impact both the organization and the industry Preparing reports for the management stating trends, patterns, and predictions using relevant data\n\nSkills required:-\nMinimum 2-3 years of proven experience in Data analytics.\nStrong mathematical skills to help collect, measure, organize, and analyze data.\nKnowledge and hands-on experience with programming languages like SQL and Python.\nExperience in ETL framework. Knowledge of data visualization software like Tableau, Metabase, etc.\nKnowledge of AWS Data-warehouse- Redshift is a plus.\nProblem-solving skills\nAccuracy and attention to detail\nGood verbal and Written communication skills\n\nHow to apply:-\nReach out to aarti.s@amberstudent.com\nor visit the following link - amberstudent.com/careers",
         "Pune",
         "494268.0",
         "/yr (est.)",
         "501 to 1000 Employees",
         "2016",
         "Company - Private",
         "Internet & Web Services",
         "Information Technology",
         "$5 to $25 million (USD)",
         "4.2",
         "3.9",
         "4.3",
         "4.1",
         "4.0"
        ],
        [
         "145",
         "SUPERDNA 3D LAB",
         "Data Analyst",
         "4.0",
         "Responsibilities\n\nUsing automated tools to extract data from primary and secondary sources\nRemoving corrupted data and fixing coding errors and related problems\nDeveloping and maintaining databases, data systems – reorganizing data in a readable format\nPerforming analysis to assess quality and meaning of data\nFilter Data by reviewing reports and performance indicators to identify and correct code problems\nUsing statistical tools to identify, analyze, and interpret patterns and trends in complex data sets that could be helpful for the diagnosis and prediction\nAssigning numerical value to essential business functions so that business performance can be assessed and compared over periods of time.\nAnalyzing National, and global trends that impact both the organization and the industry\nPreparing reports for the management stating trends, patterns, and predictions using relevant data\nWorking with 3D Technical leads, and management heads to identify process improvement opportunities, propose system modifications, and devise data governance strategies.\nPreparing final analysis reports for the stakeholders to understand the data-analysis steps, enabling them to take important decisions based on various facts and trends.\n\nSkills\n\nKnowledge of programming language\nMust have good analytical skills, logical ability and Reasoning skills\nMust have experience in Advance Excel and Google spreadsheets\nGood to have knowledge of Google cloud platform and data studio.\nAny Data Visualization Tool (Power BI/Tableau) Will be a plus.",
         "Chandigarh",
         "467012.0",
         "/yr (est.)",
         "1 to 50 Employees",
         "2017",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.1",
         "3.5",
         "4.2",
         "4.0",
         "4.2"
        ],
        [
         "151",
         "Nangia & Co LLP",
         "Data Analyst",
         "4.0",
         "Job Description\n\nDesignation\nData Analyst\n\nLocation\nChennai\n\nEducation\nPostgraduate in Econometrics, Economics, Statistics, Computer Science or related field from a recognized institution\nExperience\nrelated field from a recognized institution Minimum of 5 years’ experience. She/He should have relevant experience in handling survey and secondary datasets. She/he should have experience handling spatial datasets, cleaning, mapping, and analysing them through relevant software like Python, R, etc.\nApply Here",
         "Chennai",
         "275768.0",
         "/yr (est.)",
         "501 to 1000 Employees",
         "1984",
         "Private Practice / Firm",
         "Accounting & Tax",
         "Finance",
         "$100 to $500 million (USD)",
         "3.5",
         "3.4",
         "3.3",
         "3.0",
         "3.5"
        ],
        [
         "162",
         "iXie Gaming",
         "Game Data Analyst",
         "4.3",
         "Job Information\nRSD NO\n6840\nIndustry\nGame Development\nMin Experience\n3\nMax Experience\n8\nCity\nBangalore North\nState/Province\nKarnataka\nCountry\nIndia\nZip/Postal Code\n560002\nJob Description\nUse data to deliver fundamental insights on the player and game performance. Identify and formalise problems related to player behaviour, acquisition and churn. Communicate your impactful findings in visual form to technical and non-technical team members demonstrating impactful and visual insights. ROLE & RESPONSIBILITIES -Analyze and acquire a deep understanding of game features/user behaviour/metric trends through data and create impactful, actionable and valuable insights to drive product decisions -Understanding business requirements and implementing analytical solutions & techniques. -Designing and analysing experiments to test new product ideas and define the KPIs that measure the game’s performance in a meaningful way. -Develop algorithms and predictive models to solve critical business problems and test feasibility of solution approach -Own the design, development, and maintenance of ongoing reports, dashboards, etc. -Developing tools and libraries that will help the team to improve efficiency.\nIndium Software is an Equal Opportunity Employer and does not discriminate on the basis of race or ethnicity, religion, sex, national origin, age, veteran disability or genetic information or any other reason prohibited by law in employment.",
         "Bengaluru",
         "649084.0",
         "/yr (est.)",
         "501 to 1000 Employees",
         "2011",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "4.3",
         "3.9",
         "4.3",
         "4.2",
         "4.4"
        ],
        [
         "163",
         "JPMorgan Chase & Co",
         "Know Your Customer - Client Data Analyst",
         "4.0",
         "JOB DESCRIPTION\n\nAs a Know Your Customer Analyst in Wholesale Know Your Customer Operations, you will be responsible to review the records completed by production team to ensure all client Know Your Customer records are compliant with regulatory standards, and will ensure high quality and timely completion of all client-level due diligence You will assist in end to end operations review and the client-facing team. You will perform a research to ensure a client’s Know Your Customer profile is appropriately updated and any discrepancies or issues with the profile escalated to the appropriate lines of business.\nYou will be responsible for ascertaining that all Know Your Customer and Anti Money Laundering policies are adhered to and will be responsible for conducting reviews of client’s Know Your Customer documentation stored in internal repositories and publicly available information, performing the necessary screening against relevant search engines and sanction lists and communicate any additional deficiencies back to the business. Know Your Customer Analyst , you are expected to stay current with all regulatory changes and requirements around client Know Your Customer Analyst, Suitability and Documentation.\nJob responsibilities\nReview of confidential client data via publicly available and internal sources with understanding of the firm’s Know Your Customer requirements when reviewing documentation inclusive of Customer Identification Program (CIP), Standard Due Diligence (SDD), Enhanced Due Diligence (EDD), Local Due Diligence (LDD), Specialized Due Diligence(SpDD) and Product Due Diligence requirements (PDD)\nCompare and contrast differences within Know Your Customer records, highlight amendments required to production team and also highlight escalate to compliance in case of Anti Money Laundering Red flags\nEnsure the review of the records are complete within the due date and also Service Level Agreement deadlines and comment on trends/behavior relating to account due diligence and activity review\nExhibit the highest standards of customer service to our internal and external customers (inclusive of confidentiality) and meet firm wide quality standards\nHandling and maintenance of confidential client documentation and communicating/escalating issues to management when applicable\nBe part of the holistic client review team to follow up on outstanding alignment items within various Line of Business and other teams to close loop on the alignment\nBe flexible to work on other migration/remediation projects including Screening resolution , other Line of business holistic alignment or Quality Assurance and ability to comprehend the Know Your Customer risk factors and draft the overall risk summary for the client\nABOUT US\n\nJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.\n\nWe recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.\n\n\n\nABOUT THE TEAM\n\nThe Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world’s most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.",
         "Bengaluru",
         "657267.0",
         "/yr (est.)",
         "10000+ Employees",
         "1799",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "3.9",
         "3.6",
         "3.7"
        ],
        [
         "167",
         "Aptus Data LAbs",
         "Business Analyst/ Data Analyst",
         "4.1",
         "Job Information\nNumber of Positions\n1\nIndustry\nTechnology\nWork Experience\n0-3 years\nLast Activity Time\n12/02/2021 22:34\nCity\nBangalore North\nState/Province\nKarnataka\nCountry\nIndia\nZip/Postal Code\n560002\nJob Description\n1. Understand decision making needs of business functions (growth, marketing, product design, under-writing, collections, claim settlement, calling team etc.)\n\n2. Evaluate data required for decisions, identify sources of appropriate data, own up the sanity/accuracy of available data, ensure transformations for right decision making\n\n3. Define metrics through the business processes for clear measurability and to deep-dive into processes to identify areas of improvements\n\n4. Identify opportunities of improvement in product & process flows through exploratory analysis and Driving customer segmentation to come up with insights on customization for various customer groups\n\n5. define analytical frameworks to gain insights on correlations/causality\n\n6. Automate (wherever possible) & standardize decision making process to make it data driven\n\n7. Work with engineering & data platform team to drive data availability & reliability\n\n8. Monitor & highlight health of business by developing metric dashboards to track success & performance metrics for business functions\n\nRequirements\n1. 2+ years of hands-on experience on SQL, any BI platform (Tableau, PowerBI, Qlikview, Looker, Quicksight etc)\n\n2. Conceptual understanding of basic statistical concepts (Sampling, Distributions, Central tendency, Hypothesis testing etc)\n\n3. Basic understanding of data platforms and ETL processes\n\n4. Ability to identify relevant data to solve business problems and (in)validate hypothesis\n\n5. (Good to have) Prior data modelling experience in R/Python and some classification and/or regression techniques\n\n6. (Good to have) Prior experience with marketing platform such as moengage, clevertap, appsflyer would be a plus\n\n7. (Good to have) Prior experience / understanding of lending/insurance/banking domain would be a plus",
         "Bengaluru",
         "440688.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2014",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "$5 to $25 million (USD)",
         "4.1",
         "3.8",
         "3.8",
         "3.8",
         "4.2"
        ],
        [
         "168",
         "JPMorgan Chase & Co",
         "KYC Client Data Analyst",
         "4.0",
         "JOB DESCRIPTION\n\nAs a Know Your Customer Analyst in KYC Operations, you will be responsible to review the records completed by production team to ensure all client Know Your Customer records are compliant with regulatory standards, and will ensure high quality and timely completion of all client-level due diligence You will assist in end to end operations review and the client-facing team. You will perform a research to ensure a client’s Know Your Customer profile is appropriately updated and any discrepancies or issues with the profile escalated to the appropriate lines of business.\nYou will be responsible for ascertaining that all Know Your Customer and Anti Money Laundering policies are adhered to and will be responsible for conducting reviews of client’s Know Your Customer documentation stored in internal repositories and publicly available information, performing the necessary screening against relevant search engines and sanction lists and communicate any additional deficiencies back to the business. Know Your Customer Analyst , you are expected to stay current with all regulatory changes and requirements around client Know Your Customer Analyst, Suitability and documentation.\nJob Responsibilities:\nReview of confidential client data via publicly available and internal sources with understanding of the firm’s Know Your Customer requirements when reviewing documentation inclusive of Customer Identification Program (CIP), Standard Due Diligence (SDD), Enhanced Due Diligence (EDD), Local Due Diligence (LDD), Specialized Due Diligence(SpDD) and Product Due Diligence requirements (PDD)\nCompare and contrast differences within Know Your Customer records, highlight amendments required to production team and also highlight escalate to compliance in case of Anti Money Laundering Red flags\nEnsure the review of the records are complete within the due date and also Service Level Agreement deadlines and comment on trends/behavior relating to account due diligence and activity review\nExhibit the highest standards of customer service to our internal and external customers (inclusive of confidentiality) and meet firm wide quality standards\nHandling and maintenance of confidential client documentation and communicating/escalating issues to management when applicable\nBe part of the holistic client review team to follow up on outstanding alignment items within various Line of Business and other teams to close loop on the alignment\nBe flexible to work on other migration/remediation projects including Screening resolution, other Line of business holistic alignment or Quality Assurance and ability to comprehend the Know Your Customer risk factors and draft the overall risk summary for the client\nRequired Qualifications, Skills and Capabilities:\nBachelor’s Degree or Graduate Degree\n3-5 years’ experience in the Financial Services industry with a demonstrated track-record of delivery and/or relevant experience in Compliance and KYC.\nComputer skills: Lotus Notes and Microsoft Office Suite including Excel, Word, and PowerPoint\nOutstanding client management, partnership building, leadership, and direct experience of dealing with stakeholders using Effective communication, organisation, prioritization and interpersonal skills\nAbility to identify risks, issues and successfully navigate through to completion\nSelf-reliance and willingness to \"own\" complications and creatively find solutions\nFoster and champion High Performance Culture where people are empowered to make decisions that affect their work/environment\nABOUT US\n\nJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.\n\nWe recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.\n\n\n\nABOUT THE TEAM\nThe Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world’s most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.\n\n\nOperations teams develop and manage innovative, secure service solutions to meet clients’ needs globally. Developing and using the latest technology, teams work to deliver industry-leading capabilities to our clients and customers, making it easy and convenient to do business with the firm. Teams also drive growth by refining technology-driven customer and client experiences that put users first, providing an unparalleled experience.",
         "Hyderābād",
         "639359.0",
         "/yr (est.)",
         "10000+ Employees",
         "1799",
         "Company - Public",
         "Banking & Lending",
         "Finance",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "3.9",
         "3.6",
         "3.7"
        ],
        [
         "170",
         "INTEL",
         "Data Analyst",
         "4.1",
         "Job Description\n\nProvide expertise on database management/design to drive integration of business data, functions, and systems. Establish standards, guidelines, procedures, and other infrastructure necessary to support the objective of integration of data. Provide expertise on database management/design to drive integration of business data, functions, and systems. Partnering with IT and Data Ingestion team to transform business requirements to data requirements needed for automation. Validating feasibility of ideas, understanding customer expectations from the product, conducting design due diligence, and evaluating business value and risks. Leading E2E business product test, business process testing, validation and sign off for simple to complex implementations. Plans and schedules daily tasks, uses judgement on a variety of problems requiring deviation from standard practices. Inadequacies and erroneous decisions would cause moderate inconvenience and expense.\nQualifications\n\nQualifications: Candidates should possess a Bachelor of Computer Information Systems, Engineering, or equivalent with a minimum of 4 years of experience Worked on Learning Management System experience a plus Experience in BI Development and Deployment of SSAS models, SSIS packages from Excel, SQL Technical skills include good hands on experience in, SSRS Reporting Services, SSAS (Analysis Services) Being a result driven individual with a passion for data and analytics who can work collaboratively to solve business problems that drive operational efficiencies Convert client requirements into technical terms for the development team, and advise clients on resource requirements, scope, budgets, and timing Extensive Knowledge on analytical tools like Power BI or Tableau Ability to use BI/ Analytics tools, write queries Knowledge of SQL, Python or R Take initiatives and ownership with ability to work independently as well as collaboratively; a strong team player. Understanding of Agile principles Skills: Ability to analyze and interpret data Data acumen and domain expertise Data visualization capability MS Excel expertise High level math and statistics knowledge Written and Verbal Communication skills Critical thinking and problem-solving skills\nInside this Business Group\n\nIntel's Human Resources group is responsible for hiring, developing and retaining the best and brightest employees while continuing to strengthen the company's culture and values. Intel Human Resources provides first-rate, cost-effective services and support to employees worldwide and is dedicated to advancing Intel's business goals.\nPosting Statement\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\nBenefits\n\nWe offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here.\n\nIt has come to our notice that some people have received fake job interview letters ostensibly issued by Intel, inviting them to attend interviews in Intel’s offices for various positions and further requiring them to deposit money to be eligible for the interviews. We wish to bring to your notice that these letters are not issued by Intel or any of its authorized representatives. Hiring at Intel is based purely on merit and Intel does not ask or require candidates to deposit any money. We would urge people interested in working for Intel, to apply directly at https://jobs.intel.com/ and not fall prey to unscrupulous elements.\nWorking Model\n\nThis role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. In certain circumstances the work model may change to accommodate business needs.\n\nJobType\nHybrid",
         "Bengaluru",
         "941300.0",
         "/yr (est.)",
         "10000+ Employees",
         "1968",
         "Company - Public",
         "Computer Hardware Development",
         "Information Technology",
         "$10+ billion (USD)",
         "4.0",
         "3.9",
         "4.2",
         "3.6",
         "4.1"
        ],
        [
         "175",
         "CoStrategix",
         "Member Data Analyst",
         "3.9",
         "Position - Member Data Analyst\n\nExperience -3-5 years of prior experience having worked on data related projects\n\nQualifications - B.E (or equivalent) in Computer Sciences\n\nJob Description\nAs Data Analyst, this role will be responsible for Data analysis. Key responsibility includes analysis of data for insight generation, data visualization and quality assessment.\nRoles & Responsibilities:\nAbility to understand the business domain and determine business impact due to data issues.\nData analysis using statistical techniques and visualization.\nExperience in Data validation.\nHands on in using Data profiling tools and techniques.\nStrong in approaches to evaluate large dataset for quality and accuracy.\nAnalyze, query and manipulate data according to defined business rules and procedures.\nIdentify, compare, and resolve data quality problems.\nGood understanding of data models.\nBe a strong Agile team member.\nInsight generation through visualization.\n\nSkills:\nStrong knowledge on Excel – (Pivots, Macros / Functions (statistical), Filters,Vlookup etc).\nShould be hands on in Data profiling / Data Quality tools preferably Informatica/Talend.\nShould be hands on writing complex queries\nShould have scripting knowledge on either Python / Awk\nExcellent communication and organizational skills",
         "Bengaluru",
         "387298.0",
         "/yr (est.)",
         "51 to 200 Employees",
         "2006",
         "Company - Private",
         "Information Technology Support Services",
         "Information Technology",
         "Unknown / Non-Applicable",
         "3.9",
         "3.5",
         "3.9",
         "3.7",
         "3.6"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 133
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_avg_estimate</th>\n",
       "      <th>salary_estimate_payperiod</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_founded</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>revenue</th>\n",
       "      <th>career_opportunities_rating</th>\n",
       "      <th>comp_and_benefits_rating</th>\n",
       "      <th>culture_and_values_rating</th>\n",
       "      <th>senior_management_rating</th>\n",
       "      <th>work_life_balance_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABB</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Junior Data Analyst\\nTake your next career ste...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>325236.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1883</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electronics Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>News Corp</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Job Description :\\nJob Title: Analytics Engine...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>522206.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>2013</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Media &amp; Communication</td>\n",
       "      <td>$5 to $10 billion (USD)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Healthcare Data Analyst</td>\n",
       "      <td>3.8</td>\n",
       "      <td>A day in the life of an Infoscion • As part of...</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>533713.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1981</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JPMorgan Chase &amp; Co</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>JOB DESCRIPTION\\n\\nYou will be part of a team ...</td>\n",
       "      <td>India</td>\n",
       "      <td>539530.5</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1799</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Banking &amp; Lending</td>\n",
       "      <td>Finance</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alcon</td>\n",
       "      <td>Data Analyst - Digital Health</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Key Responsibilities\\nCollect and analyze larg...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>784161.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1945</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Biotech &amp; Pharmaceuticals</td>\n",
       "      <td>Pharmaceutical &amp; Biotechnology</td>\n",
       "      <td>$5 to $10 billion (USD)</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Addepar</td>\n",
       "      <td>Market Data Analyst (Pune)</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Who We Are\\nAddepar is a global technology and...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>420887.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>501 to 1000 Employees</td>\n",
       "      <td>2009</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Creative Synergies Group</td>\n",
       "      <td>Data Analyst-Power BI</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Role\\nData Analyst-Power BI\\n\\nExperience\\n9 –...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>761723.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>2011</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>Heads Up For Tails</td>\n",
       "      <td>Inventory Manager- Data Analyst</td>\n",
       "      <td>4.3</td>\n",
       "      <td>About Us\\nHeads Up For Tails is a one-stop pet...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>690600.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>2008</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Pet &amp; Pet Supplies Stores</td>\n",
       "      <td>Retail &amp; Wholesale</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Quest Global</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Quest Global is an organization at the forefro...</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>415258.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1997</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$500 million to $1 billion (USD)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Thoucentric</td>\n",
       "      <td>Data Analyst (Advanced SQL Experience)</td>\n",
       "      <td>4.1</td>\n",
       "      <td>About us\\nThoucentric is the Consulting arm of...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>921654.0</td>\n",
       "      <td>/yr (est.)</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>2015</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Business Consulting</td>\n",
       "      <td>Management &amp; Consulting</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company                               job_title  \\\n",
       "0                         ABB                     Junior Data Analyst   \n",
       "10                  News Corp                            Data Analyst   \n",
       "20                    Infosys                 Healthcare Data Analyst   \n",
       "22        JPMorgan Chase & Co                            Data Analyst   \n",
       "23                      Alcon           Data Analyst - Digital Health   \n",
       "..                        ...                                     ...   \n",
       "524                   Addepar              Market Data Analyst (Pune)   \n",
       "528  Creative Synergies Group                   Data Analyst-Power BI   \n",
       "533        Heads Up For Tails         Inventory Manager- Data Analyst   \n",
       "543              Quest Global                            Data Analyst   \n",
       "551               Thoucentric  Data Analyst (Advanced SQL Experience)   \n",
       "\n",
       "     company_rating                                    job_description  \\\n",
       "0               4.0  Junior Data Analyst\\nTake your next career ste...   \n",
       "10              3.6  Job Description :\\nJob Title: Analytics Engine...   \n",
       "20              3.8  A day in the life of an Infoscion • As part of...   \n",
       "22              4.0  JOB DESCRIPTION\\n\\nYou will be part of a team ...   \n",
       "23              3.8  Key Responsibilities\\nCollect and analyze larg...   \n",
       "..              ...                                                ...   \n",
       "524             4.2  Who We Are\\nAddepar is a global technology and...   \n",
       "528             3.8  Role\\nData Analyst-Power BI\\n\\nExperience\\n9 –...   \n",
       "533             4.3  About Us\\nHeads Up For Tails is a one-stop pet...   \n",
       "543             3.7  Quest Global is an organization at the forefro...   \n",
       "551             4.1  About us\\nThoucentric is the Consulting arm of...   \n",
       "\n",
       "      location  salary_avg_estimate salary_estimate_payperiod  \\\n",
       "0    Bengaluru             325236.0                /yr (est.)   \n",
       "10   Bengaluru             522206.0                /yr (est.)   \n",
       "20     Chennai             533713.0                /yr (est.)   \n",
       "22       India             539530.5                /yr (est.)   \n",
       "23   Bengaluru             784161.0                /yr (est.)   \n",
       "..         ...                  ...                       ...   \n",
       "524       Pune             420887.0                /yr (est.)   \n",
       "528  Bengaluru             761723.0                /yr (est.)   \n",
       "533  Bengaluru             690600.0                /yr (est.)   \n",
       "543    Belgaum             415258.0                /yr (est.)   \n",
       "551  Bengaluru             921654.0                /yr (est.)   \n",
       "\n",
       "               company_size company_founded    employment_type  \\\n",
       "0          10000+ Employees            1883   Company - Public   \n",
       "10         10000+ Employees            2013   Company - Public   \n",
       "20         10000+ Employees            1981   Company - Public   \n",
       "22         10000+ Employees            1799   Company - Public   \n",
       "23         10000+ Employees            1945   Company - Public   \n",
       "..                      ...             ...                ...   \n",
       "524   501 to 1000 Employees            2009  Company - Private   \n",
       "528  1001 to 5000 Employees            2011  Company - Private   \n",
       "533  1001 to 5000 Employees            2008  Company - Private   \n",
       "543        10000+ Employees            1997  Company - Private   \n",
       "551    201 to 500 Employees            2015  Company - Private   \n",
       "\n",
       "                                    industry                          sector  \\\n",
       "0                  Electronics Manufacturing                   Manufacturing   \n",
       "10                                Publishing           Media & Communication   \n",
       "20   Information Technology Support Services          Information Technology   \n",
       "22                         Banking & Lending                         Finance   \n",
       "23                 Biotech & Pharmaceuticals  Pharmaceutical & Biotechnology   \n",
       "..                                       ...                             ...   \n",
       "524  Enterprise Software & Network Solutions          Information Technology   \n",
       "528                     Software Development          Information Technology   \n",
       "533                Pet & Pet Supplies Stores              Retail & Wholesale   \n",
       "543  Information Technology Support Services          Information Technology   \n",
       "551                      Business Consulting         Management & Consulting   \n",
       "\n",
       "                              revenue  career_opportunities_rating  \\\n",
       "0                  $10+ billion (USD)                          3.7   \n",
       "10            $5 to $10 billion (USD)                          3.5   \n",
       "20                 $10+ billion (USD)                          3.8   \n",
       "22                 $10+ billion (USD)                          4.0   \n",
       "23            $5 to $10 billion (USD)                          3.4   \n",
       "..                                ...                          ...   \n",
       "524          Unknown / Non-Applicable                          4.0   \n",
       "528          Unknown / Non-Applicable                          3.9   \n",
       "533          Unknown / Non-Applicable                          4.0   \n",
       "543  $500 million to $1 billion (USD)                          3.7   \n",
       "551          Unknown / Non-Applicable                          3.8   \n",
       "\n",
       "     comp_and_benefits_rating  culture_and_values_rating  \\\n",
       "0                         3.6                        4.0   \n",
       "10                        3.4                        3.3   \n",
       "20                        3.0                        4.0   \n",
       "22                        3.9                        3.9   \n",
       "23                        3.9                        3.6   \n",
       "..                        ...                        ...   \n",
       "524                       4.2                        4.0   \n",
       "528                       3.6                        3.8   \n",
       "533                       3.7                        3.9   \n",
       "543                       3.2                        3.8   \n",
       "551                       3.5                        4.5   \n",
       "\n",
       "     senior_management_rating  work_life_balance_rating  \n",
       "0                         3.5                       3.9  \n",
       "10                        3.2                       3.5  \n",
       "20                        3.5                       3.7  \n",
       "22                        3.6                       3.7  \n",
       "23                        3.3                       3.5  \n",
       "..                        ...                       ...  \n",
       "524                       3.3                       4.0  \n",
       "528                       3.9                       3.8  \n",
       "533                       3.8                       3.8  \n",
       "543                       3.5                       3.7  \n",
       "551                       4.1                       4.0  \n",
       "\n",
       "[133 rows x 18 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"job_title\"].str.contains(\".*[D|d]ata [A|a]nalyst.*\", regex = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e138d",
   "metadata": {},
   "source": [
    "## Personally I feel this dataset can be honed further more. but it's time cosuming process. so for my current project i'm stopping here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "315aaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r\"D:\\4.Data Wrangling\\Datasets\\Ds_jobs\\cleaned_glassdoor_job_postings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "das",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
